{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "No CUDA-capable device is detected\n",
      "torch.Size([500, 13]) torch.Size([500])\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# %%\n",
    "import torch\n",
    "import time\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from task_evaluation import TaskEvaluation\n",
    "from data.ioi_dataset import gen_templated_prompts\n",
    "from data.greater_than_dataset import generate_greater_than_dataset\n",
    "from circuit_discovery import CircuitDiscovery, only_feature\n",
    "from circuit_lens import CircuitComponent\n",
    "from plotly_utils import *\n",
    "from data.ioi_dataset import IOI_GROUND_TRUTH_HEADS\n",
    "from data.greater_than_dataset import GT_GROUND_TRUTH_HEADS\n",
    "from memory import get_gpu_memory\n",
    "from sklearn import metrics\n",
    "from tqdm import trange\n",
    "\n",
    "from utils import get_attn_head_roc\n",
    "\n",
    "\n",
    "# %%\n",
    "torch.set_grad_enabled(False)\n",
    "get_gpu_memory()\n",
    "# %%\n",
    "dataset_prompts = gen_templated_prompts(template_idex=1, N=500)\n",
    "dataset_gt = generate_greater_than_dataset(N=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# dataset_prompts = generate_greater_than_dataset(N=100)\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "def component_filter(component: str):\n",
    "    return component in [\n",
    "        CircuitComponent.Z_FEATURE,\n",
    "        CircuitComponent.MLP_FEATURE,\n",
    "        CircuitComponent.ATTN_HEAD,\n",
    "        CircuitComponent.UNEMBED,\n",
    "        # CircuitComponent.UNEMBED_AT_TOKEN,\n",
    "        CircuitComponent.EMBED,\n",
    "        CircuitComponent.POS_EMBED,\n",
    "        # CircuitComponent.BIAS_O,\n",
    "        CircuitComponent.Z_SAE_ERROR,\n",
    "        # CircuitComponent.Z_SAE_BIAS,\n",
    "        # CircuitComponent.TRANSCODER_ERROR,\n",
    "        # CircuitComponent.TRANSCODER_BIAS,\n",
    "    ]\n",
    "\n",
    "\n",
    "pass_based = True\n",
    "\n",
    "passes = 5\n",
    "node_contributors = 1\n",
    "first_pass_minimal = True\n",
    "\n",
    "sub_passes = 3\n",
    "do_sub_pass = True #False\n",
    "layer_thres = 9\n",
    "minimal = True\n",
    "\n",
    "\n",
    "num_greedy_passes = 20\n",
    "k = 1\n",
    "N = 30\n",
    "\n",
    "thres = 4\n",
    "\n",
    "\n",
    "# # Danny and Charlie... Charlie gave shit to Danny\n",
    "# # Danny and Charlie... Charlie gave shit to Charlie\n",
    "# # Danny and Charlie... Danny gave shit to Danny\n",
    "# #\n",
    "\n",
    "def strategy(cd: CircuitDiscovery):\n",
    "    if pass_based:\n",
    "        for _ in range(passes):\n",
    "            cd.add_greedy_pass(contributors_per_node=node_contributors, minimal=first_pass_minimal)\n",
    "\n",
    "            if do_sub_pass:\n",
    "                for _ in range(sub_passes):\n",
    "                    cd.add_greedy_pass_against_all_existing_nodes(contributors_per_node=node_contributors, skip_z_features=True, layer_threshold=layer_thres, minimal=minimal)\n",
    "    else:\n",
    "        for _ in range(num_greedy_passes):\n",
    "            cd.greedily_add_top_contributors(k=k, reciever_threshold=thres)\n",
    "\n",
    "\n",
    "\n",
    "task_eval = TaskEvaluation(prompts=dataset_prompts, circuit_discovery_strategy=strategy, allowed_components_filter=component_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "hbi [[5, 8], [9, 6], [0, 1], [7, 9], [9, 9], [2, 2], [8, 10], [7, 3], [9, 7], [10, 0], [3, 0], [10, 2], [10, 7], [11, 10], [8, 6], [10, 6], [11, 3], [11, 2], [4, 11], [6, 9], [10, 10], [0, 10], [11, 9], [10, 1], [5, 5], [5, 9], [6, 4], [8, 7], [8, 5], [6, 5], [11, 5], [2, 3], [6, 7], [3, 7], [2, 9], [4, 3], [3, 3], [8, 8], [3, 4], [4, 8], [8, 0], [1, 5], [9, 5], [0, 2], [9, 10], [5, 6], [0, 3], [0, 6], [2, 6], [11, 7], [2, 8], [9, 1], [1, 8], [5, 11], [5, 4], [3, 11], [0, 0], [10, 8], [1, 4], [11, 1], [1, 6], [4, 4], [10, 3], [8, 3], [4, 5], [6, 1], [6, 6], [6, 10], [2, 4], [0, 5], [7, 8], [10, 9], [8, 11], [0, 4], [6, 2], [3, 6], [2, 0], [7, 1], [0, 9], [11, 11], [7, 7], [0, 11], [5, 1], [3, 10], [6, 3], [4, 9], [4, 2], [2, 1], [6, 8], [1, 1], [5, 10], [5, 0], [7, 6], [1, 11], [6, 11], [8, 2], [2, 11], [2, 10], [7, 10], [3, 2], [5, 3], [8, 1], [4, 10], [11, 4], [7, 2], [1, 3], [9, 3], [4, 0], [1, 10], [10, 11], [1, 2], [5, 2], [9, 2], [1, 0], [9, 11], [6, 0], [5, 7], [0, 8], [8, 9], [9, 8], [7, 4], [9, 0], [7, 5], [8, 4], [0, 7], [2, 7], [1, 7], [10, 5], [4, 6], [10, 4], [9, 4], [1, 9], [7, 11], [11, 8], [11, 6], [3, 1], [7, 0], [4, 7], [3, 5], [4, 1], [3, 9], [2, 5], [3, 8], [11, 0]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Num Heads=%{x}<br>Normalized Logit Difference=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          4,
          8,
          12,
          16,
          20,
          24,
          28,
          32,
          36,
          40,
          44,
          48,
          52,
          56,
          60,
          64,
          68,
          72,
          76,
          80,
          84,
          88,
          92,
          96,
          100,
          104,
          108,
          112,
          116,
          120,
          124,
          128,
          132,
          136,
          140,
          144
         ],
         "xaxis": "x",
         "y": [
          0,
          0.21186257898807526,
          0.5489739179611206,
          0.8727449774742126,
          0.6796296834945679,
          0.8599653244018555,
          0.9136337637901306,
          0.9623374342918396,
          0.9627640247344971,
          0.9671616554260254,
          0.9698102474212646,
          0.9698017835617065,
          0.9670000076293945,
          0.9668703079223633,
          0.9661858081817627,
          0.9729059934616089,
          0.9796709418296814,
          0.9797811508178711,
          0.9813811779022217,
          0.982769250869751,
          0.9864718914031982,
          0.9852297902107239,
          0.9863163828849792,
          0.9903882741928101,
          0.9909783005714417,
          0.9914416670799255,
          0.9912298917770386,
          0.9917020201683044,
          0.9918546676635742,
          0.9914759993553162,
          0.9948742985725403,
          0.9956631064414978,
          0.9954479336738586,
          0.997222900390625,
          0.9982313513755798,
          0.9993125796318054,
          1
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Faithfulness Curve"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Num Heads"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Normalized Logit Difference"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:04<00:00,  6.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "hbi [[10, 1], [0, 1], [5, 5], [0, 3], [9, 11], [0, 5], [0, 6], [0, 7], [9, 0], [9, 1], [9, 10], [6, 8], [10, 7], [9, 9], [8, 7], [8, 6], [7, 0], [3, 8], [7, 4], [7, 5], [2, 8], [9, 3], [1, 10], [2, 7], [2, 0], [9, 7], [2, 2], [9, 6], [3, 0], [5, 0], [10, 6], [10, 9], [4, 11], [10, 10], [10, 0], [10, 3], [5, 1], [4, 3], [2, 9], [6, 1], [10, 4], [10, 2], [9, 8], [3, 7], [1, 5], [6, 0], [9, 5], [1, 11], [1, 1], [6, 9], [4, 7], [0, 4], [10, 11], [9, 4], [3, 6], [9, 2], [10, 5], [6, 4], [7, 3], [8, 5], [0, 10], [6, 11], [5, 2], [1, 0], [5, 7], [11, 10], [8, 3], [10, 8], [5, 8], [8, 4], [5, 10], [0, 11], [3, 3], [8, 10], [7, 9], [1, 2], [5, 4], [6, 5], [11, 7], [11, 5], [2, 3], [2, 4], [4, 5], [3, 11], [3, 10], [7, 1], [11, 1], [3, 4], [7, 2], [2, 10], [5, 6], [2, 5], [7, 8], [4, 0], [4, 1], [4, 4], [2, 1], [11, 3], [11, 4], [5, 9], [11, 6], [6, 6], [11, 8], [4, 9], [0, 9], [11, 9], [11, 2], [8, 11], [8, 9], [8, 8], [8, 2], [8, 1], [8, 0], [7, 11], [7, 10], [7, 7], [7, 6], [6, 10], [6, 7], [6, 3], [6, 2], [0, 0], [5, 11], [5, 3], [4, 10], [4, 8], [4, 6], [4, 2], [3, 9], [3, 5], [3, 2], [3, 1], [11, 0], [2, 11], [2, 6], [1, 9], [1, 8], [1, 7], [1, 6], [1, 4], [1, 3], [0, 8], [0, 2], [11, 11]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Num Heads=%{x}<br>Normalized Logit Difference=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          4,
          8,
          12,
          16,
          20,
          24,
          28,
          32,
          36,
          40,
          44,
          48,
          52,
          56,
          60,
          64,
          68,
          72,
          76,
          80,
          84,
          88,
          92,
          96,
          100,
          104,
          108,
          112,
          116,
          120,
          124,
          128,
          132,
          136,
          140,
          144
         ],
         "xaxis": "x",
         "y": [
          0,
          0.07476472854614258,
          0.08381564915180206,
          0.11193161457777023,
          0.3168685734272003,
          0.31970757246017456,
          0.31903788447380066,
          0.4926495850086212,
          0.5997485518455505,
          0.8657242655754089,
          0.8672425746917725,
          0.9254310131072998,
          0.9289693236351013,
          0.9442175626754761,
          0.941994309425354,
          0.9590809345245361,
          0.9593459963798523,
          0.9118312001228333,
          0.9046187996864319,
          0.9500923752784729,
          0.9492096900939941,
          0.9481399059295654,
          0.9660481214523315,
          0.9657186269760132,
          0.9551959037780762,
          0.9783065319061279,
          0.9865961670875549,
          0.9958215355873108,
          0.9953812956809998,
          0.9955219626426697,
          0.9942097067832947,
          0.9976003170013428,
          0.9989522099494934,
          0.9991394877433777,
          0.9990469813346863,
          0.9993738532066345,
          1
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Faithfulness Curve"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Num Heads"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Normalized Logit Difference"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "hbi [[11, 10], [9, 5], [6, 2], [3, 3], [8, 9], [5, 9], [9, 4], [9, 11], [8, 8], [1, 5], [0, 4], [9, 1], [3, 1], [0, 3], [0, 2], [8, 4], [5, 8], [11, 6], [5, 3], [8, 1], [1, 10], [10, 5], [10, 7], [7, 10], [10, 6], [0, 0], [8, 0], [2, 6], [1, 6], [6, 10], [10, 4], [2, 0], [5, 0], [7, 6], [9, 9], [6, 0], [10, 0], [8, 7], [1, 7], [2, 2], [10, 3], [8, 3], [10, 2], [1, 11], [9, 2], [2, 4], [5, 6], [3, 2], [11, 7], [7, 7], [11, 1], [1, 9], [6, 1], [11, 2], [5, 4], [1, 1], [4, 11], [6, 9], [9, 0], [10, 10], [4, 2], [4, 8], [4, 1], [3, 6], [6, 5], [3, 10], [7, 0], [5, 7], [0, 1], [10, 8], [9, 6], [3, 9], [0, 8], [2, 10], [10, 11], [6, 3], [0, 9], [7, 9], [9, 10], [8, 5], [5, 10], [7, 2], [0, 5], [6, 4], [6, 6], [4, 10], [3, 5], [2, 7], [1, 3], [7, 3], [11, 8], [6, 7], [4, 4], [0, 6], [1, 4], [5, 2], [6, 8], [2, 8], [3, 7], [7, 1], [10, 9], [11, 9], [5, 11], [2, 11], [4, 3], [11, 11], [4, 6], [11, 4], [3, 11], [8, 2], [11, 5], [10, 1], [7, 5], [0, 11], [5, 5], [2, 3], [2, 9], [11, 3], [8, 6], [4, 9], [3, 8], [9, 3], [3, 4], [9, 8], [4, 7], [7, 4], [0, 7], [1, 2], [2, 1], [3, 0], [2, 5], [6, 11], [1, 0], [7, 8], [11, 0], [7, 11], [1, 8], [9, 7], [8, 11], [0, 10], [4, 5], [8, 10], [4, 0], [5, 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:06<02:01,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "hbi [[6, 7], [1, 1], [4, 10], [0, 3], [4, 0], [4, 6], [6, 1], [3, 1], [9, 2], [6, 2], [0, 11], [0, 7], [0, 1], [11, 1], [3, 5], [9, 3], [5, 2], [7, 4], [5, 9], [5, 8], [6, 5], [0, 8], [0, 5], [8, 3], [5, 7], [10, 2], [4, 8], [3, 7], [7, 9], [10, 1], [1, 4], [10, 3], [9, 4], [9, 11], [2, 8], [7, 11], [9, 5], [9, 7], [0, 10], [1, 2], [4, 5], [4, 7], [5, 1], [7, 0], [6, 8], [0, 4], [10, 0], [5, 3], [1, 3], [5, 11], [5, 10], [9, 0], [4, 11], [2, 3], [11, 4], [4, 9], [8, 10], [10, 9], [3, 0], [2, 4], [7, 6], [6, 11], [3, 10], [1, 7], [1, 8], [5, 0], [6, 3], [7, 2], [2, 11], [10, 5], [8, 7], [10, 4], [8, 5], [10, 11], [10, 7], [11, 10], [2, 6], [2, 1], [8, 0], [6, 6], [8, 8], [9, 1], [11, 6], [11, 2], [11, 3], [2, 9], [2, 5], [1, 9], [6, 0], [10, 8], [1, 0], [3, 9], [6, 10], [2, 7], [9, 8], [7, 8], [9, 6], [3, 6], [11, 5], [0, 2], [7, 5], [9, 9], [6, 4], [1, 6], [8, 9], [3, 2], [10, 6], [8, 1], [2, 10], [8, 4], [2, 2], [8, 2], [9, 10], [4, 4], [3, 8], [5, 6], [1, 10], [11, 7], [0, 9], [3, 3], [10, 10], [6, 9], [7, 1], [5, 4], [7, 10], [4, 1], [11, 0], [3, 11], [8, 11], [0, 0], [11, 11], [4, 2], [1, 11], [4, 3], [8, 6], [1, 5], [2, 0], [11, 9], [5, 5], [11, 8], [7, 3], [0, 6], [3, 4], [7, 7]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:12<01:49,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "hbi [[5, 3], [0, 0], [1, 7], [4, 8], [7, 0], [8, 1], [1, 6], [0, 8], [2, 6], [5, 2], [7, 3], [9, 11], [3, 8], [4, 0], [4, 1], [0, 4], [3, 9], [8, 10], [5, 7], [7, 11], [7, 7], [1, 2], [4, 4], [9, 10], [11, 2], [1, 9], [3, 3], [8, 8], [10, 3], [8, 3], [10, 4], [3, 6], [2, 3], [2, 4], [0, 1], [6, 2], [7, 10], [6, 11], [3, 11], [4, 11], [11, 5], [5, 5], [10, 5], [6, 9], [1, 4], [2, 11], [4, 2], [6, 1], [5, 10], [4, 5], [9, 6], [10, 0], [6, 10], [0, 9], [1, 10], [11, 8], [1, 11], [3, 4], [7, 6], [11, 4], [9, 0], [0, 6], [1, 8], [10, 10], [2, 9], [1, 1], [5, 4], [10, 8], [7, 9], [8, 0], [4, 6], [9, 4], [4, 3], [2, 2], [2, 0], [10, 9], [6, 4], [4, 10], [5, 6], [4, 7], [8, 4], [3, 10], [7, 8], [3, 1], [10, 6], [9, 1], [1, 3], [6, 0], [11, 1], [10, 1], [8, 5], [8, 6], [7, 2], [2, 1], [3, 7], [11, 7], [5, 8], [9, 7], [3, 0], [2, 8], [2, 10], [3, 2], [0, 2], [0, 11], [0, 5], [8, 11], [6, 8], [10, 2], [4, 9], [6, 3], [11, 3], [9, 9], [9, 2], [0, 7], [11, 10], [5, 1], [10, 7], [5, 0], [11, 6], [6, 6], [9, 3], [8, 9], [1, 0], [11, 11], [9, 5], [7, 1], [2, 5], [10, 11], [2, 7], [6, 7], [0, 3], [8, 7], [5, 9], [5, 11], [11, 0], [6, 5], [7, 5], [11, 9], [8, 2], [0, 10], [3, 5], [7, 4], [1, 5], [9, 8]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:18<01:42,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "hbi [[3, 3], [2, 0], [5, 2], [0, 5], [6, 0], [8, 2], [9, 11], [7, 5], [4, 1], [11, 9], [0, 2], [3, 7], [6, 9], [10, 3], [3, 6], [8, 8], [0, 8], [3, 5], [3, 2], [7, 6], [6, 6], [5, 7], [6, 1], [11, 11], [11, 3], [2, 2], [0, 4], [8, 3], [9, 8], [2, 1], [7, 11], [1, 11], [3, 9], [9, 5], [0, 1], [6, 10], [2, 11], [0, 6], [10, 0], [7, 9], [8, 11], [9, 0], [7, 1], [11, 6], [5, 9], [4, 6], [4, 0], [1, 7], [9, 10], [8, 6], [2, 10], [6, 11], [7, 10], [1, 5], [4, 4], [2, 8], [10, 4], [8, 7], [10, 2], [2, 7], [7, 2], [9, 2], [10, 11], [9, 3], [11, 7], [8, 1], [1, 9], [2, 3], [3, 11], [7, 4], [4, 9], [0, 0], [11, 8], [4, 10], [9, 4], [10, 5], [4, 11], [1, 0], [6, 7], [5, 0], [3, 4], [3, 8], [1, 8], [2, 4], [11, 2], [5, 3], [11, 1], [5, 4], [4, 2], [1, 10], [5, 10], [0, 9], [11, 4], [7, 7], [1, 3], [3, 1], [5, 6], [5, 11], [11, 0], [2, 9], [8, 5], [9, 1], [7, 3], [8, 9], [11, 5], [1, 1], [10, 6], [6, 5], [4, 8], [8, 4], [2, 6], [11, 10], [0, 3], [10, 1], [10, 7], [7, 0], [5, 1], [4, 5], [9, 6], [3, 0], [5, 8], [8, 10], [6, 4], [9, 7], [7, 8], [6, 3], [10, 8], [8, 0], [1, 2], [0, 10], [4, 3], [2, 5], [6, 8], [1, 4], [10, 9], [10, 10], [1, 6], [3, 10], [0, 7], [5, 5], [6, 2], [0, 11], [9, 9], [4, 7]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:24<01:36,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "hbi [[7, 7], [2, 5], [8, 2], [4, 10], [4, 11], [4, 8], [9, 1], [5, 3], [10, 9], [3, 5], [0, 7], [11, 4], [6, 3], [3, 6], [2, 4], [2, 6], [9, 9], [3, 11], [2, 7], [11, 2], [9, 7], [11, 9], [11, 3], [9, 5], [6, 5], [5, 0], [1, 8], [10, 11], [7, 8], [10, 3], [3, 7], [3, 10], [5, 11], [10, 4], [9, 3], [1, 3], [11, 10], [8, 4], [4, 3], [9, 6], [7, 3], [6, 4], [5, 2], [3, 4], [10, 2], [6, 11], [0, 1], [8, 1], [9, 11], [10, 1], [10, 6], [2, 11], [7, 9], [4, 0], [10, 0], [5, 9], [0, 4], [6, 8], [9, 4], [10, 5], [1, 1], [6, 9], [0, 2], [9, 2], [0, 8], [10, 10], [11, 8], [3, 0], [2, 1], [0, 5], [6, 1], [0, 11], [5, 1], [1, 4], [11, 0], [7, 0], [7, 1], [7, 2], [8, 7], [0, 9], [4, 4], [1, 5], [8, 5], [9, 0], [8, 6], [5, 5], [4, 7], [0, 3], [0, 10], [1, 0], [11, 5], [2, 10], [2, 3], [5, 8], [3, 8], [3, 2], [8, 11], [7, 5], [6, 0], [6, 2], [7, 10], [7, 4], [0, 6], [11, 6], [8, 3], [4, 9], [8, 0], [2, 8], [4, 5], [11, 7], [3, 1], [10, 8], [8, 9], [9, 8], [4, 2], [2, 9], [8, 10], [3, 3], [0, 0], [5, 7], [5, 4], [10, 7], [1, 2], [7, 6], [1, 9], [2, 2], [1, 6], [3, 9], [1, 10], [8, 8], [6, 7], [1, 11], [1, 7], [5, 10], [4, 6], [6, 10], [5, 6], [11, 1], [4, 1], [6, 6], [9, 10], [7, 11], [11, 11], [2, 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:30<01:31,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "hbi [[11, 11], [7, 2], [10, 7], [1, 3], [4, 9], [6, 7], [3, 11], [8, 1], [9, 9], [2, 10], [7, 7], [5, 8], [1, 4], [10, 10], [4, 4], [9, 11], [2, 11], [1, 9], [11, 5], [11, 2], [6, 11], [7, 11], [3, 9], [0, 4], [8, 9], [5, 3], [5, 0], [10, 11], [11, 10], [9, 3], [3, 5], [4, 11], [0, 2], [1, 6], [7, 6], [9, 5], [8, 11], [8, 7], [7, 5], [10, 9], [0, 5], [8, 0], [9, 6], [1, 5], [10, 1], [6, 10], [0, 10], [6, 2], [5, 9], [3, 6], [4, 10], [8, 3], [4, 6], [2, 3], [8, 5], [0, 11], [10, 2], [8, 6], [5, 7], [7, 9], [5, 5], [3, 10], [9, 4], [1, 11], [7, 0], [10, 4], [6, 4], [4, 8], [3, 1], [6, 6], [7, 4], [11, 8], [2, 8], [4, 1], [5, 1], [2, 5], [1, 7], [0, 6], [9, 2], [4, 0], [6, 0], [2, 0], [9, 8], [3, 8], [6, 9], [11, 0], [6, 8], [6, 3], [8, 2], [8, 4], [1, 8], [2, 7], [10, 3], [3, 4], [11, 3], [11, 9], [0, 0], [7, 8], [5, 6], [11, 4], [4, 2], [7, 1], [3, 0], [11, 7], [5, 10], [10, 6], [11, 1], [0, 1], [0, 3], [3, 2], [1, 2], [7, 3], [5, 4], [5, 11], [9, 0], [8, 8], [7, 10], [2, 2], [0, 9], [9, 10], [5, 2], [3, 3], [11, 6], [6, 5], [10, 0], [0, 7], [0, 8], [9, 1], [2, 6], [10, 5], [4, 5], [1, 10], [2, 9], [4, 3], [4, 7], [9, 7], [8, 10], [3, 7], [10, 8], [2, 4], [1, 1], [1, 0], [2, 1], [6, 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:36<01:26,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "hbi [[3, 6], [0, 11], [1, 10], [3, 5], [8, 6], [1, 1], [6, 11], [0, 3], [7, 10], [9, 8], [6, 2], [10, 11], [7, 0], [10, 4], [7, 5], [4, 2], [8, 9], [10, 1], [6, 8], [1, 4], [9, 9], [2, 0], [6, 1], [11, 11], [9, 7], [6, 6], [0, 0], [4, 4], [1, 6], [9, 3], [11, 3], [10, 5], [0, 1], [2, 9], [7, 2], [7, 4], [10, 0], [10, 2], [4, 8], [3, 2], [10, 8], [11, 9], [10, 3], [5, 3], [6, 9], [10, 10], [5, 6], [7, 3], [6, 5], [11, 0], [9, 6], [10, 9], [1, 7], [2, 6], [7, 11], [5, 2], [8, 11], [8, 1], [8, 0], [8, 10], [2, 10], [11, 7], [3, 9], [7, 6], [9, 11], [4, 10], [1, 2], [5, 9], [2, 3], [3, 11], [3, 8], [6, 3], [9, 1], [3, 7], [1, 9], [5, 0], [1, 8], [11, 4], [0, 6], [6, 0], [3, 10], [0, 2], [9, 0], [11, 2], [2, 2], [6, 4], [2, 5], [8, 8], [4, 5], [5, 1], [3, 0], [5, 5], [5, 10], [5, 11], [0, 8], [1, 11], [8, 4], [3, 4], [0, 10], [11, 1], [7, 7], [8, 5], [11, 8], [9, 5], [5, 7], [6, 7], [3, 3], [6, 10], [4, 11], [3, 1], [2, 11], [0, 5], [1, 5], [7, 9], [9, 4], [8, 2], [4, 3], [0, 9], [11, 5], [8, 3], [2, 8], [2, 1], [0, 4], [2, 4], [8, 7], [5, 4], [7, 1], [11, 6], [2, 7], [1, 3], [5, 8], [4, 0], [4, 1], [4, 9], [4, 7], [9, 10], [0, 7], [1, 0], [11, 10], [10, 6], [9, 2], [10, 7], [7, 8], [4, 6]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:42<01:20,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "hbi [[10, 11], [10, 8], [8, 4], [3, 11], [0, 3], [7, 0], [4, 7], [8, 11], [2, 1], [6, 8], [0, 11], [11, 8], [3, 3], [10, 0], [0, 8], [1, 7], [5, 10], [8, 9], [4, 6], [5, 7], [8, 10], [11, 7], [0, 0], [1, 4], [4, 11], [6, 0], [6, 7], [10, 7], [7, 9], [7, 10], [7, 11], [2, 10], [7, 6], [0, 9], [9, 5], [2, 3], [2, 11], [9, 1], [11, 4], [6, 5], [7, 2], [8, 7], [2, 6], [3, 2], [10, 6], [6, 6], [11, 11], [4, 4], [5, 3], [1, 1], [2, 2], [5, 1], [10, 9], [4, 0], [3, 6], [1, 10], [6, 1], [7, 7], [5, 5], [6, 2], [2, 9], [7, 8], [0, 2], [10, 3], [6, 10], [1, 9], [3, 7], [9, 8], [8, 6], [10, 10], [5, 2], [10, 4], [2, 5], [4, 1], [9, 9], [11, 6], [8, 8], [5, 0], [9, 3], [2, 0], [9, 7], [5, 8], [4, 2], [6, 9], [2, 7], [10, 1], [4, 10], [6, 4], [8, 1], [1, 2], [1, 11], [3, 9], [11, 2], [7, 4], [4, 5], [4, 3], [1, 8], [3, 4], [1, 5], [11, 3], [11, 5], [4, 8], [10, 2], [6, 11], [1, 6], [2, 4], [1, 3], [3, 1], [7, 5], [10, 5], [11, 0], [3, 5], [2, 8], [0, 10], [4, 9], [6, 3], [9, 0], [3, 0], [8, 3], [8, 5], [5, 11], [8, 2], [3, 10], [0, 4], [8, 0], [9, 11], [7, 1], [0, 7], [3, 8], [5, 4], [9, 4], [9, 6], [0, 1], [5, 6], [5, 9], [0, 6], [9, 10], [9, 2], [11, 9], [7, 3], [11, 1], [1, 0], [11, 10], [0, 5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:49<01:13,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "hbi [[0, 9], [1, 10], [4, 3], [8, 3], [2, 4], [5, 1], [4, 9], [10, 8], [7, 6], [0, 2], [1, 11], [11, 3], [0, 4], [5, 6], [0, 5], [9, 7], [11, 7], [10, 2], [1, 8], [6, 8], [1, 2], [0, 3], [5, 2], [3, 9], [10, 6], [9, 11], [11, 6], [2, 0], [8, 7], [9, 0], [2, 5], [0, 8], [9, 6], [10, 10], [5, 7], [4, 1], [6, 2], [11, 9], [8, 9], [8, 1], [10, 7], [0, 11], [6, 0], [3, 0], [4, 5], [1, 6], [5, 3], [6, 9], [8, 0], [9, 1], [11, 0], [2, 6], [9, 8], [4, 7], [2, 10], [9, 2], [10, 5], [3, 10], [2, 9], [0, 7], [7, 9], [1, 5], [3, 2], [7, 11], [4, 6], [1, 4], [0, 1], [3, 11], [5, 10], [5, 8], [8, 10], [10, 11], [3, 3], [1, 7], [8, 6], [7, 5], [7, 8], [10, 3], [5, 0], [6, 11], [1, 0], [4, 0], [3, 1], [5, 4], [11, 10], [0, 0], [3, 7], [1, 1], [2, 11], [2, 8], [7, 1], [8, 5], [10, 1], [6, 10], [7, 4], [11, 5], [6, 3], [2, 7], [6, 7], [3, 5], [6, 1], [8, 4], [7, 7], [9, 10], [5, 11], [11, 1], [4, 11], [8, 2], [3, 8], [4, 10], [4, 8], [0, 10], [6, 4], [10, 4], [4, 2], [11, 2], [7, 3], [10, 0], [1, 9], [2, 2], [11, 8], [7, 0], [9, 4], [2, 3], [9, 9], [3, 6], [6, 6], [10, 9], [0, 6], [7, 10], [4, 4], [9, 5], [11, 4], [2, 1], [11, 11], [8, 11], [6, 5], [8, 8], [3, 4], [1, 3], [5, 5], [7, 2], [9, 3], [5, 9]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:55<01:08,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "hbi [[1, 9], [7, 7], [0, 6], [6, 0], [11, 2], [0, 9], [2, 0], [2, 10], [7, 5], [3, 10], [4, 3], [7, 9], [3, 0], [11, 0], [6, 10], [11, 7], [7, 2], [11, 5], [0, 2], [5, 6], [4, 1], [8, 0], [7, 10], [2, 4], [0, 10], [6, 4], [9, 9], [4, 7], [0, 11], [0, 1], [9, 8], [0, 5], [10, 0], [10, 10], [10, 1], [8, 2], [1, 6], [8, 11], [5, 0], [7, 8], [3, 8], [10, 7], [10, 3], [0, 4], [4, 0], [4, 10], [7, 11], [8, 4], [8, 10], [6, 2], [8, 8], [10, 4], [11, 9], [2, 2], [11, 8], [11, 10], [10, 9], [8, 5], [11, 6], [4, 6], [3, 9], [9, 0], [2, 3], [8, 3], [1, 4], [4, 8], [2, 11], [3, 3], [8, 9], [3, 11], [5, 5], [7, 0], [7, 3], [9, 6], [10, 5], [4, 5], [1, 11], [5, 3], [9, 4], [9, 5], [1, 5], [9, 3], [11, 4], [0, 7], [2, 6], [7, 1], [4, 4], [8, 6], [3, 4], [8, 1], [0, 3], [6, 1], [3, 2], [5, 11], [11, 3], [2, 1], [6, 8], [3, 7], [0, 0], [6, 11], [3, 5], [9, 1], [1, 10], [5, 1], [0, 8], [5, 9], [9, 10], [2, 8], [2, 9], [11, 1], [10, 6], [5, 10], [4, 9], [1, 3], [6, 9], [6, 5], [9, 2], [1, 7], [6, 3], [8, 7], [1, 1], [1, 0], [1, 2], [9, 11], [2, 7], [10, 11], [6, 7], [5, 4], [11, 11], [7, 6], [10, 8], [9, 7], [5, 8], [2, 5], [3, 6], [3, 1], [5, 2], [4, 2], [5, 7], [10, 2], [1, 8], [6, 6], [4, 11], [7, 4]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [01:01<01:01,  6.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "hbi [[0, 11], [1, 4], [11, 9], [10, 11], [5, 2], [1, 11], [6, 9], [4, 9], [9, 2], [6, 3], [5, 6], [11, 1], [0, 4], [0, 9], [9, 3], [9, 9], [0, 1], [5, 10], [8, 1], [11, 10], [11, 11], [7, 10], [5, 9], [7, 5], [6, 6], [10, 6], [11, 6], [1, 8], [11, 7], [7, 1], [6, 2], [10, 0], [9, 8], [5, 0], [9, 6], [1, 9], [2, 8], [1, 3], [0, 6], [3, 3], [10, 9], [9, 7], [0, 10], [11, 0], [2, 3], [3, 7], [7, 8], [3, 1], [4, 10], [11, 8], [1, 6], [6, 10], [5, 4], [4, 2], [4, 11], [3, 0], [0, 3], [1, 2], [3, 6], [0, 7], [7, 4], [1, 5], [10, 3], [9, 11], [2, 11], [6, 5], [2, 7], [2, 10], [6, 4], [5, 3], [10, 2], [9, 4], [5, 11], [7, 2], [0, 0], [11, 4], [4, 7], [11, 5], [4, 5], [7, 0], [10, 5], [2, 6], [3, 10], [5, 7], [0, 5], [5, 1], [3, 9], [10, 7], [9, 5], [4, 4], [2, 2], [0, 8], [6, 11], [4, 0], [9, 0], [7, 3], [1, 0], [2, 0], [8, 5], [8, 4], [8, 6], [10, 1], [6, 8], [8, 11], [11, 3], [3, 4], [8, 7], [11, 2], [1, 7], [3, 2], [4, 8], [7, 7], [2, 5], [4, 3], [10, 4], [4, 1], [3, 8], [4, 6], [8, 3], [2, 1], [7, 11], [10, 8], [6, 7], [8, 10], [5, 8], [3, 5], [8, 0], [10, 10], [7, 9], [1, 10], [7, 6], [8, 8], [5, 5], [8, 9], [2, 4], [2, 9], [6, 0], [9, 10], [3, 11], [9, 1], [0, 2], [8, 2], [6, 1], [1, 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [01:07<00:54,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "hbi [[7, 2], [8, 10], [6, 2], [7, 6], [10, 4], [0, 0], [8, 3], [8, 4], [8, 9], [9, 3], [3, 9], [1, 10], [6, 9], [7, 4], [6, 10], [8, 6], [2, 9], [8, 1], [7, 0], [0, 1], [0, 9], [11, 6], [8, 2], [6, 5], [4, 5], [3, 0], [7, 3], [2, 10], [9, 10], [11, 3], [9, 6], [6, 7], [10, 11], [1, 9], [9, 1], [11, 2], [2, 4], [5, 10], [10, 7], [11, 11], [5, 9], [5, 2], [5, 11], [10, 9], [1, 2], [5, 8], [7, 5], [11, 9], [10, 1], [7, 11], [10, 2], [9, 4], [8, 8], [5, 6], [11, 5], [7, 7], [4, 2], [0, 7], [9, 5], [1, 8], [0, 10], [9, 0], [6, 3], [11, 4], [4, 11], [4, 8], [8, 0], [4, 0], [4, 3], [0, 5], [0, 2], [2, 1], [6, 0], [2, 0], [0, 8], [10, 0], [11, 10], [8, 11], [11, 8], [5, 1], [1, 4], [5, 4], [10, 6], [7, 10], [3, 8], [1, 3], [2, 6], [6, 1], [0, 6], [0, 11], [5, 3], [6, 11], [7, 9], [10, 8], [3, 1], [4, 4], [9, 9], [5, 7], [10, 10], [2, 3], [5, 5], [4, 9], [1, 11], [11, 0], [9, 11], [3, 2], [2, 5], [1, 0], [0, 4], [1, 7], [2, 7], [2, 8], [3, 7], [6, 6], [3, 4], [6, 4], [2, 11], [8, 5], [6, 8], [4, 1], [3, 3], [3, 6], [7, 8], [0, 3], [1, 1], [5, 0], [11, 7], [4, 7], [1, 6], [9, 8], [3, 5], [4, 6], [11, 1], [10, 3], [1, 5], [9, 2], [10, 5], [8, 7], [7, 1], [2, 2], [4, 10], [9, 7], [3, 11], [3, 10]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [01:13<00:48,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "hbi [[9, 1], [5, 6], [11, 5], [8, 1], [6, 2], [8, 6], [0, 4], [10, 3], [4, 5], [7, 2], [11, 2], [9, 4], [3, 6], [10, 7], [2, 1], [2, 3], [7, 0], [3, 10], [10, 5], [1, 11], [11, 0], [3, 0], [10, 1], [6, 9], [0, 6], [2, 10], [4, 3], [5, 0], [4, 7], [7, 6], [3, 8], [9, 9], [9, 0], [2, 2], [0, 7], [5, 3], [4, 9], [4, 1], [2, 5], [2, 0], [1, 4], [2, 4], [8, 3], [11, 11], [9, 5], [0, 0], [0, 1], [5, 2], [7, 9], [5, 9], [11, 4], [6, 3], [3, 7], [1, 6], [8, 8], [1, 2], [5, 10], [0, 2], [10, 4], [1, 5], [10, 8], [1, 8], [7, 1], [4, 4], [7, 10], [10, 9], [4, 6], [10, 2], [10, 11], [8, 10], [9, 8], [4, 2], [7, 3], [5, 11], [11, 6], [5, 1], [6, 5], [3, 1], [6, 8], [0, 8], [11, 3], [10, 10], [0, 5], [7, 8], [8, 11], [0, 11], [1, 7], [3, 4], [10, 6], [1, 9], [11, 8], [9, 6], [2, 9], [5, 5], [7, 4], [6, 1], [6, 6], [3, 5], [8, 5], [6, 11], [10, 0], [6, 7], [9, 3], [4, 0], [3, 11], [8, 7], [0, 9], [1, 0], [8, 4], [4, 10], [4, 11], [6, 0], [11, 1], [9, 2], [8, 0], [2, 11], [2, 6], [2, 8], [5, 7], [8, 9], [11, 9], [5, 8], [0, 3], [1, 3], [6, 4], [7, 5], [8, 2], [3, 2], [3, 3], [1, 10], [2, 7], [6, 10], [11, 10], [9, 11], [4, 8], [0, 10], [9, 7], [5, 4], [1, 1], [3, 9], [7, 11], [7, 7], [9, 10], [11, 7]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [01:19<00:41,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "hbi [[1, 9], [8, 2], [7, 10], [9, 9], [10, 5], [2, 0], [11, 11], [3, 10], [5, 7], [8, 6], [6, 5], [6, 0], [11, 2], [1, 3], [8, 4], [9, 6], [0, 3], [5, 2], [9, 10], [1, 6], [10, 11], [11, 6], [10, 3], [4, 3], [10, 4], [8, 8], [4, 5], [7, 2], [11, 7], [5, 6], [0, 0], [9, 5], [5, 9], [1, 5], [2, 7], [11, 1], [4, 0], [8, 1], [0, 6], [10, 6], [0, 10], [6, 9], [7, 1], [11, 0], [3, 9], [6, 11], [7, 4], [6, 8], [4, 1], [2, 5], [6, 10], [8, 3], [2, 2], [0, 4], [11, 5], [11, 9], [9, 1], [11, 3], [2, 8], [11, 4], [0, 2], [4, 6], [2, 11], [0, 5], [6, 3], [7, 3], [9, 4], [7, 11], [11, 8], [4, 2], [8, 5], [7, 6], [2, 6], [1, 0], [5, 5], [5, 8], [3, 11], [6, 4], [3, 8], [4, 9], [8, 0], [3, 1], [3, 5], [2, 4], [5, 3], [9, 3], [3, 0], [0, 9], [0, 1], [9, 8], [3, 2], [4, 10], [8, 9], [9, 2], [1, 1], [5, 11], [4, 8], [11, 10], [5, 10], [1, 11], [10, 0], [3, 3], [8, 11], [6, 6], [6, 7], [9, 7], [5, 0], [4, 4], [10, 7], [7, 8], [3, 4], [0, 11], [7, 7], [1, 4], [5, 4], [3, 6], [1, 2], [2, 1], [10, 8], [6, 2], [9, 0], [7, 0], [10, 2], [4, 11], [1, 10], [1, 8], [3, 7], [0, 8], [2, 3], [9, 11], [7, 9], [8, 7], [7, 5], [2, 10], [1, 7], [4, 7], [2, 9], [6, 1], [5, 1], [10, 10], [10, 1], [8, 10], [0, 7], [10, 9]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [01:25<00:35,  5.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "hbi [[9, 0], [9, 6], [7, 4], [11, 8], [9, 4], [10, 0], [9, 5], [8, 8], [8, 4], [0, 2], [6, 10], [7, 7], [3, 7], [5, 9], [8, 2], [8, 0], [9, 7], [2, 4], [0, 8], [10, 2], [4, 7], [8, 3], [6, 11], [3, 5], [6, 4], [2, 3], [4, 8], [2, 10], [1, 7], [3, 0], [10, 1], [5, 11], [7, 9], [10, 7], [2, 0], [5, 3], [10, 4], [6, 2], [11, 9], [4, 3], [4, 2], [9, 11], [4, 11], [7, 2], [3, 4], [0, 10], [4, 1], [7, 8], [2, 7], [8, 6], [1, 8], [9, 10], [0, 0], [2, 11], [11, 7], [3, 6], [3, 1], [11, 6], [10, 11], [2, 5], [0, 1], [7, 10], [0, 3], [5, 1], [1, 5], [5, 6], [4, 9], [6, 9], [0, 6], [2, 2], [3, 8], [7, 3], [3, 3], [11, 1], [0, 7], [5, 8], [6, 8], [5, 10], [10, 3], [4, 0], [8, 11], [11, 4], [4, 4], [1, 10], [10, 5], [6, 7], [0, 5], [11, 3], [4, 6], [0, 11], [7, 5], [11, 0], [11, 5], [8, 5], [9, 9], [10, 6], [5, 2], [6, 5], [8, 10], [5, 5], [1, 1], [10, 8], [8, 9], [3, 9], [7, 1], [1, 4], [11, 10], [6, 1], [2, 6], [1, 2], [6, 3], [1, 3], [2, 9], [8, 7], [1, 0], [1, 11], [5, 4], [3, 10], [4, 10], [5, 7], [8, 1], [3, 11], [7, 11], [1, 6], [9, 8], [10, 10], [10, 9], [9, 1], [11, 11], [1, 9], [7, 6], [9, 2], [6, 6], [3, 2], [0, 4], [7, 0], [9, 3], [6, 0], [2, 8], [2, 1], [11, 2], [0, 9], [4, 5], [5, 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [01:30<00:29,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "hbi [[2, 1], [2, 6], [7, 5], [9, 10], [3, 1], [6, 11], [5, 0], [3, 9], [11, 4], [4, 1], [9, 11], [2, 0], [5, 2], [4, 4], [6, 6], [4, 6], [9, 8], [5, 6], [5, 3], [8, 10], [10, 5], [7, 1], [6, 4], [11, 7], [7, 6], [10, 9], [3, 5], [5, 5], [10, 10], [5, 1], [8, 7], [0, 5], [0, 6], [6, 0], [2, 4], [7, 10], [6, 7], [11, 1], [5, 10], [9, 3], [1, 11], [11, 2], [4, 10], [5, 7], [7, 3], [10, 1], [9, 6], [8, 9], [7, 8], [9, 7], [9, 0], [3, 10], [10, 7], [7, 2], [5, 4], [4, 11], [6, 10], [1, 8], [7, 11], [2, 10], [0, 11], [1, 6], [10, 2], [4, 7], [6, 8], [3, 0], [1, 4], [9, 1], [4, 5], [7, 0], [11, 10], [0, 0], [8, 6], [8, 1], [10, 6], [4, 9], [3, 7], [8, 8], [7, 7], [10, 3], [0, 3], [11, 6], [8, 2], [10, 4], [8, 5], [6, 5], [2, 11], [3, 3], [5, 11], [1, 0], [6, 2], [4, 8], [2, 2], [2, 7], [0, 1], [2, 9], [1, 5], [1, 10], [11, 8], [4, 0], [3, 8], [9, 2], [4, 2], [2, 5], [11, 9], [8, 11], [8, 0], [6, 3], [9, 5], [10, 11], [0, 4], [2, 8], [7, 4], [6, 1], [2, 3], [5, 8], [8, 4], [6, 9], [1, 2], [1, 1], [1, 9], [11, 0], [7, 9], [11, 5], [5, 9], [10, 0], [3, 2], [1, 3], [10, 8], [3, 6], [1, 7], [4, 3], [8, 3], [0, 8], [3, 11], [9, 9], [0, 10], [0, 7], [9, 4], [3, 4], [0, 2], [0, 9], [11, 3], [11, 11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [01:37<00:24,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "hbi [[7, 0], [3, 7], [3, 1], [8, 9], [10, 3], [11, 4], [7, 9], [9, 6], [3, 2], [10, 4], [10, 9], [2, 9], [2, 6], [9, 3], [9, 4], [5, 6], [8, 7], [0, 9], [2, 0], [4, 3], [10, 8], [0, 3], [1, 1], [6, 6], [9, 5], [7, 6], [11, 7], [10, 11], [11, 6], [10, 5], [2, 5], [3, 4], [11, 3], [6, 0], [0, 4], [2, 1], [10, 7], [10, 0], [3, 3], [6, 2], [1, 6], [6, 11], [1, 11], [1, 7], [1, 8], [2, 11], [6, 1], [1, 9], [7, 7], [4, 5], [10, 2], [1, 2], [6, 3], [6, 4], [10, 6], [4, 4], [3, 6], [8, 4], [4, 2], [0, 7], [11, 5], [9, 0], [5, 1], [5, 2], [1, 4], [8, 3], [0, 2], [8, 11], [3, 10], [8, 10], [5, 11], [2, 3], [9, 9], [3, 9], [11, 10], [2, 8], [7, 2], [5, 4], [0, 0], [9, 7], [8, 2], [11, 0], [7, 10], [2, 7], [6, 7], [11, 9], [11, 8], [3, 5], [8, 1], [1, 0], [0, 11], [5, 10], [8, 8], [5, 5], [0, 6], [9, 11], [2, 4], [1, 5], [6, 8], [7, 1], [8, 5], [8, 0], [0, 8], [7, 4], [7, 11], [4, 8], [6, 10], [5, 3], [7, 8], [2, 2], [7, 3], [9, 1], [0, 1], [4, 6], [11, 2], [3, 0], [4, 9], [1, 3], [9, 2], [5, 7], [2, 10], [5, 0], [3, 11], [5, 8], [4, 0], [1, 10], [4, 11], [10, 10], [4, 1], [3, 8], [4, 7], [0, 5], [9, 8], [6, 9], [9, 10], [5, 9], [6, 5], [4, 10], [11, 11], [0, 10], [8, 6], [10, 1], [7, 5], [11, 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [01:43<00:18,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "hbi [[3, 8], [10, 8], [9, 5], [3, 11], [1, 6], [11, 5], [7, 9], [4, 0], [7, 6], [2, 2], [8, 4], [9, 1], [8, 10], [9, 11], [8, 8], [9, 9], [5, 9], [9, 4], [9, 2], [11, 7], [10, 1], [1, 1], [7, 3], [9, 10], [4, 5], [2, 6], [5, 2], [1, 5], [10, 10], [8, 5], [6, 4], [0, 11], [2, 10], [10, 11], [4, 2], [10, 2], [4, 11], [4, 3], [2, 4], [6, 10], [10, 0], [5, 6], [1, 2], [3, 2], [4, 7], [5, 11], [1, 11], [9, 0], [8, 2], [5, 7], [10, 6], [6, 1], [8, 0], [8, 6], [2, 0], [1, 4], [4, 4], [0, 5], [3, 10], [9, 7], [1, 10], [3, 9], [0, 2], [11, 10], [11, 3], [6, 2], [4, 1], [0, 1], [0, 10], [7, 11], [2, 5], [10, 4], [7, 1], [6, 9], [10, 9], [5, 3], [4, 8], [3, 3], [0, 6], [6, 5], [1, 8], [3, 1], [2, 7], [7, 4], [3, 4], [9, 8], [8, 1], [9, 6], [10, 3], [5, 1], [8, 3], [8, 11], [7, 10], [6, 6], [8, 7], [2, 8], [0, 9], [5, 4], [3, 5], [11, 2], [4, 6], [5, 5], [7, 7], [1, 7], [3, 7], [5, 10], [2, 11], [11, 4], [7, 5], [2, 9], [11, 11], [7, 0], [3, 0], [10, 5], [11, 8], [9, 3], [3, 6], [6, 11], [1, 3], [6, 7], [8, 9], [1, 0], [4, 10], [2, 3], [11, 6], [0, 7], [0, 0], [7, 2], [0, 8], [1, 9], [0, 4], [6, 0], [6, 8], [7, 8], [11, 0], [5, 0], [2, 1], [5, 8], [6, 3], [0, 3], [11, 1], [4, 9], [10, 7], [11, 9]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [01:49<00:11,  5.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "hbi [[4, 8], [8, 5], [0, 8], [4, 4], [5, 9], [2, 6], [2, 5], [9, 5], [7, 3], [6, 0], [5, 3], [7, 5], [8, 7], [2, 3], [4, 0], [5, 7], [9, 0], [9, 9], [3, 7], [2, 2], [7, 11], [0, 0], [7, 6], [8, 11], [4, 10], [8, 8], [2, 11], [1, 11], [0, 3], [1, 0], [7, 4], [2, 10], [5, 2], [10, 4], [9, 3], [7, 7], [7, 0], [1, 9], [10, 11], [4, 3], [6, 7], [9, 11], [8, 2], [11, 11], [0, 6], [0, 4], [4, 2], [11, 1], [2, 0], [3, 3], [5, 8], [0, 5], [2, 7], [10, 3], [3, 9], [7, 1], [4, 5], [4, 9], [5, 6], [11, 5], [1, 10], [0, 2], [2, 9], [6, 6], [11, 8], [7, 9], [10, 7], [3, 11], [10, 2], [11, 10], [0, 7], [1, 3], [9, 4], [10, 8], [9, 1], [6, 1], [3, 4], [3, 5], [0, 9], [2, 4], [3, 2], [5, 1], [11, 4], [11, 9], [8, 9], [6, 3], [8, 10], [0, 1], [10, 5], [8, 6], [9, 6], [10, 9], [5, 10], [3, 10], [2, 1], [6, 8], [3, 0], [4, 11], [9, 8], [1, 4], [5, 4], [5, 0], [11, 0], [0, 10], [6, 5], [1, 8], [4, 7], [10, 10], [9, 10], [6, 10], [1, 6], [6, 4], [6, 2], [3, 6], [1, 7], [3, 8], [6, 9], [10, 0], [4, 6], [3, 1], [7, 2], [5, 5], [8, 3], [1, 2], [9, 2], [8, 4], [7, 10], [11, 6], [9, 7], [5, 11], [10, 6], [4, 1], [11, 2], [8, 1], [11, 7], [7, 8], [0, 11], [2, 8], [6, 11], [11, 3], [8, 0], [10, 1], [1, 5], [1, 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [01:55<00:05,  5.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "torch.Size([20, 50257]) torch.Size([20, 2])\n",
      "hbi [[1, 10], [6, 3], [0, 8], [9, 10], [4, 5], [7, 9], [6, 4], [2, 6], [8, 3], [4, 4], [10, 5], [11, 10], [5, 6], [1, 7], [10, 1], [1, 0], [1, 2], [9, 4], [4, 1], [5, 0], [0, 5], [8, 7], [0, 3], [6, 5], [4, 10], [11, 7], [10, 0], [9, 1], [0, 7], [9, 8], [2, 5], [9, 9], [10, 8], [4, 8], [10, 4], [2, 1], [8, 9], [0, 10], [8, 1], [1, 4], [7, 0], [1, 6], [5, 2], [8, 5], [3, 7], [0, 4], [8, 10], [6, 1], [10, 7], [2, 2], [4, 0], [1, 8], [0, 6], [7, 4], [6, 0], [6, 8], [4, 6], [1, 3], [4, 3], [4, 9], [11, 6], [2, 7], [9, 6], [8, 8], [3, 5], [7, 1], [6, 10], [11, 2], [0, 1], [11, 3], [5, 10], [5, 1], [2, 4], [8, 0], [7, 3], [7, 7], [5, 5], [9, 0], [1, 5], [7, 2], [5, 9], [11, 11], [2, 9], [0, 9], [9, 7], [2, 8], [5, 11], [11, 1], [7, 10], [2, 0], [9, 11], [6, 11], [2, 11], [11, 4], [10, 9], [7, 11], [7, 6], [0, 2], [5, 4], [5, 3], [4, 2], [10, 11], [3, 0], [3, 6], [3, 9], [8, 4], [3, 11], [8, 6], [1, 1], [0, 0], [10, 6], [9, 3], [10, 10], [6, 9], [1, 11], [3, 1], [3, 2], [3, 10], [4, 11], [11, 5], [10, 3], [1, 9], [8, 11], [9, 2], [7, 8], [2, 3], [10, 2], [6, 6], [2, 10], [3, 8], [4, 7], [0, 11], [11, 8], [6, 7], [5, 7], [8, 2], [9, 5], [3, 3], [11, 9], [3, 4], [5, 8], [11, 0], [6, 2], [7, 5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:01<00:00,  6.07s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# a = task_eval.get_attn_head_freqs_over_dataset(N=N, return_freqs=True)\n",
    "\n",
    "# %%\n",
    "ground = task_eval.get_faithfulness_curve_over_data(N=20, attn_head_freq_n=10, faithfulness_intervals=30, rand=False, ioi_ground=True, task='ioi')\n",
    "base = task_eval.get_faithfulness_curve_over_data(N=20, attn_head_freq_n=10, faithfulness_intervals=30, rand=False, ioi_ground=False, task='ioi')\n",
    "\n",
    "radd = []\n",
    "for _ in trange(20):\n",
    "    radd.append(task_eval.get_faithfulness_curve_over_data(N=20, attn_head_freq_n=10, faithfulness_intervals=30, rand=True, ioi_ground=False, visualize=False))\n",
    "\n",
    "\n",
    "# %%\n",
    "big_rad = {}\n",
    "for rad in radd:\n",
    "    for k, v in rad.items():\n",
    "        if k not in big_rad:\n",
    "            big_rad[k] = 0\n",
    "        big_rad[k] += v\n",
    "\n",
    "for k in big_rad:\n",
    "    big_rad[k] /= 20\n",
    "\n",
    "rad = big_rad\n",
    "\n",
    "# %%\n",
    "plt.plot([float(k) for k in ground.keys()], ground.values(), label=\"Ground Truth\")\n",
    "plt.plot([float(k) for k in rad.keys()], base.values(), label=\"Circuit Discovery\")\n",
    "plt.plot([float(k) for k in base.keys()], rad.values(), label=\"Random\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.grid(color='gray', linestyle='--', linewidth=0.2)\n",
    "plt.title(\"IOI Faithfulness (Mean Ablation)\")\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.margins(0)\n",
    "plt.ylabel(\"Normalized KL\")\n",
    "plt.xlabel(\"# Heads\")\n",
    "# ax.spines['left'].set_visible(False)\n",
    "# ax.spines['bottom'].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "blue",
          "width": 2
         },
         "marker": {
          "color": "blue",
          "size": 8,
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "Ground Truth",
         "type": "scatter",
         "x": [
          0,
          4,
          8,
          12,
          16,
          20,
          24,
          28,
          32,
          36,
          40,
          44,
          48,
          52,
          56,
          60,
          64,
          68,
          72,
          76,
          80,
          84,
          88,
          92,
          96,
          100,
          104,
          108,
          112,
          116,
          120,
          124,
          128,
          132,
          136,
          140,
          144
         ],
         "y": [
          0,
          0.21186257898807526,
          0.5489739179611206,
          0.8727449774742126,
          0.6796296834945679,
          0.8599653244018555,
          0.9136337637901306,
          0.9623374342918396,
          0.9627640247344971,
          0.9671616554260254,
          0.9698102474212646,
          0.9698017835617065,
          0.9670000076293945,
          0.9668703079223633,
          0.9661858081817627,
          0.9729059934616089,
          0.9796709418296814,
          0.9797811508178711,
          0.9813811779022217,
          0.982769250869751,
          0.9864718914031982,
          0.9852297902107239,
          0.9863163828849792,
          0.9903882741928101,
          0.9909783005714417,
          0.9914416670799255,
          0.9912298917770386,
          0.9917020201683044,
          0.9918546676635742,
          0.9914759993553162,
          0.9948742985725403,
          0.9956631064414978,
          0.9954479336738586,
          0.997222900390625,
          0.9982313513755798,
          0.9993125796318054,
          1
         ]
        },
        {
         "line": {
          "color": "red",
          "width": 2
         },
         "marker": {
          "color": "red",
          "size": 8,
          "symbol": "square"
         },
         "mode": "lines+markers",
         "name": "Circuit Discovery",
         "type": "scatter",
         "x": [
          0,
          4,
          8,
          12,
          16,
          20,
          24,
          28,
          32,
          36,
          40,
          44,
          48,
          52,
          56,
          60,
          64,
          68,
          72,
          76,
          80,
          84,
          88,
          92,
          96,
          100,
          104,
          108,
          112,
          116,
          120,
          124,
          128,
          132,
          136,
          140,
          144
         ],
         "y": [
          0,
          0.07476472854614258,
          0.08381564915180206,
          0.11193161457777023,
          0.3168685734272003,
          0.31970757246017456,
          0.31903788447380066,
          0.4926495850086212,
          0.5997485518455505,
          0.8657242655754089,
          0.8672425746917725,
          0.9254310131072998,
          0.9289693236351013,
          0.9442175626754761,
          0.941994309425354,
          0.9590809345245361,
          0.9593459963798523,
          0.9118312001228333,
          0.9046187996864319,
          0.9500923752784729,
          0.9492096900939941,
          0.9481399059295654,
          0.9660481214523315,
          0.9657186269760132,
          0.9551959037780762,
          0.9783065319061279,
          0.9865961670875549,
          0.9958215355873108,
          0.9953812956809998,
          0.9955219626426697,
          0.9942097067832947,
          0.9976003170013428,
          0.9989522099494934,
          0.9991394877433777,
          0.9990469813346863,
          0.9993738532066345,
          1
         ]
        },
        {
         "line": {
          "color": "green",
          "width": 2
         },
         "marker": {
          "color": "green",
          "size": 8,
          "symbol": "triangle-up"
         },
         "mode": "lines+markers",
         "name": "Random",
         "type": "scatter",
         "x": [
          0,
          4,
          8,
          12,
          16,
          20,
          24,
          28,
          32,
          36,
          40,
          44,
          48,
          52,
          56,
          60,
          64,
          68,
          72,
          76,
          80,
          84,
          88,
          92,
          96,
          100,
          104,
          108,
          112,
          116,
          120,
          124,
          128,
          132,
          136,
          140,
          144
         ],
         "y": [
          0,
          0.020432655507465824,
          0.058388034434756264,
          0.1018543844926171,
          0.17063466772087849,
          0.25763054041308353,
          0.286436257744208,
          0.3571845702826977,
          0.44261234253644943,
          0.5007993467152119,
          0.5445549473166466,
          0.582907659560442,
          0.6256546720862388,
          0.6653543844819069,
          0.6773890137672425,
          0.7045949906110763,
          0.7321155056357384,
          0.7482847839593887,
          0.7753148406744004,
          0.8070685297250748,
          0.8136045530438423,
          0.8364524334669113,
          0.850072817504406,
          0.8604228854179382,
          0.8758532166481018,
          0.8852175593376159,
          0.894993132352829,
          0.9104346632957458,
          0.9122334241867065,
          0.9272860318422318,
          0.9423514574766159,
          0.9538587898015976,
          0.9623119473457337,
          0.9681534916162491,
          0.9782587945461273,
          0.987187796831131,
          1
         ]
        }
       ],
       "layout": {
        "font": {
         "size": 14
        },
        "height": 600,
        "hovermode": "x",
        "legend": {
         "bgcolor": "rgba(255, 255, 255, 0.8)",
         "bordercolor": "black",
         "borderwidth": 1,
         "x": 0.7,
         "y": 0.9
        },
        "plot_bgcolor": "white",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "IOI Faithfulness (Mean Ablation)"
        },
        "width": 800,
        "xaxis": {
         "linecolor": "black",
         "linewidth": 1,
         "mirror": true,
         "showgrid": false,
         "showline": true,
         "title": {
          "text": "# Heads"
         },
         "zeroline": false
        },
        "yaxis": {
         "linecolor": "black",
         "linewidth": 1,
         "mirror": true,
         "showgrid": false,
         "showline": true,
         "title": {
          "text": "Normalized KL"
         },
         "zeroline": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=list(ground.keys()), y=list(ground.values()),\n",
    "                         mode='lines+markers',\n",
    "                         name='Ground Truth',\n",
    "                         line=dict(color='blue', width=2),\n",
    "                         marker=dict(size=8, symbol='circle', color='blue')))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=list(rad.keys()), y=list(base.values()),\n",
    "                         mode='lines+markers',\n",
    "                         name='Circuit Discovery',\n",
    "                         line=dict(color='red', width=2),\n",
    "                         marker=dict(size=8, symbol='square', color='red')))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=list(base.keys()), y=list(rad.values()),\n",
    "                         mode='lines+markers',\n",
    "                         name='Random',\n",
    "                         line=dict(color='green', width=2),\n",
    "                         marker=dict(size=8, symbol='triangle-up', color='green')))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='IOI Faithfulness (Mean Ablation)',\n",
    "    xaxis=dict(title='# Heads', showgrid=False, zeroline=False, showline=True, linewidth=1, linecolor='black', mirror=True),\n",
    "    yaxis=dict(title='Normalized KL', showgrid=False, zeroline=False, showline=True, linewidth=1, linecolor='black', mirror=True),\n",
    "    font=dict(size=14),\n",
    "    template='plotly_white',\n",
    "    width=800,\n",
    "    height=600,\n",
    "    legend=dict(x=0.7, y=0.9, borderwidth=1, bordercolor='black', bgcolor='rgba(255, 255, 255, 0.8)'),\n",
    "    plot_bgcolor='white',\n",
    "    hovermode='x'\n",
    ")\n",
    "\n",
    "# fig.update_xaxes(tickvals=list(ground.keys()))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "torch.Size([100, 13]) torch.Size([100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:45<00:00,  1.66s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "Head: %{x}<br>Layer: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "xaxis": "x",
         "yaxis": "y",
         "z": [
          [
           0,
           0.93,
           0,
           0.26,
           0.1,
           0.57,
           0.43,
           0.01,
           0,
           0,
           0,
           0
          ],
          [
           0.36,
           0,
           0,
           0,
           0,
           0.03,
           0.02,
           0.04,
           0,
           0.1,
           0.57,
           0.02
          ],
          [
           0.08,
           0,
           0.03,
           0,
           0.04,
           0.01,
           0,
           0,
           0,
           0.04,
           0,
           0
          ],
          [
           0,
           0,
           0.01,
           0.44,
           0,
           0,
           0.03,
           0.06,
           0,
           0.01,
           0,
           0
          ],
          [
           0,
           0.01,
           0,
           0,
           0,
           0.07,
           0,
           0.04,
           0,
           0.01,
           0,
           0.09
          ],
          [
           0.02,
           0.17,
           0.03,
           0,
           0,
           0.32,
           0.04,
           0.16,
           0.01,
           0.05,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0.15,
           0.01,
           0,
           0,
           0,
           0.03,
           0,
           0.12
          ],
          [
           0,
           0,
           0,
           0,
           0.04,
           0,
           0,
           0.11,
           0.01,
           0,
           0.21,
           0.01
          ],
          [
           0,
           0.02,
           0,
           0,
           0,
           0.02,
           0.08,
           0.09,
           0.07,
           0,
           0,
           0.05
          ],
          [
           0,
           0.17,
           0,
           0.02,
           0.02,
           0.02,
           0.06,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0.01,
           0.01,
           0,
           0,
           0,
           0,
           0.37,
           0,
           0,
           0,
           0.45
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0.01,
           0.01,
           0,
           0,
           0
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "cmid": 0,
         "colorscale": [
          [
           0,
           "rgb(103,0,31)"
          ],
          [
           0.1,
           "rgb(178,24,43)"
          ],
          [
           0.2,
           "rgb(214,96,77)"
          ],
          [
           0.3,
           "rgb(244,165,130)"
          ],
          [
           0.4,
           "rgb(253,219,199)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(209,229,240)"
          ],
          [
           0.7,
           "rgb(146,197,222)"
          ],
          [
           0.8,
           "rgb(67,147,195)"
          ],
          [
           0.9,
           "rgb(33,102,172)"
          ],
          [
           1,
           "rgb(5,48,97)"
          ]
         ]
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Attn Head Freqs for Strategy + Task "
        },
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y",
         "title": {
          "text": "Head"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Layer"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# %%\n",
    "import torch\n",
    "import time\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from task_evaluation import TaskEvaluation\n",
    "from data.ioi_dataset import gen_templated_prompts\n",
    "from data.greater_than_dataset import generate_greater_than_dataset\n",
    "from circuit_discovery import CircuitDiscovery, only_feature\n",
    "from circuit_lens import CircuitComponent\n",
    "from plotly_utils import *\n",
    "from data.ioi_dataset import IOI_GROUND_TRUTH_HEADS\n",
    "from data.greater_than_dataset import GT_GROUND_TRUTH_HEADS\n",
    "from memory import get_gpu_memory\n",
    "from sklearn import metrics\n",
    "from tqdm import trange\n",
    "\n",
    "from utils import get_attn_head_roc\n",
    "\n",
    "\n",
    "# %%\n",
    "torch.set_grad_enabled(False)\n",
    "# %%\n",
    "\n",
    "\n",
    "#dataset_prompts = gen_templated_prompts(template_idex=1, N=500)\n",
    "dataset_prompts = generate_greater_than_dataset(N=100)\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "def component_filter(component: str):\n",
    "    return component in [\n",
    "        CircuitComponent.Z_FEATURE,\n",
    "        CircuitComponent.MLP_FEATURE,\n",
    "        CircuitComponent.ATTN_HEAD,\n",
    "        CircuitComponent.UNEMBED,\n",
    "        # CircuitComponent.UNEMBED_AT_TOKEN,\n",
    "        CircuitComponent.EMBED,\n",
    "        CircuitComponent.POS_EMBED,\n",
    "        # CircuitComponent.BIAS_O,\n",
    "        CircuitComponent.Z_SAE_ERROR,\n",
    "        # CircuitComponent.Z_SAE_BIAS,\n",
    "        # CircuitComponent.TRANSCODER_ERROR,\n",
    "        # CircuitComponent.TRANSCODER_BIAS,\n",
    "    ]\n",
    "\n",
    "\n",
    "pass_based = True\n",
    "\n",
    "passes = 5\n",
    "node_contributors = 1\n",
    "first_pass_minimal = True\n",
    "\n",
    "sub_passes = 3\n",
    "do_sub_pass = False\n",
    "layer_thres = 9\n",
    "minimal = True\n",
    "\n",
    "\n",
    "num_greedy_passes = 20\n",
    "k = 1\n",
    "N = 30\n",
    "\n",
    "thres = 4\n",
    "\n",
    "def strategy(cd: CircuitDiscovery):\n",
    "    if pass_based:\n",
    "        for _ in range(passes):\n",
    "            cd.add_greedy_pass(contributors_per_node=node_contributors, minimal=first_pass_minimal)\n",
    "\n",
    "            if do_sub_pass:\n",
    "                for _ in range(sub_passes):\n",
    "                    cd.add_greedy_pass_against_all_existing_nodes(contributors_per_node=node_contributors, skip_z_features=True, layer_threshold=layer_thres, minimal=minimal)\n",
    "    else:\n",
    "        for _ in range(num_greedy_passes):\n",
    "            cd.greedily_add_top_contributors(k=k, reciever_threshold=thres)\n",
    "\n",
    "\n",
    "\n",
    "task_eval = TaskEvaluation(prompts=dataset_prompts, circuit_discovery_strategy=strategy, allowed_components_filter=component_filter)\n",
    "\n",
    "cd = task_eval.get_circuit_discovery_for_prompt(20)\n",
    "# f = task_eval.get_features_at_heads_over_dataset(N=30)\n",
    "N = 100\n",
    "\n",
    "attn_freqs = task_eval.get_attn_head_freqs_over_dataset(N=N, subtract_counter_factuals=False, return_freqs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def get_attn_head_roc(ground_truth, data, task_name, visualize=True, additional_title=\"\"):\n",
    "    fp, tp, thresh = metrics.roc_curve(ground_truth.flatten(), data.flatten())\n",
    "    score = metrics.roc_auc_score(ground_truth.flatten(), data.flatten())\n",
    "\n",
    "    if visualize:\n",
    "        print(\"Score:\", score)\n",
    "\n",
    "        # Create the ROC curve with flat lines and vertical lines\n",
    "        x_coords = []\n",
    "        y_coords = []\n",
    "\n",
    "        for i in range(len(fp)):\n",
    "            x_coords.append(fp[i])\n",
    "            y_coords.append(tp[i])\n",
    "\n",
    "            if i < len(fp) - 1:\n",
    "                x_coords.append(fp[i])\n",
    "                y_coords.append(tp[i+1])\n",
    "                x_coords.append(fp[i+1])\n",
    "                y_coords.append(tp[i+1])\n",
    "\n",
    "        fig = go.Figure()\n",
    "\n",
    "        fig.add_trace(go.Scatter(x=x_coords, y=y_coords,\n",
    "                                 mode='lines',\n",
    "                                 name='ROC Curve',\n",
    "                                 line=dict(color='blue', width=2)))\n",
    "\n",
    "        fig.add_shape(type='line',\n",
    "                      x0=0, y0=0, x1=1, y1=1,\n",
    "                      line=dict(color='red', width=2, dash='dash'),\n",
    "                      name='Random Guess')\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=f\"ROC Curve for {task_name} \" + additional_title,\n",
    "            xaxis=dict(title='False Positive Rate', showgrid=False, zeroline=False),\n",
    "            yaxis=dict(title='True Positive Rate', showgrid=False, zeroline=False),\n",
    "            font=dict(size=14),\n",
    "            template='plotly_white',\n",
    "            width=600,\n",
    "            height=600,\n",
    "            legend=dict(x=0.7, y=0.2, borderwidth=1, bordercolor='black', bgcolor='rgba(255, 255, 255, 0.8)'),\n",
    "            plot_bgcolor='white',\n",
    "            hovermode='closest'\n",
    "        )\n",
    "\n",
    "        fig.update_xaxes(range=[0, 1.01])\n",
    "        fig.update_yaxes(range=[0, 1.01])\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "    return score, fp, tp, thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8592592592592592\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "blue",
          "width": 2
         },
         "mode": "lines",
         "name": "ROC Curve",
         "type": "scatter",
         "x": [
          0,
          0,
          0,
          0,
          0,
          0.007407407407407408,
          0.007407407407407408,
          0.007407407407407408,
          0.044444444444444446,
          0.044444444444444446,
          0.044444444444444446,
          0.044444444444444446,
          0.044444444444444446,
          0.044444444444444446,
          0.05185185185185185,
          0.05185185185185185,
          0.05185185185185185,
          0.08148148148148149,
          0.08148148148148149,
          0.08148148148148149,
          0.15555555555555556,
          0.15555555555555556,
          0.15555555555555556,
          0.16296296296296298,
          0.16296296296296298,
          0.16296296296296298,
          0.2074074074074074,
          0.2074074074074074,
          0.2074074074074074,
          0.23703703703703705,
          0.23703703703703705,
          0.23703703703703705,
          0.2962962962962963,
          0.2962962962962963,
          0.2962962962962963,
          0.4,
          0.4,
          0.4,
          1,
          1
         ],
         "y": [
          0,
          0.1111111111111111,
          0.1111111111111111,
          0.1111111111111111,
          0.2222222222222222,
          0.2222222222222222,
          0.2222222222222222,
          0.2222222222222222,
          0.2222222222222222,
          0.2222222222222222,
          0.5555555555555556,
          0.5555555555555556,
          0.5555555555555556,
          0.6666666666666666,
          0.6666666666666666,
          0.6666666666666666,
          0.6666666666666666,
          0.6666666666666666,
          0.6666666666666666,
          0.6666666666666666,
          0.6666666666666666,
          0.6666666666666666,
          0.7777777777777778,
          0.7777777777777778,
          0.7777777777777778,
          0.7777777777777778,
          0.7777777777777778,
          0.7777777777777778,
          0.8888888888888888,
          0.8888888888888888,
          0.8888888888888888,
          0.8888888888888888,
          0.8888888888888888,
          0.8888888888888888,
          0.8888888888888888,
          0.8888888888888888,
          0.8888888888888888,
          1,
          1,
          1
         ]
        }
       ],
       "layout": {
        "font": {
         "size": 14
        },
        "height": 600,
        "hovermode": "closest",
        "legend": {
         "bgcolor": "rgba(255, 255, 255, 0.8)",
         "bordercolor": "black",
         "borderwidth": 1,
         "x": 0.7,
         "y": 0.2
        },
        "plot_bgcolor": "white",
        "shapes": [
         {
          "line": {
           "color": "red",
           "dash": "dash",
           "width": 2
          },
          "name": "Random Guess",
          "type": "line",
          "x0": 0,
          "x1": 1,
          "y0": 0,
          "y1": 1
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "ROC Curve for GT (No Counterfactuals)"
        },
        "width": 600,
        "xaxis": {
         "range": [
          0,
          1.01
         ],
         "showgrid": false,
         "title": {
          "text": "False Positive Rate"
         },
         "zeroline": false
        },
        "yaxis": {
         "range": [
          0,
          1.01
         ],
         "showgrid": false,
         "title": {
          "text": "True Positive Rate"
         },
         "zeroline": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# IOI_GROUND_TRUTH_DATA = torch.load(\"data/ioi_ground_truth.pt\")\n",
    "\n",
    "# IOI_GROUND_TRUTH_HEADS = torch.zeros(12, 12)\n",
    "\n",
    "# for layer, head in IOI_GROUND_TRUTH_DATA:\n",
    "#     IOI_GROUND_TRUTH_HEADS[layer, head] = 1\n",
    "\n",
    "# ground_truth = IOI_GROUND_TRUTH_HEADS.flatten()\n",
    "\n",
    "GT_GROUND_TRUTH_DATA = torch.load(\"data/gt_ground_truth.pt\")\n",
    "\n",
    "GT_GROUND_TRUTH_HEADS = torch.zeros(12, 12)\n",
    "\n",
    "for layer, head in GT_GROUND_TRUTH_DATA:\n",
    "    GT_GROUND_TRUTH_HEADS[layer, head] = 1\n",
    "\n",
    "ground_truth = GT_GROUND_TRUTH_HEADS.flatten()\n",
    "\n",
    "# fp, tp, thresh = get_attn_head_roc(ground_truth, a.flatten().softmax(dim=-1), \"IOI\", visualize=True, additional_title=\"(No Counterfactuals)\")\n",
    "score, _, _, _ = get_attn_head_roc(ground_truth, attn_freqs.flatten().softmax(dim=-1), \"GT\", visualize=True, additional_title=\"(No Counterfactuals)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labelling IOI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are we going to do this?\n",
    "* We will work from the bottom up (starting at bottom nodes of our graph and moving onto connected components).\n",
    "* Get feature families for each component. \n",
    "* Get max-activating examples for each feature family.\n",
    "* Get token contributions for these max-activating examples - combine this into one prompt.\n",
    "* Get the max-activating examples/tokens on IOI specific inputs, as well as token contributions.\n",
    "* Provide a description of the IOI task in the prompt. \n",
    "* Provide the feature interpretation of every component feeding in to our current component.\n",
    "* Get IOI-specific interpretation of component.\n",
    "\n",
    "Baseline:\n",
    "* One circuit at a time, same process. \n",
    "\n",
    "\n",
    "Extensions (not for now):\n",
    "* Feature co-occurrences - not only what our component is doing, but how it passes information between nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlesoneill/miniconda3/envs/anu/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "\n",
      "Loading SAEs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 12/12 [00:08<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Transcoders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:05<00:00,  2.40it/s]\n",
      "100%|██████████| 20/20 [00:48<00:00,  2.42s/it]\n"
     ]
    }
   ],
   "source": [
    "# Get feature families for each component\n",
    "\n",
    "from autointerpretability import *\n",
    "\n",
    "cp = get_circuit_prediction(task='ioi', N=20)\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "def get_top_k_feature_tuples_for_component(co_occurrence_dict, component_str, k=5):\n",
    "    # Parse the component string to get the appropriate tuple key\n",
    "    if component_str.startswith(\"MLP\"):\n",
    "        layer = int(component_str[3:])\n",
    "        component = ('mlp_feature', layer)\n",
    "    elif component_str.startswith(\"L\") and \"H\" in component_str:\n",
    "        layer, head = map(int, component_str[1:].split(\"H\"))\n",
    "        component = ('attn_head', layer, head)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid component format: {component_str}\")\n",
    "\n",
    "    # Use a Counter to count the occurrences of each tuple\n",
    "    global_counter = Counter()\n",
    "\n",
    "    # Iterate through the co-occurrence dictionary\n",
    "    for comp_pair, co_occurrences in co_occurrence_dict.items():\n",
    "        comp1, comp2 = comp_pair\n",
    "\n",
    "        if comp1 == component or comp2 == component:\n",
    "            for feature_tuple in co_occurrences:\n",
    "                global_counter[(comp_pair, feature_tuple)] += 1\n",
    "\n",
    "    # Get the top-k tuples by count\n",
    "    top_k_tuples = global_counter.most_common(k)\n",
    "\n",
    "    # Create a dictionary to store the results\n",
    "    top_k_dict = defaultdict(dict)\n",
    "    \n",
    "    for (comp_pair, feature_tuple), count in top_k_tuples:\n",
    "        top_k_dict[comp_pair][feature_tuple] = count\n",
    "\n",
    "    return top_k_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19042, 6510, 4559, 176, 5081]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = list(set(cp.circuit_hypergraph['L2_H2']['features']))\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, z_saes, transcoders = get_model_encoders('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wg/cdt_cw_5265_z_gwnxlf0tv80000gn/T/ipykernel_8977/780314101.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dataset_prompt_tokens = torch.tensor(tokens)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [01:10<00:00,  1.76s/it]\n",
      "100%|██████████| 5/5 [01:18<00:00, 15.69s/it]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.02it/s]\n",
      "100%|██████████| 5/5 [00:04<00:00,  1.25it/s]\n",
      "100%|██████████| 40/40 [01:09<00:00,  1.75s/it]\n",
      "100%|██████████| 5/5 [01:18<00:00, 15.79s/it]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.50it/s]\n",
      "100%|██████████| 5/5 [00:06<00:00,  1.35s/it]\n",
      "100%|██████████| 40/40 [01:10<00:00,  1.75s/it]\n",
      "100%|██████████| 5/5 [01:16<00:00, 15.30s/it]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.54it/s]\n",
      "100%|██████████| 5/5 [00:04<00:00,  1.06it/s]\n",
      "100%|██████████| 40/40 [01:10<00:00,  1.75s/it]\n",
      "100%|██████████| 5/5 [01:17<00:00, 15.42s/it]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.51it/s]\n",
      "100%|██████████| 5/5 [00:05<00:00,  1.16s/it]\n",
      "100%|██████████| 40/40 [01:10<00:00,  1.76s/it]\n",
      "100%|██████████| 5/5 [01:17<00:00, 15.56s/it]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.42it/s]\n",
      "100%|██████████| 5/5 [00:03<00:00,  1.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# Autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from data.ioi_dataset import gen_templated_prompts\n",
    "from aug_interp_prompts import main_aug_interp_prompt, main_aug_interp_prompt_v2\n",
    "from openai_utils import gen_openai_completion, get_response\n",
    "from autointerpretability import *\n",
    "from discovery_strategies import (\n",
    "    create_filter,\n",
    "    create_simple_greedy_strategy,\n",
    "    create_top_contributor_strategy,\n",
    ")\n",
    "from max_act_analysis import MaxActAnalysis\n",
    "\n",
    "features = list(set(cp.circuit_hypergraph['L2_H2']['features']))\n",
    "\n",
    "#feature = 19042\n",
    "layer = 2\n",
    "num_examples = 5000\n",
    "\n",
    "strategy = create_simple_greedy_strategy(\n",
    "    passes=1,\n",
    "    node_contributors=1,\n",
    "    minimal=True,\n",
    ")\n",
    "\n",
    "\n",
    "dataset_prompts = gen_templated_prompts(template_idex=1, N=500)\n",
    "prompts = [x['text'] + x['correct'] for x in dataset_prompts]\n",
    "tokens = model.to_tokens(prompts)  # Assuming `model` is already defined\n",
    "dataset_prompt_tokens = torch.tensor(tokens)\n",
    "\n",
    "mini_examples_owt_overall = []\n",
    "mini_examples_ioi_overall = []\n",
    "\n",
    "for feature in features:\n",
    "\n",
    "    analyze_owt = MaxActAnalysis(\n",
    "        \"attn\", \n",
    "        layer, \n",
    "        feature, \n",
    "        num_sequences=num_examples, \n",
    "        batch_size=128, \n",
    "        strategy=strategy\n",
    "    )\n",
    "    mini_examples_owt = analyze_owt.get_context_referenced_prompts_for_range(0, 5)\n",
    "    mini_examples_owt_overall.append(mini_examples_owt)\n",
    "\n",
    "    # For Dataset Prompt Tokens\n",
    "    analyze_prompts = MaxActAnalysis(\n",
    "        \"attn\", \n",
    "        layer, \n",
    "        feature, \n",
    "        num_sequences=num_examples, \n",
    "        batch_size=128, \n",
    "        strategy=strategy, \n",
    "        token_dataset=dataset_prompt_tokens\n",
    "    )\n",
    "    mini_examples_ioi = analyze_prompts.get_context_referenced_prompts_for_range(0, 5)\n",
    "    mini_examples_ioi_overall.append(mini_examples_ioi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Template\n",
    "from typing import List, Tuple\n",
    "\n",
    "def main_aug_interp_prompt_ioi(\n",
    "    examples: List[str], examples_ioi: List[str], token_lr=(\"<<\", \">>\"), context_lr=(\"[[\", \"]]\")\n",
    "):\n",
    "    tl, tr = token_lr\n",
    "    cl, cr = context_lr\n",
    "\n",
    "    template = Template(\n",
    "        \"\"\"\n",
    "{# You are a meticulous AI researcher conducting an important investigation into a certain neuron in a language model. Your task is to analyze the neuron and provide an explanation that thoroughly encapsulates its behavior in the context of a specific task: Indirect Object Identification (IOI). Here's how you will complete this task: #}\n",
    "\n",
    "You are a meticulous AI researcher conducting an important investigation into a certain neuron in a language model. This language model is trained to predict the text that will follow a given input. Your task is to figure out what sort of behavior this neuron is responsible for -- namely, when this neuron fires, what kind of predictions does this neuron promote in the context of the specific task of Indirect Object Identification (IOI)? Here's how you'll complete the task:\n",
    "\n",
    "INPUT_DESCRIPTION: \n",
    "You will be given several examples of text that activate the neuron. First we'll provide the example text without any annotations, and then we'll provide the same text with annotations that show the specific tokens that caused the neuron to activate and context about why the neuron fired.\n",
    "\n",
    "The specific token that the neuron activates on will be the last token in the sequence, and will appear between {{tl}} and {{tr}} (like {{tl}}this{{tr}}).  \n",
    "\n",
    "Additionally, each sequence will have tokens enclosed between {{cl}} and {{cr}} (like {{cl}}this{{cr}}). From previous analysis, we know that these tokens form the context for why our neuron fires on the token enclosed in {{tl}} and {{tr}} (in addition to the value of the actual token itself). Note that we treat the group of tokens enclosed between {{cl}} and {{cr}} as the \"context\" for why the neuron fired.\n",
    "\n",
    "We will provide both general examples and specific examples related to the task of Indirect Object Identification (IOI).\n",
    "\n",
    "Task Description: A sentence containing indirect object identification (IOI) has an initial dependent clause, e.g. \"When Mary and John went to the store\", and a main clause, e.g. \"John gave a bottle of milk to Mary\". The initial clause introduces the indirect object (IO) \"Mary\" and the subject (S) \"John\". The main clause refers to the subject a second time, and in all our examples of IOI, the subject gives an object to the IO. The IOI task is to predict the final token in the sentence to be the IO. We use 'S1' and 'S2' to refer to the first and second occurrences of the subject, when we want to specify position.\n",
    "\n",
    "Given these examples, complete the following steps.\n",
    "\n",
    "OUTPUT_DESCRIPTION:\n",
    "\n",
    "Step 1: Based on the general examples provided, write down observed patterns between the tokens that caused the neuron to activate (just the tokens enclosed in {{tl}} and {{tr}}).\n",
    "Step 2: Based on the general examples provided, write down patterns you see in the context for why the neuron fired. (Remember, the \"context\" for an example is the group of tokens enclosed in {{cl}} and {{cr}}). Include any patterns in the relationships between different tokens in the context, and any patterns in the relationship between the context and the rest of the text.\n",
    "Step 3: Write down several general shared features of the general text examples.\n",
    "Step 4: Based on the IOI examples provided, write down observed patterns between the tokens that caused the neuron to activate (just the tokens enclosed in {{tl}} and {{tr}}).\n",
    "Step 5: Based on the IOI examples provided, write down patterns you see in the context for why the neuron fired. (Remember, the \"context\" for an example is the group of tokens enclosed in {{cl}} and {{cr}}). Include any patterns in the relationships between different tokens in the context, and any patterns in the relationship between the context and the rest of the text.\n",
    "Step 6: Write down several general shared features of the IOI text examples.\n",
    "Step 7: Based on the patterns you found between the activating token and the relevant context in both general and IOI examples, write down your best explanation for what this neuron is responsible for. Propose your explanation in the following form: \n",
    "[EXPLANATION]: <your explanation>\n",
    "\n",
    "Guidelines:\n",
    "- Try to produce a final explanation that's both concise and general to the examples provided.\n",
    "- Your explanation should be short: 1-2 sentences.\n",
    "- Specifically address the neuron's role in the context of the IOI task, explaining its specific function in relation to predicting the indirect object.\n",
    "\n",
    "INPUT:\n",
    "\n",
    "General Examples:\n",
    "{% for example in examples %}                         \n",
    "EXAMPLE {{loop.index + 1}}:\n",
    "- Base Text -\n",
    "=================================================\n",
    "{{example[0]}}\n",
    "=================================================\n",
    "\n",
    "- Annotated Text -\n",
    "=================================================\n",
    "{{example[1]}}\n",
    "=================================================\n",
    "\n",
    "{% endfor %}\n",
    "\n",
    "IOI Task Examples:\n",
    "{% for example in examples_ioi %}                         \n",
    "EXAMPLE {{loop.index + 1}}:\n",
    "- Base Text -\n",
    "=================================================\n",
    "{{example[0]}}\n",
    "=================================================\n",
    "\n",
    "- Annotated Text -\n",
    "=================================================\n",
    "{{example[1]}}\n",
    "=================================================\n",
    "\n",
    "{% endfor %}\n",
    "\n",
    "OUTPUT:\n",
    "                         \n",
    "Step 1:\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "    return template.render(\n",
    "        {\"tl\": tl, \"tr\": tr, \"cl\": cl, \"cr\": cr, \"examples\": examples, \"examples_ioi\": examples_ioi}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "You are a meticulous AI researcher conducting an important investigation into a certain neuron in a language model. This language model is trained to predict the text that will follow a given input. Your task is to figure out what sort of behavior this neuron is responsible for -- namely, when this neuron fires, what kind of predictions does this neuron promote in the context of the specific task of Indirect Object Identification (IOI)? Here's how you'll complete the task:\n",
      "\n",
      "INPUT_DESCRIPTION: \n",
      "You will be given several examples of text that activate the neuron. First we'll provide the example text without any annotations, and then we'll provide the same text with annotations that show the specific tokens that caused the neuron to activate and context about why the neuron fired.\n",
      "\n",
      "The specific token that the neuron activates on will be the last token in the sequence, and will appear between << and >> (like <<this>>).  \n",
      "\n",
      "Additionally, each sequence will have tokens enclosed between [[ and ]] (like [[this]]). From previous analysis, we know that these tokens form the context for why our neuron fires on the token enclosed in << and >> (in addition to the value of the actual token itself). Note that we treat the group of tokens enclosed between [[ and ]] as the \"context\" for why the neuron fired.\n",
      "\n",
      "We will provide both general examples and specific examples related to the task of Indirect Object Identification (IOI).\n",
      "\n",
      "Task Description: A sentence containing indirect object identification (IOI) has an initial dependent clause, e.g. \"When Mary and John went to the store\", and a main clause, e.g. \"John gave a bottle of milk to Mary\". The initial clause introduces the indirect object (IO) \"Mary\" and the subject (S) \"John\". The main clause refers to the subject a second time, and in all our examples of IOI, the subject gives an object to the IO. The IOI task is to predict the final token in the sentence to be the IO. We use 'S1' and 'S2' to refer to the first and second occurrences of the subject, when we want to specify position.\n",
      "\n",
      "Given these examples, complete the following steps.\n",
      "\n",
      "OUTPUT_DESCRIPTION:\n",
      "\n",
      "Step 1: Based on the general examples provided, write down observed patterns between the tokens that caused the neuron to activate (just the tokens enclosed in << and >>).\n",
      "Step 2: Based on the general examples provided, write down patterns you see in the context for why the neuron fired. (Remember, the \"context\" for an example is the group of tokens enclosed in [[ and ]]). Include any patterns in the relationships between different tokens in the context, and any patterns in the relationship between the context and the rest of the text.\n",
      "Step 3: Write down several general shared features of the general text examples.\n",
      "Step 4: Based on the IOI examples provided, write down observed patterns between the tokens that caused the neuron to activate (just the tokens enclosed in << and >>).\n",
      "Step 5: Based on the IOI examples provided, write down patterns you see in the context for why the neuron fired. (Remember, the \"context\" for an example is the group of tokens enclosed in [[ and ]]). Include any patterns in the relationships between different tokens in the context, and any patterns in the relationship between the context and the rest of the text.\n",
      "Step 6: Write down several general shared features of the IOI text examples.\n",
      "Step 7: Based on the patterns you found between the activating token and the relevant context in both general and IOI examples, write down your best explanation for what this neuron is responsible for. Propose your explanation in the following form: \n",
      "[EXPLANATION]: <your explanation>\n",
      "\n",
      "Guidelines:\n",
      "- Try to produce a final explanation that's both concise and general to the examples provided.\n",
      "- Your explanation should be short: 1-2 sentences.\n",
      "- Specifically address the neuron's role in the context of the IOI task, explaining its specific function in relation to predicting the indirect object.\n",
      "\n",
      "INPUT:\n",
      "\n",
      "General Examples:\n",
      "                         \n",
      "EXAMPLE 2:\n",
      "- Base Text -\n",
      "=================================================\n",
      "(' bat speed of Javier Baez.\\n\\nThere is the artistry of Kyle Hendricks and the deceptively quick Tsuyoshi Wada. I no longer cringe when the Cubs make the call to their bullpen. These guys throw strikes and brings multiple weapons to each appearance. I even enjoy seeing quality ballplayers like Luis Valbuena, Chris Coghlan, and Justin R', ' bat speed of Javier Baez.\\n\\nThere is the artistry of Kyle Hendricks and the deceptively quick Tsuyoshi Wada. I no longer cringe when the[[ Cubs]] make the call to their bullpen. These guys throw strikes and brings multiple weapons to each appearance. I even enjoy seeing quality ballplayers like Luis Valbuena, Chris Coghlan, and[[ Justin]]<< R>>')\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "(' sustainably. It is also essential for supporting the organic plant breeders, small-scale farmers, millers and bakers who have opted out of the industrial system to produce a sustainable future for bread and to ensure it is the wholesome, healthy staple food it should be.\\n\\nPhotographs: Justin Party', ' sustainably. It is also essential for supporting the organic plant breeders, small-scale farmers, millers and bakers who have opted out of the industrial system to produce a sustainable future for bread and to ensure it is the wholesome, healthy staple food it should be.\\n\\nPhotographs:[[ Justin]]<< Party>>')\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 3:\n",
      "- Base Text -\n",
      "=================================================\n",
      "(' with the required anti-aliasing filters creeping into the audio band. While many might say that makes hi-res audio overkill, some astute listeners maintain they can hear a quality difference when higher sampling rates are used.<|endoftext|>Giving people', ' with the required anti-aliasing filters creeping into the audio band. While many might say that makes hi-res audio overkill, some astute listeners maintain they can hear a quality difference when higher sampling rates are used.[[<|endoftext|>]][[Giving]]<< people>>')\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "('.�� The agent cited ��privacy concerns,�� while giving no', '.�� The agent cited ��privacy[[ concerns]],�� while[[ giving]]<< no>>')\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 4:\n",
      "- Base Text -\n",
      "=================================================\n",
      "(' no good? Who forced Gordon to retreat back to give Lee the bad news – leading directly to Appomattox and the end of the war? Having looked at all the available records, I cannot say.\\n\\nBut I remember those horseflies: I��m not denying it, either.\\n\\nFollow Disunion at twitter.com/NYTcivilwar or join us on Facebook.\\n\\nSources: John C. Taylor and Samuel P. Hatfield, ��History of the First Connecticut Artillery and of the siege trains of the armies operating against Richmond, 1862-1865��; William C', ' no good? Who forced Gordon to retreat back to give Lee the bad news – leading directly to Appomattox and the end of the war? Having looked at all the available records, I cannot say.\\n\\nBut I remember those horseflies: I��m not denying it, either.\\n\\nFollow Disunion at twitter.com/NYTcivilwar or join us on Facebook.\\n\\nSources: John C. Taylor and Samuel P. Hatfield, ��History of the First Connecticut Artillery and of the siege trains of the armies operating against Richmond,[[ 1862]]-1865��;[[ William]]<< C>>')\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "('Athens, GA: University of Georgia Press, 2000); P.J. Carisella, James W. Ryan, and Edward W. Brooke, The Black Swallow of Death: The Incredible Story of Eugene Jacques Bullard, The World��s First Black Combat Aviator (Boston: Marlborough House, 1972); William A', 'Athens, GA: University of Georgia Press, 2000); P.J. Carisella, James W. Ryan, and Edward W. Brooke, The Black Swallow of Death: The Incredible Story of Eugene Jacques Bullard, The World��s First Black Combat Aviator (Boston: Marlborough House, 1972);[[ William]]<< A>>')\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 5:\n",
      "- Base Text -\n",
      "=================================================\n",
      "('/Washington Monthly]\\n\\n• Christopher Orr concurs that many ��Joe the Plumbers, Tito the Builders, Phil the Bricklayers, etc. … may be less than thrilled to hear that the RNC has apparently spent $150,000 clothing and accessorizing La Palin.�� Though on the bright side, ��John McCain��s $520 Ferragamos now sound like the shoes of a pauper.�� [Plank/New Republic]\\n\\n• Matthew Y', '/Washington Monthly]\\n\\n• Christopher Orr concurs that many ��Joe the Plumbers, Tito the Builders, Phil the Bricklayers, etc. … may be less than thrilled to hear that the RNC has apparently spent $150,000 clothing and accessorizing La Palin.�� Though on the bright side, ��John McCain��s $520 Ferragamos now sound like the shoes of a pauper.�� [Plank/New Republic]\\n\\n•[[ Matthew]]<< Y>>')\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "('-life Ron Woodroof, Matthew Mc', '-[[life]] Ron Woodroof,[[ Matthew]]<< Mc>>')\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 6:\n",
      "- Base Text -\n",
      "=================================================\n",
      "(' the AshleyMadison data dump is similar to the Sony leak in that there is some clear information that is of public interest and other that is private and salacious. In both cases, noted Ryan Thomas', ' the AshleyMadison data dump is similar to the Sony leak in that there is some clear information that is of public interest and other that is private and salacious. In both cases, noted[[ Ryan]]<< Thomas>>')\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "(' putting everything together,�� Russell said. ��Having another year with this coaching staff has been great for everybody. Just concentrating on the small details for me has been very good and helped me fine tune my game some more.��\\n\\nThe coming season could give way to Russell becoming a household name in the Big Ten. He��s the clear leader of the Boilermaker defense and is next in line after Ryan Ker', ' putting everything together,�� Russell said. ��Having another year with this coaching staff has been great for everybody. Just concentrating on the small details for me has been very good and helped me fine tune my game some more.��\\n\\nThe coming season could give way to Russell becoming a household name in the Big Ten. He��s the clear leader of the Boilermaker defense and is next in line after[[ Ryan]]<< Ker>>')\n",
      "=================================================\n",
      "\n",
      "\n",
      "\n",
      "IOI Task Examples:\n",
      "                         \n",
      "EXAMPLE 2:\n",
      "- Base Text -\n",
      "=================================================\n",
      "('Then, Justin and', 'Then,[[ Justin]]<< and>>')\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "('Then, Justin and', 'Then,[[ Justin]]<< and>>')\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 3:\n",
      "- Base Text -\n",
      "=================================================\n",
      "('Then, Lisa and James had a lot of fun at the station. Lisa gave a', 'Then, Lisa and James had[[ a]] lot of fun at the station.[[ Lisa]][[ gave]]<< a>>')\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "('Then, Michelle and Brian had a lot of fun at the office. Michelle gave a', 'Then, Michelle and[[ Brian]] had a lot of fun at the office. Michelle[[ gave]]<< a>>')\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 4:\n",
      "- Base Text -\n",
      "=================================================\n",
      "('Then, William and', 'Then,[[ William]]<< and>>')\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "('Then, William and', 'Then,[[ William]]<< and>>')\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 5:\n",
      "- Base Text -\n",
      "=================================================\n",
      "('Then, Matthew and', '[[Then]],[[ Matthew]]<< and>>')\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "('Then, Matthew and', '[[Then]],[[ Matthew]]<< and>>')\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 6:\n",
      "- Base Text -\n",
      "=================================================\n",
      "('Then, Ryan and', 'Then,[[ Ryan]]<< and>>')\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "('Then, Ryan and', 'Then,[[ Ryan]]<< and>>')\n",
      "=================================================\n",
      "\n",
      "\n",
      "\n",
      "OUTPUT:\n",
      "                         \n",
      "Step 1:\n"
     ]
    }
   ],
   "source": [
    "p = main_aug_interp_prompt_ioi(mini_examples_owt_overall, mini_examples_ioi_overall)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the general examples provided, the tokens that cause the neuron to activate are typically the beginning of a proper name or noun phrase (e.g., \"R\" in \"Justin R\", \"Party\" in \"Justin Party\", \"people\" in \"Giving people\", \"C\" in \"William C\", \"A\" in \"William A\", \"Y\" in \"Matthew Y\", \"Mc\" in \"Matthew Mc\", \"Thomas\" in \"Ryan Thomas\", and \"Ker\" in \"Ryan Ker\").\n",
      "\n",
      "Step 2: In the context for why the neuron fires, tokens within the brackets \"[[\" and \"]]\" tend to be proper names or noun phrases similar to the activating tokens. They also often come before prepositions or conjunctions, suggesting this neuron relates to the prediction of names or parts of names in specific grammatical contexts. \n",
      "\n",
      "Step 3: In a shared feature of general text examples, this neuron seems to activate specifically around the final part of proper names, or completions of noun phrases. It's usually where a name or noun phrase immediately precedes a preposition, conjunction, or punctuation.\n",
      "\n",
      "Step 4: In the IOI examples, the neuron activates on conjunctions (e.g., \"and\" in \"Justin and\", \"Lisa and\", \"William and\", \"Matthew and\", \"Ryan and\")\n",
      "\n",
      "Step 5: In the context for the neuron firing in IOI examples, similar to general examples, the tokens enclosed in \"[[\" and \"]]\" are proper names (e.g., \"Justin\", \"Lisa\", \"William\", \"Matthew\", \"Ryan\").\n",
      "\n",
      "Step 6: The general shared feature of the IOI text examples is their structure. Each sentence begins with \"Then,\" followed by two proper names connected by \"and\". The neuron activates on the conjunction \"and\".\n",
      "\n",
      "Step 7: This neuron appears to be responsible for the prediction of what comes next in a sequence following proper names, either a continuation of the name or noun phrase, or a grammatical structure in more complex sentences. In terms of the IOI task, this neuron seems to fire when predicting the conjunction following the subject's name, but doesn't seem to contribute directly to the identification of the indirect object.\n",
      "[EXPLANATION]: This neuron is responsible for predicting the continuation of a proper noun or noun phrase, often in the context of a specific grammatical structure, such as a conjunction or preposition. In terms of Indirect Object Identification, it doesn't directly contribute to identifying the indirect object, but aids in formulating the prediction of the conjunction following the subject's name.\n"
     ]
    }
   ],
   "source": [
    "interp = get_response(p)\n",
    "print(interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2h2_interp = \"Predicting conjunctions following the subject's name.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wg/cdt_cw_5265_z_gwnxlf0tv80000gn/T/ipykernel_8977/3545841595.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dataset_prompt_tokens = torch.tensor(tokens)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:43<00:00,  1.09s/it]\n",
      "100%|██████████| 5/5 [00:48<00:00,  9.72s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00,  6.23it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.47it/s]\n",
      "100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "100%|██████████| 5/5 [00:45<00:00,  9.13s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00,  6.11it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.24it/s]\n",
      "100%|██████████| 40/40 [00:42<00:00,  1.05s/it]\n",
      "100%|██████████| 5/5 [00:46<00:00,  9.30s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00,  6.47it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.35it/s]\n",
      "100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "100%|██████████| 5/5 [00:45<00:00,  9.16s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00,  6.31it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.27it/s]\n",
      "100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "100%|██████████| 5/5 [00:46<00:00,  9.21s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00,  6.23it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.27it/s]\n",
      "100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "100%|██████████| 5/5 [00:45<00:00,  9.19s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00,  6.22it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.31it/s]\n",
      "100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "100%|██████████| 5/5 [00:45<00:00,  9.18s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00,  6.07it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.30it/s]\n",
      "100%|██████████| 40/40 [00:42<00:00,  1.06s/it]\n",
      "100%|██████████| 5/5 [00:46<00:00,  9.33s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00,  6.28it/s]\n",
      "100%|██████████| 5/5 [00:03<00:00,  1.57it/s]\n",
      "100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "100%|██████████| 5/5 [00:45<00:00,  9.13s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00,  6.28it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.26it/s]\n",
      "100%|██████████| 40/40 [00:41<00:00,  1.03s/it]\n",
      "100%|██████████| 5/5 [00:45<00:00,  9.10s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00,  6.41it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.36it/s]\n",
      "100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "100%|██████████| 5/5 [00:45<00:00,  9.19s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00,  6.11it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.27it/s]\n",
      "100%|██████████| 40/40 [00:41<00:00,  1.05s/it]\n",
      "100%|██████████| 5/5 [00:46<00:00,  9.24s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00,  6.23it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.34it/s]\n",
      "100%|██████████| 40/40 [00:41<00:00,  1.04s/it]\n",
      "100%|██████████| 5/5 [00:45<00:00,  9.12s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00,  6.14it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.29it/s]\n"
     ]
    }
   ],
   "source": [
    "features = [x for x in list(set(cp.circuit_hypergraph['L0_H1']['features'])) if x!=-1]\n",
    "\n",
    "#feature = 19042\n",
    "layer = 0\n",
    "num_examples = 5000\n",
    "\n",
    "strategy = create_simple_greedy_strategy(\n",
    "    passes=1,\n",
    "    node_contributors=1,\n",
    "    minimal=True,\n",
    ")\n",
    "\n",
    "\n",
    "dataset_prompts = gen_templated_prompts(template_idex=1, N=500)\n",
    "prompts = [x['text'] + x['correct'] for x in dataset_prompts]\n",
    "tokens = model.to_tokens(prompts)  # Assuming `model` is already defined\n",
    "dataset_prompt_tokens = torch.tensor(tokens)\n",
    "\n",
    "mini_examples_owt_overall = []\n",
    "mini_examples_ioi_overall = []\n",
    "\n",
    "for feature in features:\n",
    "\n",
    "    analyze_owt = MaxActAnalysis(\n",
    "        \"attn\", \n",
    "        layer, \n",
    "        feature, \n",
    "        num_sequences=num_examples, \n",
    "        batch_size=128, \n",
    "        strategy=strategy\n",
    "    )\n",
    "    mini_examples_owt = analyze_owt.get_context_referenced_prompts_for_range(0, 5)\n",
    "    mini_examples_owt_overall.append(mini_examples_owt)\n",
    "\n",
    "    # For Dataset Prompt Tokens\n",
    "    analyze_prompts = MaxActAnalysis(\n",
    "        \"attn\", \n",
    "        layer, \n",
    "        feature, \n",
    "        num_sequences=num_examples, \n",
    "        batch_size=128, \n",
    "        strategy=strategy, \n",
    "        token_dataset=dataset_prompt_tokens\n",
    "    )\n",
    "    mini_examples_ioi = analyze_prompts.get_context_referenced_prompts_for_range(0, 5)\n",
    "    mini_examples_ioi_overall.append(mini_examples_ioi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list of lists into a single list\n",
    "mini_examples_owt_overall = [item for sublist in mini_examples_owt_overall for item in sublist]\n",
    "mini_examples_ioi_overall = [item for sublist in mini_examples_ioi_overall for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tokens causing neuron activation are predominantly names such as \"Christopher\", \"Michael\", \"John\" etc. However, there are also non-name tokens that activate the neuron such as \"<<\" or \".\", and common nouns like \"bone\".\n",
      "\n",
      "Step 2: For the non-name tokens, there's typically no observable significant context that's provided (as nothing has been marked with [[ and ]] tags). For the proper names, the context appears to often be another proper name earlier in the sentence. For example, in \"Then, Jamie and Christopher had a lot of fun at the station. Jamie gave a necklace to<< Christopher>>\". The marked context is the first occurrence of the subject, \"Jamie\".\n",
      "\n",
      "Step 3:\n",
      "- The general examples frequently use proper names (especially male names) as the token to activate the neuron. \n",
      "- Sentences are often in the past tense and describe some form of action or event.\n",
      "- Non-name examples often reflect tokens placed at the end of statements or inputs.\n",
      "\n",
      "Step 4: Much like the general examples, the IOI examples that trigger the neuron are again mainly names. Of note is that these names were also the indirect object of the sentence.\n",
      "\n",
      "Step 5: The context patterns in the IOI examples often shows that when the neuron fires, the token in question is an indirect object that was earlier introduced in the sentence. For instance, in \"Then, Jamie and Christopher had a lot of fun at the station. Jamie gave a necklace to<< Christopher>>\", \"Jamie\" and \"Christopher\" were introduced and then mentioned again in the final action (giving a necklace), which triggered the neuron.\n",
      "\n",
      "Step 6:\n",
      "- The IOI examples often use names as the token to activate the neuron.\n",
      "- Sentences describe a series of events and the activation often appears in the context of giving or receiving an object.\n",
      "- The neuron activation frequently identifies the indirect object in the described action.\n",
      "\n",
      "Step 7: [EXPLANATION]: The neuron seems to be responsible for identifying repeated entities in a sentence, specifically proper names. In the context of the IOI task, it seems specifically tuned towards the later appearance of the indirect object in a sentence structure where the indirect object is being given something.\n"
     ]
    }
   ],
   "source": [
    "p = main_aug_interp_prompt_ioi(mini_examples_owt_overall, mini_examples_ioi_overall)\n",
    "interp = get_response(p)\n",
    "print(interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "l0h1_interp = \"Identifying the later appearance of the indirect object in a sentence structure where the indirect object is being given something.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wg/cdt_cw_5265_z_gwnxlf0tv80000gn/T/ipykernel_8977/2252016215.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dataset_prompt_tokens = torch.tensor(tokens)\n",
      "100%|██████████| 40/40 [01:24<00:00,  2.12s/it]\n",
      "100%|██████████| 5/5 [01:32<00:00, 18.54s/it]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.50it/s]\n",
      "100%|██████████| 5/5 [00:04<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The general examples seem to show that the tokens causing the neuron to fire are the last words of a sentence or clause. Often, these trigger tokens are nouns, specifically ones that have previously appeared in the text.\n",
      "\n",
      "Step 2: Context tokens often immediately precede the trigger token with one or more words in between. These tokens usually form a small phrase or clause with the trigger token, sometimes giving additional information about the function or importance of the trigger token in the described scenario.\n",
      "\n",
      "Step 3: General shared features of the text examples include: there is always a repeat of the trigger token within the text, the trigger token is frequently a noun, and the trigger token tends to appear at the end of a clause or sentence.\n",
      "\n",
      "Step 4: For the IOI examples, the tokens causing the neuron to activate always refer to the subject (S1) or the indirect object (IO) in the task of indirect object identification (IOI). These tokens can be seen as placeholders indicating where the subject or indirect object from the earlier clause should be placed.\n",
      "\n",
      "Step 5: In the context for the IOI task, the context tokens always include the indirect object and/or subject from the earlier dependent clause. This provides the necessary reference point for placing the correct word (subject or indirect object) in the final position.\n",
      "\n",
      "Step 6: Shared features of the IOI text examples include: the trigger token is either the subject or the indirect object from the earlier dependent clause, there’s always a repetition of the trigger token within the text, and the trigger token always appears at the end of a sentence.\n",
      "\n",
      "Step 7: \n",
      "[EXPLANATION]: This neuron seems responsible for recognizing when a named entity (like a subject or an indirect object) re-occurs in the text, often at the end of a sentence or clause. In the context of Indirect Object Identification, it aids in flagging when and where the subject or indirect object from a prior clause reappears in the text.\n"
     ]
    }
   ],
   "source": [
    "features = [x for x in list(set(cp.circuit_hypergraph['L3_H0']['features'])) if x!=-1]\n",
    "\n",
    "# #feature = 19042\n",
    "layer = 3\n",
    "num_examples = 5000\n",
    "\n",
    "strategy = create_simple_greedy_strategy(\n",
    "    passes=1,\n",
    "    node_contributors=1,\n",
    "    minimal=True,\n",
    ")\n",
    "\n",
    "\n",
    "dataset_prompts = gen_templated_prompts(template_idex=1, N=500)\n",
    "prompts = [x['text'] + x['correct'] for x in dataset_prompts]\n",
    "tokens = model.to_tokens(prompts)  # Assuming `model` is already defined\n",
    "dataset_prompt_tokens = torch.tensor(tokens)\n",
    "\n",
    "mini_examples_owt_overall = []\n",
    "mini_examples_ioi_overall = []\n",
    "\n",
    "for feature in features:\n",
    "\n",
    "    analyze_owt = MaxActAnalysis(\n",
    "        \"attn\", \n",
    "        layer, \n",
    "        feature, \n",
    "        num_sequences=num_examples, \n",
    "        batch_size=128, \n",
    "        strategy=strategy\n",
    "    )\n",
    "    mini_examples_owt = analyze_owt.get_context_referenced_prompts_for_range(0, 5)\n",
    "    mini_examples_owt_overall.extend(mini_examples_owt)\n",
    "\n",
    "    # For Dataset Prompt Tokens\n",
    "    analyze_prompts = MaxActAnalysis(\n",
    "        \"attn\", \n",
    "        layer, \n",
    "        feature, \n",
    "        num_sequences=num_examples, \n",
    "        batch_size=128, \n",
    "        strategy=strategy, \n",
    "        token_dataset=dataset_prompt_tokens\n",
    "    )\n",
    "    mini_examples_ioi = analyze_prompts.get_context_referenced_prompts_for_range(0, 5)\n",
    "    mini_examples_ioi_overall.extend(mini_examples_ioi)\n",
    "\n",
    "p = main_aug_interp_prompt_ioi(mini_examples_owt_overall, mini_examples_ioi_overall)\n",
    "interp = get_response(p)\n",
    "print(interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3h0_interp = \"Aids in flagging when and where the subject or indirect object from a prior clause reappears in the text.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wg/cdt_cw_5265_z_gwnxlf0tv80000gn/T/ipykernel_8977/4026547288.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dataset_prompt_tokens = torch.tensor(tokens)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20359]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [01:38<00:00,  2.45s/it]\n",
      "100%|██████████| 5/5 [01:46<00:00, 21.24s/it] \n",
      "100%|██████████| 4/4 [00:01<00:00,  2.41it/s]\n",
      "100%|██████████| 5/5 [00:04<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The neuron activates on determiners (\"rightly\", \"hold\", \"observed\", \"are\", \"had\") attached to the last token in the sequence.\n",
      "\n",
      "Step 2: The context triggering neuron activation illustrates a co-occurrence pattern between a specific noun phrase (usually consisting of two proper nouns connected with \"and\") and the following determiner.\n",
      "\n",
      "Step 3: The general shared features of the general text examples are that the sentence usually includes a pair of entities or characters expressed as \"<Name_1> and <Name_2>\", followed by a determiner that triggers the neuron activation.\n",
      "\n",
      "Step 4: The neuron activates again on determiners (\"had\") attached to the last token in the sequence.\n",
      "\n",
      "Step 5: The context triggers when there are two proper nouns connected with \"and\", followed by a determiner which then activates the neuron.\n",
      "\n",
      "Step 6: The general shared features of the IOI text examples are that all sentences begin with \"Then,\" and includes a pair of entities or characters expressed as \"<Name_1> and <Name_2>\" followed by a determiner that triggers the neuron.\n",
      "\n",
      "Step 7: \n",
      "[EXPLANATION]: The neuron is responsible for predicting a determiner that is following a structure of \"<Name_1> and <Name_2>\", signalling the association between two entities or characters and promoting predictions in the context of an action or state involving them. In the context of the IOI task, this neuron helps identify and predict an interaction between the subject and the indirect object.\n"
     ]
    }
   ],
   "source": [
    "features = [x for x in list(set(cp.circuit_hypergraph['L4_H11']['features'])) if x!=-1]\n",
    "print(features)\n",
    "\n",
    "# #feature = 19042\n",
    "layer = 4\n",
    "num_examples = 5000\n",
    "\n",
    "strategy = create_simple_greedy_strategy(\n",
    "    passes=1,\n",
    "    node_contributors=1,\n",
    "    minimal=True,\n",
    ")\n",
    "\n",
    "\n",
    "dataset_prompts = gen_templated_prompts(template_idex=1, N=500)\n",
    "prompts = [x['text'] + x['correct'] for x in dataset_prompts]\n",
    "tokens = model.to_tokens(prompts)  # Assuming `model` is already defined\n",
    "dataset_prompt_tokens = torch.tensor(tokens)\n",
    "\n",
    "mini_examples_owt_overall = []\n",
    "mini_examples_ioi_overall = []\n",
    "\n",
    "for feature in features:\n",
    "\n",
    "    analyze_owt = MaxActAnalysis(\n",
    "        \"attn\", \n",
    "        layer, \n",
    "        feature, \n",
    "        num_sequences=num_examples, \n",
    "        batch_size=128, \n",
    "        strategy=strategy\n",
    "    )\n",
    "    mini_examples_owt = analyze_owt.get_context_referenced_prompts_for_range(0, 5)\n",
    "    mini_examples_owt_overall.extend(mini_examples_owt)\n",
    "\n",
    "    # For Dataset Prompt Tokens\n",
    "    analyze_prompts = MaxActAnalysis(\n",
    "        \"attn\", \n",
    "        layer, \n",
    "        feature, \n",
    "        num_sequences=num_examples, \n",
    "        batch_size=128, \n",
    "        strategy=strategy, \n",
    "        token_dataset=dataset_prompt_tokens\n",
    "    )\n",
    "    mini_examples_ioi = analyze_prompts.get_context_referenced_prompts_for_range(0, 5)\n",
    "    mini_examples_ioi_overall.extend(mini_examples_ioi)\n",
    "\n",
    "p = main_aug_interp_prompt_ioi(mini_examples_owt_overall, mini_examples_ioi_overall)\n",
    "interp = get_response(p)\n",
    "print(interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "l4h11_interp = \"\"\" \n",
    "Predicts a determiner that is following a structure of \"<Name_1> and <Name_2>\", signalling the association between two entities or characters and promoting predictions in the context of an action or state involving them. In the context of the IOI task, this neuron helps identify and predict an interaction between the subject and the indirect object.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Template\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "def main_aug_interp_prompt_ioi(\n",
    "    examples: List[str], examples_ioi: List[str], \n",
    "    token_lr=(\"<<\", \">>\"), context_lr=(\"[[\", \"]]\")\n",
    "):\n",
    "    tl, tr = token_lr\n",
    "    cl, cr = context_lr\n",
    "\n",
    "    template = Template(\n",
    "        \"\"\"\n",
    "{# You are a meticulous AI researcher conducting an important investigation into a certain neuron in a language model. Your task is to analyze the neuron and provide an explanation that thoroughly encapsulates its behavior in the context of a specific task: Indirect Object Identification (IOI). Here's how you will complete this task: #}\n",
    "\n",
    "You are a meticulous AI researcher conducting an important investigation into a certain neuron in a language model. This language model is trained to predict the text that will follow a given input. Your task is to figure out what sort of behavior this neuron is responsible for -- namely, when this neuron fires, what kind of predictions does this neuron promote in the context of the specific task of Indirect Object Identification (IOI)? Here's how you'll complete the task:\n",
    "\n",
    "INPUT_DESCRIPTION: \n",
    "You will be given several examples of text that activate the neuron. First we'll provide the example text without any annotations, and then we'll provide the same text with annotations that show the specific tokens that caused the neuron to activate and context about why the neuron fired.\n",
    "\n",
    "The specific token that the neuron activates on will be the last token in the sequence, and will appear between {{tl}} and {{tr}} (like {{tl}}this{{tr}}).  \n",
    "\n",
    "Additionally, each sequence will have tokens enclosed between {{cl}} and {{cr}} (like {{cl}}this{{cr}}). From previous analysis, we know that these tokens form the context for why our neuron fires on the token enclosed in {{tl}} and {{tr}} (in addition to the value of the actual token itself). Note that we treat the group of tokens enclosed between {{cl}} and {{cr}} as the \"context\" for why the neuron fired.\n",
    "\n",
    "We will provide both general examples and specific examples related to the task of Indirect Object Identification (IOI).\n",
    "\n",
    "Task Description: A sentence containing indirect object identification (IOI) has an initial dependent clause, e.g. \"When Mary and John went to the store\", and a main clause, e.g. \"John gave a bottle of milk to Mary\". The initial clause introduces the indirect object (IO) \"Mary\" and the subject (S) \"John\". The main clause refers to the subject a second time, and in all our examples of IOI, the subject gives an object to the IO. The IOI task is to predict the final token in the sentence to be the IO. We use 'S1' and 'S2' to refer to the first and second occurrences of the subject, when we want to specify position.\n",
    "\n",
    "Given these examples, complete the following steps.\n",
    "\n",
    "OUTPUT_DESCRIPTION:\n",
    "\n",
    "Step 1: Based on the general examples provided, write down observed patterns between the tokens that caused the neuron to activate (just the tokens enclosed in {{tl}} and {{tr}}).\n",
    "Step 2: Based on the general examples provided, write down patterns you see in the context for why the neuron fired. (Remember, the \"context\" for an example is the group of tokens enclosed in {{cl}} and {{cr}}). Include any patterns in the relationships between different tokens in the context, and any patterns in the relationship between the context and the rest of the text.\n",
    "Step 3: Write down several general shared features of the general text examples.\n",
    "Step 4: Based on the IOI examples provided, write down observed patterns between the tokens that caused the neuron to activate (just the tokens enclosed in {{tl}} and {{tr}}).\n",
    "Step 5: Based on the IOI examples provided, write down patterns you see in the context for why the neuron fired. (Remember, the \"context\" for an example is the group of tokens enclosed in {{cl}} and {{cr}}). Include any patterns in the relationships between different tokens in the context, and any patterns in the relationship between the context and the rest of the text.\n",
    "Step 6: Write down several general shared features of the IOI text examples.\n",
    "Step 7: Based on the patterns you found between the activating token and the relevant context in both general and IOI examples, write down your best explanation for what this neuron is responsible for. Propose your explanation in the following form: \n",
    "[EXPLANATION]: <your explanation>\n",
    "\n",
    "Guidelines:\n",
    "- Try to produce a final explanation that's both concise and general to the examples provided.\n",
    "- Your explanation should be short: 1-2 sentences.\n",
    "- Specifically address the neuron's role in the context of the IOI task, explaining its specific function in relation to predicting the indirect object.\n",
    "- If provided, incorporate the interpretation of the previous neurons into your explanation, considering how the current neuron processes and uses the information from these previous neurons.\n",
    "\n",
    "INPUT:\n",
    "\n",
    "General Examples:\n",
    "{% for example in examples %}                         \n",
    "EXAMPLE {{loop.index + 1}}:\n",
    "- Base Text -\n",
    "=================================================\n",
    "{{example[0]}}\n",
    "=================================================\n",
    "\n",
    "- Annotated Text -\n",
    "=================================================\n",
    "{{example[1]}}\n",
    "=================================================\n",
    "\n",
    "{% endfor %}\n",
    "\n",
    "IOI Task Examples:\n",
    "{% for example in examples_ioi %}                         \n",
    "EXAMPLE {{loop.index + 1}}:\n",
    "- Base Text -\n",
    "=================================================\n",
    "{{example[0]}}\n",
    "=================================================\n",
    "\n",
    "- Annotated Text -\n",
    "=================================================\n",
    "{{example[1]}}\n",
    "=================================================\n",
    "\n",
    "{% endfor %}\n",
    "\n",
    "OUTPUT:\n",
    "                         \n",
    "Step 1:\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "    return template.render(\n",
    "        {\"tl\": tl, \"tr\": tr, \"cl\": cl, \"cr\": cr, \"examples\": examples, \"examples_ioi\": examples_ioi, \"incoming_information\": incoming_information}\n",
    "    )\n",
    "\n",
    "def main_aug_interp_prompt_ioi_incoming(\n",
    "    examples: List[str], examples_ioi: List[str], \n",
    "    incoming_information: Optional[List[Tuple[str, str]]] = None, \n",
    "    token_lr=(\"<<\", \">>\"), context_lr=(\"[[\", \"]]\")\n",
    "):\n",
    "    tl, tr = token_lr\n",
    "    cl, cr = context_lr\n",
    "\n",
    "    template = Template(\n",
    "        \"\"\"\n",
    "{# You are a meticulous AI researcher conducting an important investigation into a certain neuron in a language model. Your task is to analyze the neuron and provide an explanation that thoroughly encapsulates its behavior in the context of a specific task: Indirect Object Identification (IOI). Here's how you will complete this task: #}\n",
    "\n",
    "You are a meticulous AI researcher conducting an important investigation into a certain neuron in a language model. This language model is trained to predict the text that will follow a given input. Your task is to figure out what sort of behavior this neuron is responsible for -- namely, when this neuron fires, what kind of predictions does this neuron promote in the context of the specific task of Indirect Object Identification (IOI)? Here's how you'll complete the task:\n",
    "\n",
    "INPUT_DESCRIPTION: \n",
    "You will be given several examples of text that activate the neuron. First we'll provide the example text without any annotations, and then we'll provide the same text with annotations that show the specific tokens that caused the neuron to activate and context about why the neuron fired.\n",
    "\n",
    "The specific token that the neuron activates on will be the last token in the sequence, and will appear between {{tl}} and {{tr}} (like {{tl}}this{{tr}}).  \n",
    "\n",
    "Additionally, each sequence will have tokens enclosed between {{cl}} and {{cr}} (like {{cl}}this{{cr}}). From previous analysis, we know that these tokens form the context for why our neuron fires on the token enclosed in {{tl}} and {{tr}} (in addition to the value of the actual token itself). Note that we treat the group of tokens enclosed between {{cl}} and {{cr}} as the \"context\" for why the neuron fired.\n",
    "\n",
    "We will provide both general examples and specific examples related to the task of Indirect Object Identification (IOI).\n",
    "\n",
    "Task Description: A sentence containing indirect object identification (IOI) has an initial dependent clause, e.g. \"When Mary and John went to the store\", and a main clause, e.g. \"John gave a bottle of milk to Mary\". The initial clause introduces the indirect object (IO) \"Mary\" and the subject (S) \"John\". The main clause refers to the subject a second time, and in all our examples of IOI, the subject gives an object to the IO. The IOI task is to predict the final token in the sentence to be the IO. We use 'S1' and 'S2' to refer to the first and second occurrences of the subject, when we want to specify position.\n",
    "\n",
    "Previous Neuron Information:\n",
    "You will also be provided with information about important previous neurons that feed into the current neuron. These neurons play a significant role in the IOI task and move information into the current neuron. The incoming information will be presented as a list of tuples, where each tuple contains the neuron's name and its interpretation in the context of the IOI task.\n",
    "\n",
    "{% for neuron in incoming_information %}\n",
    "Neuron {{neuron[0]}}:\n",
    "- Interpretation in IOI context: {{neuron[1]}}\n",
    "\n",
    "{% endfor %}\n",
    "\n",
    "Use this incoming information to help interpret the current neuron's role, considering how it processes and uses the information from these previous neurons.\n",
    "\n",
    "Given these examples, complete the following steps.\n",
    "\n",
    "OUTPUT_DESCRIPTION:\n",
    "\n",
    "Step 1: Based on the general examples provided, write down observed patterns between the tokens that caused the neuron to activate (just the tokens enclosed in {{tl}} and {{tr}}).\n",
    "Step 2: Based on the general examples provided, write down patterns you see in the context for why the neuron fired. (Remember, the \"context\" for an example is the group of tokens enclosed in {{cl}} and {{cr}}). Include any patterns in the relationships between different tokens in the context, and any patterns in the relationship between the context and the rest of the text.\n",
    "Step 3: Write down several general shared features of the general text examples.\n",
    "Step 4: Based on the IOI examples provided, write down observed patterns between the tokens that caused the neuron to activate (just the tokens enclosed in {{tl}} and {{tr}}).\n",
    "Step 5: Based on the IOI examples provided, write down patterns you see in the context for why the neuron fired. (Remember, the \"context\" for an example is the group of tokens enclosed in {{cl}} and {{cr}}). Include any patterns in the relationships between different tokens in the context, and any patterns in the relationship between the context and the rest of the text.\n",
    "Step 6: Write down several general shared features of the IOI text examples.\n",
    "Step 7: Based on the patterns you found between the activating token and the relevant context in both general and IOI examples, write down your best explanation for what this neuron is responsible for. Propose your explanation in the following form: \n",
    "[EXPLANATION]: <your explanation>\n",
    "\n",
    "Guidelines:\n",
    "- Try to produce a final explanation that's both concise and general to the examples provided.\n",
    "- Your explanation should be short: 1-2 sentences.\n",
    "- Specifically address the neuron's role in the context of the IOI task, explaining its specific function in relation to predicting the indirect object.\n",
    "- If provided, incorporate the interpretation of the previous neurons into your explanation, considering how the current neuron processes and uses the information from these previous neurons.\n",
    "\n",
    "INPUT:\n",
    "\n",
    "General Examples:\n",
    "{% for example in examples %}                         \n",
    "EXAMPLE {{loop.index + 1}}:\n",
    "- Base Text -\n",
    "=================================================\n",
    "{{example[0]}}\n",
    "=================================================\n",
    "\n",
    "- Annotated Text -\n",
    "=================================================\n",
    "{{example[1]}}\n",
    "=================================================\n",
    "\n",
    "{% endfor %}\n",
    "\n",
    "IOI Task Examples:\n",
    "{% for example in examples_ioi %}                         \n",
    "EXAMPLE {{loop.index + 1}}:\n",
    "- Base Text -\n",
    "=================================================\n",
    "{{example[0]}}\n",
    "=================================================\n",
    "\n",
    "- Annotated Text -\n",
    "=================================================\n",
    "{{example[1]}}\n",
    "=================================================\n",
    "\n",
    "{% endfor %}\n",
    "\n",
    "OUTPUT:\n",
    "                         \n",
    "Step 1:\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "    return template.render(\n",
    "        {\"tl\": tl, \"tr\": tr, \"cl\": cl, \"cr\": cr, \"examples\": examples, \"examples_ioi\": examples_ioi, \"incoming_information\": incoming_information}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [x for x in list(set(cp.circuit_hypergraph['L5_H5']['features'])) if x!=-1]\n",
    "print(features)\n",
    "\n",
    "# #feature = 19042\n",
    "layer = 5\n",
    "num_examples = 5000\n",
    "\n",
    "strategy = create_simple_greedy_strategy(\n",
    "    passes=1,\n",
    "    node_contributors=1,\n",
    "    minimal=True,\n",
    ")\n",
    "\n",
    "\n",
    "dataset_prompts = gen_templated_prompts(template_idex=1, N=500)\n",
    "prompts = [x['text'] + x['correct'] for x in dataset_prompts]\n",
    "tokens = model.to_tokens(prompts)  # Assuming `model` is already defined\n",
    "dataset_prompt_tokens = torch.tensor(tokens)\n",
    "\n",
    "mini_examples_owt_overall = []\n",
    "mini_examples_ioi_overall = []\n",
    "\n",
    "for feature in features:\n",
    "\n",
    "    analyze_owt = MaxActAnalysis(\n",
    "        \"attn\", \n",
    "        layer, \n",
    "        feature, \n",
    "        num_sequences=num_examples, \n",
    "        batch_size=128, \n",
    "        strategy=strategy\n",
    "    )\n",
    "    mini_examples_owt = analyze_owt.get_context_referenced_prompts_for_range(0, 5)\n",
    "    mini_examples_owt_overall.extend(mini_examples_owt)\n",
    "\n",
    "    # For Dataset Prompt Tokens\n",
    "    analyze_prompts = MaxActAnalysis(\n",
    "        \"attn\", \n",
    "        layer, \n",
    "        feature, \n",
    "        num_sequences=num_examples, \n",
    "        batch_size=128, \n",
    "        strategy=strategy, \n",
    "        token_dataset=dataset_prompt_tokens\n",
    "    )\n",
    "    mini_examples_ioi = analyze_prompts.get_context_referenced_prompts_for_range(0, 5)\n",
    "    mini_examples_ioi_overall.extend(mini_examples_ioi)\n",
    "\n",
    "\n",
    "incoming_information = [\n",
    "    (\"L2H2\", l2h2_interp),\n",
    "    (\"L0H1\", l0h1_interp),\n",
    "    (\"L3H0\", l3h0_interp),\n",
    "    (\"L4H11\", l4h11_interp),\n",
    "]\n",
    "\n",
    "p = main_aug_interp_prompt_ioi_incoming(mini_examples_owt_overall, mini_examples_ioi_overall, incoming_information)\n",
    "interp = get_response(p)\n",
    "print(interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "l5h5_interp = \"This neuron predicts the appearance of named entities, specifically indirect objects, influenced by a previous introduction of the same entity or entities in the text (especially when entities were linked with a conjunction), crucial in identifying these entities when they reappear in a later context.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wg/cdt_cw_5265_z_gwnxlf0tv80000gn/T/ipykernel_8977/912588485.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dataset_prompt_tokens = torch.tensor(tokens)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6424, 16513, 2623]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [02:34<00:00,  3.85s/it]\n",
      "100%|██████████| 5/5 [02:45<00:00, 33.11s/it] \n",
      "100%|██████████| 4/4 [00:02<00:00,  1.60it/s]\n",
      "100%|██████████| 5/5 [00:05<00:00,  1.03s/it]\n",
      "100%|██████████| 40/40 [02:33<00:00,  3.85s/it]\n",
      "100%|██████████| 5/5 [02:51<00:00, 34.33s/it] \n",
      "100%|██████████| 4/4 [00:02<00:00,  1.56it/s]\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.43s/it]\n",
      "100%|██████████| 40/40 [02:33<00:00,  3.84s/it]\n",
      "100%|██████████| 5/5 [02:45<00:00, 33.07s/it] \n",
      "100%|██████████| 4/4 [00:02<00:00,  1.48it/s]\n",
      "100%|██████████| 5/5 [00:10<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tokens that activate the neuron are mostly coordinating conjunctions (\"and\"), a few terminal markers like period and closing parenthesis, and in one instance, a preposition (\"to\").\n",
      "\n",
      "Step 2: In all the general examples, the context responsible for the firing of the neuron includes named entities, linked together with the help of conjunction. These named entities are highlighted as a pair in most cases or individually with the pair forming the overall context. The named entities seem to be part of a group or set of entities being listed or described in the given text. A common pattern is either the entities are connected through a shared activity or attribute, or they are being enumerated or introduced for the first time in the context.\n",
      "\n",
      "Step 3: A shared feature in the general text examples is the presence of a group or a pair of named entities in the context. These entities could be part of an enumeration, a description, or a narration involving these entities.\n",
      "\n",
      "Step 4: The tokens that activate the neuron in IOI examples are coordinating conjunctions (\"and\") and a preposition (\"to\").\n",
      "\n",
      "Step 5: In all the IOI examples, the context involves two named entities - the subject, and another entity which is being connected to the subject. Contexts highlighted include the introduction of these entities and their interplay, especially in activities that are suggestive of being related to indirect object identification.\n",
      "\n",
      "Step 6: The general shared features in the IOI text examples is the presence of named entities, notably two, that are part of a larger clause or statement. These entities are described in the context of their interaction or their attributes that have implications in indirect object identification.\n",
      "\n",
      "Step 7: \n",
      "[EXPLANATION]: This neuron is responsible for detecting a linking or coordinating structure (\"and\", \"to\") between multiple named entities, especially in a context where these entities share a common activity or attribute. In the context of Indirect Object Identification, this neuron plays a pivotal role in recognizing the conjunction or linkage between the subject and the indirect object. The information fed from neuron L5H5 further aids in understanding the appearance of these named entities, triggering the current neuron.\n"
     ]
    }
   ],
   "source": [
    "features = [x for x in list(set(cp.circuit_hypergraph['L8_H6']['features'])) if x!=-1]\n",
    "print(features)\n",
    "\n",
    "# #feature = 19042\n",
    "layer = 8\n",
    "num_examples = 5000\n",
    "\n",
    "strategy = create_simple_greedy_strategy(\n",
    "    passes=1,\n",
    "    node_contributors=1,\n",
    "    minimal=True,\n",
    ")\n",
    "\n",
    "\n",
    "dataset_prompts = gen_templated_prompts(template_idex=1, N=500)\n",
    "prompts = [x['text'] + x['correct'] for x in dataset_prompts]\n",
    "tokens = model.to_tokens(prompts)  # Assuming `model` is already defined\n",
    "dataset_prompt_tokens = torch.tensor(tokens)\n",
    "\n",
    "mini_examples_owt_overall = []\n",
    "mini_examples_ioi_overall = []\n",
    "\n",
    "for feature in features:\n",
    "\n",
    "    analyze_owt = MaxActAnalysis(\n",
    "        \"attn\", \n",
    "        layer, \n",
    "        feature, \n",
    "        num_sequences=num_examples, \n",
    "        batch_size=128, \n",
    "        strategy=strategy\n",
    "    )\n",
    "    mini_examples_owt = analyze_owt.get_context_referenced_prompts_for_range(0, 5)\n",
    "    mini_examples_owt_overall.extend(mini_examples_owt)\n",
    "\n",
    "    # For Dataset Prompt Tokens\n",
    "    analyze_prompts = MaxActAnalysis(\n",
    "        \"attn\", \n",
    "        layer, \n",
    "        feature, \n",
    "        num_sequences=num_examples, \n",
    "        batch_size=128, \n",
    "        strategy=strategy, \n",
    "        token_dataset=dataset_prompt_tokens\n",
    "    )\n",
    "    mini_examples_ioi = analyze_prompts.get_context_referenced_prompts_for_range(0, 5)\n",
    "    mini_examples_ioi_overall.extend(mini_examples_ioi)\n",
    "\n",
    "\n",
    "incoming_information = [\n",
    "    # (\"L2H2\", l2h2_interp),\n",
    "    # (\"L0H1\", l0h1_interp),\n",
    "    # (\"L3H0\", l3h0_interp),\n",
    "    # (\"L4H11\", l4h11_interp),\n",
    "    (\"L5H5\", l5h5_interp),\n",
    "]\n",
    "\n",
    "p = main_aug_interp_prompt_ioi_incoming(mini_examples_owt_overall, mini_examples_ioi_overall, incoming_information)\n",
    "interp = get_response(p)\n",
    "print(interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "l8h6_interp = \"\"\" \n",
    "This neuron is responsible for detecting a linking or coordinating structure (\"and\", \"to\") between multiple named entities when those entities have already been introduced, as determined by L5H5.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp.circuit_hypergraph['L9_H9']['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [x for x in list(set(cp.circuit_hypergraph['L9_H9']['features'])) if x!=-1]\n",
    "print(features)\n",
    "\n",
    "# #feature = 19042\n",
    "layer = 9\n",
    "num_examples = 2500\n",
    "\n",
    "strategy = create_simple_greedy_strategy(\n",
    "    passes=1,\n",
    "    node_contributors=1,\n",
    "    minimal=True,\n",
    ")\n",
    "\n",
    "\n",
    "dataset_prompts = gen_templated_prompts(template_idex=1, N=500)\n",
    "prompts = [x['text'] + x['correct'] for x in dataset_prompts]\n",
    "tokens = model.to_tokens(prompts)  # Assuming `model` is already defined\n",
    "dataset_prompt_tokens = torch.tensor(tokens)\n",
    "\n",
    "mini_examples_owt_overall = []\n",
    "mini_examples_ioi_overall = []\n",
    "\n",
    "for feature in features:\n",
    "    try:\n",
    "\n",
    "        analyze_owt = MaxActAnalysis(\n",
    "            \"attn\", \n",
    "            layer, \n",
    "            feature, \n",
    "            num_sequences=num_examples, \n",
    "            batch_size=128, \n",
    "            strategy=strategy\n",
    "        )\n",
    "        mini_examples_owt = analyze_owt.get_context_referenced_prompts_for_range(0, 5)\n",
    "        mini_examples_owt_overall.extend(mini_examples_owt)\n",
    "\n",
    "        # For Dataset Prompt Tokens\n",
    "        analyze_prompts = MaxActAnalysis(\n",
    "            \"attn\", \n",
    "            layer, \n",
    "            feature, \n",
    "            num_sequences=num_examples, \n",
    "            batch_size=128, \n",
    "            strategy=strategy, \n",
    "            token_dataset=dataset_prompt_tokens\n",
    "        )\n",
    "        mini_examples_ioi = analyze_prompts.get_context_referenced_prompts_for_range(0, 5)\n",
    "        mini_examples_ioi_overall.extend(mini_examples_ioi)\n",
    "    \n",
    "    except:\n",
    "        print(f\"Error with feature {feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the general examples, the neuron activates on a diverse set of tokens. These include function words (\"to\", \"is\", \"at\", \"does\", \"up\", \",\", \"of\", \".\", \"�\", \"and\", \"(\", \")\"), names (\"Emily\", \"Marilyn\", \"Chris\", \"Eric\", \"P\", \"Sarah\", \"Crystal\", \"Jacob\"\n",
      ", \"Ellis\", \"Paul\", \"Carp\", \"t\", \"Josh\", \"Rita\", \"Alexander\", \"Allan\") and other content words (\"car\", \"pic\", \"Twitter\", \"com\", \"attention\", \"menace\", \") \", \"RT\", \"tagged\", \"call\", \"meet\", \"whether\", \"sell\", \"name\").\n",
      "\n",
      "Step 2: \n",
      "In most of the context provided, the neuron seems to pay attention to a combination of people's names (like \"Emily\", \"Paul\", \"Eric\", etc.), and function words (\"to\", \"of\", \"at\", etc). The name often appears in the context with some kind of action or possession (e.g., \"Emily's image tagged in\", \"Paul gave a ring to\", \"Josh showed Mary\"). The neuron also seems to capture various grammatical and semantic relations between tokens within the context.\n",
      "\n",
      "Step 3: \n",
      "In general examples, the text is mostly composed of sentences from various domains showing different situations. These situations usually involve actions performed by previously mentioned entities, often people. In many cases, the neuron seems to be tracking people and the actions oriented towards them.\n",
      "\n",
      "Step 4: \n",
      "In the IOI examples, the neuron activates on the token \"to\" which occurs at the end of the sentences. \n",
      "\n",
      "Step 5: \n",
      "In the IOI examples, the context always includes the second occurrence of the subject (S2) and an action (verb) performed by the subject. The context does not include the indirect object (IO) that the action is directed towards.\n",
      "\n",
      "Step 6: \n",
      "In IOI examples, the sentences always follow a specific pattern: an initial situation, usually involving fun activities, takes place between a pair of individuals. Subsequently, one of the individuals gives an unspecified item to another (the indirect object). The name of the recipient is expected, but not said.\n",
      "\n",
      "Step 7: \n",
      "[EXPLANATION]: Based on the patterns observed, it appears that this neuron is responsible for recognizing contexts that involve a person's action directed towards another entity. In the context of the IOI task, this function becomes more specific: the neuron activates on the token \"to\" when it follows the second occurrence of the subject (S2) and an action (verb) performed by the subject. This leads the model to predict the indirect object (IO) as the next token. This neuron thus contributes to the identification of the indirect object in a sentence by recognizing the contextual pattern of a conducted action by a previously mentioned person.\n"
     ]
    }
   ],
   "source": [
    "incoming_information = [\n",
    "    # (\"L2H2\", l2h2_interp),\n",
    "    # (\"L0H1\", l0h1_interp),\n",
    "    # (\"L3H0\", l3h0_interp),\n",
    "    # (\"L4H11\", l4h11_interp),\n",
    "    #(\"L5H5\", l5h5_interp),\n",
    "    (\"L8H6\", l8h6_interp),\n",
    "]\n",
    "\n",
    "p = main_aug_interp_prompt_ioi_incoming(mini_examples_owt_overall, mini_examples_ioi_overall, incoming_information)\n",
    "interp = get_response(p)\n",
    "print(interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "You are a meticulous AI researcher conducting an important investigation into a certain neuron in a language model. This language model is trained to predict the text that will follow a given input. Your task is to figure out what sort of behavior this neuron is responsible for -- namely, when this neuron fires, what kind of predictions does this neuron promote in the context of the specific task of Indirect Object Identification (IOI)? Here's how you'll complete the task:\n",
      "\n",
      "INPUT_DESCRIPTION: \n",
      "You will be given several examples of text that activate the neuron. First we'll provide the example text without any annotations, and then we'll provide the same text with annotations that show the specific tokens that caused the neuron to activate and context about why the neuron fired.\n",
      "\n",
      "The specific token that the neuron activates on will be the last token in the sequence, and will appear between << and >> (like <<this>>).  \n",
      "\n",
      "Additionally, each sequence will have tokens enclosed between [[ and ]] (like [[this]]). From previous analysis, we know that these tokens form the context for why our neuron fires on the token enclosed in << and >> (in addition to the value of the actual token itself). Note that we treat the group of tokens enclosed between [[ and ]] as the \"context\" for why the neuron fired.\n",
      "\n",
      "We will provide both general examples and specific examples related to the task of Indirect Object Identification (IOI).\n",
      "\n",
      "Task Description: A sentence containing indirect object identification (IOI) has an initial dependent clause, e.g. \"When Mary and John went to the store\", and a main clause, e.g. \"John gave a bottle of milk to Mary\". The initial clause introduces the indirect object (IO) \"Mary\" and the subject (S) \"John\". The main clause refers to the subject a second time, and in all our examples of IOI, the subject gives an object to the IO. The IOI task is to predict the final token in the sentence to be the IO. We use 'S1' and 'S2' to refer to the first and second occurrences of the subject, when we want to specify position.\n",
      "\n",
      "Previous Neuron Information:\n",
      "You will also be provided with information about important previous neurons that feed into the current neuron. These neurons play a significant role in the IOI task and move information into the current neuron. The incoming information will be presented as a list of tuples, where each tuple contains the neuron's name and its interpretation in the context of the IOI task.\n",
      "\n",
      "\n",
      "Neuron L8H6:\n",
      "- Interpretation in IOI context:  \n",
      "This neuron is responsible for detecting a linking or coordinating structure (\"and\", \"to\") between multiple named entities when those entities have already been introduced, as determined by L5H5.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Use this incoming information to help interpret the current neuron's role, considering how it processes and uses the information from these previous neurons.\n",
      "\n",
      "Given these examples, complete the following steps.\n",
      "\n",
      "OUTPUT_DESCRIPTION:\n",
      "\n",
      "Step 1: Based on the general examples provided, write down observed patterns between the tokens that caused the neuron to activate (just the tokens enclosed in << and >>).\n",
      "Step 2: Based on the general examples provided, write down patterns you see in the context for why the neuron fired. (Remember, the \"context\" for an example is the group of tokens enclosed in [[ and ]]). Include any patterns in the relationships between different tokens in the context, and any patterns in the relationship between the context and the rest of the text.\n",
      "Step 3: Write down several general shared features of the general text examples.\n",
      "Step 4: Based on the IOI examples provided, write down observed patterns between the tokens that caused the neuron to activate (just the tokens enclosed in << and >>).\n",
      "Step 5: Based on the IOI examples provided, write down patterns you see in the context for why the neuron fired. (Remember, the \"context\" for an example is the group of tokens enclosed in [[ and ]]). Include any patterns in the relationships between different tokens in the context, and any patterns in the relationship between the context and the rest of the text.\n",
      "Step 6: Write down several general shared features of the IOI text examples.\n",
      "Step 7: Based on the patterns you found between the activating token and the relevant context in both general and IOI examples, write down your best explanation for what this neuron is responsible for. Propose your explanation in the following form: \n",
      "[EXPLANATION]: <your explanation>\n",
      "\n",
      "Guidelines:\n",
      "- Try to produce a final explanation that's both concise and general to the examples provided.\n",
      "- Your explanation should be short: 1-2 sentences.\n",
      "- Specifically address the neuron's role in the context of the IOI task, explaining its specific function in relation to predicting the indirect object.\n",
      "- If provided, incorporate the interpretation of the previous neurons into your explanation, considering how the current neuron processes and uses the information from these previous neurons.\n",
      "\n",
      "INPUT:\n",
      "\n",
      "General Examples:\n",
      "                         \n",
      "EXAMPLE 2:\n",
      "- Base Text -\n",
      "=================================================\n",
      "synthetic compound derived from morphine, so authorities had probably considered it as a proscribed drug since the first schedule was passed in 1911, which included \"morphine, its salts and compounds.\"\n",
      "\n",
      "Proscribing codeine was more controversial, although after it was added doctors, druggists and the pharmaceutical industry successfully lobbied to have codeine decriminalized.\n",
      "\n",
      "It was removed from the schedule in 1925, though the U.S. government and the Canadian government��s own narcotic division criticized the decision.\n",
      "\n",
      "Emily Murphy's ��new menace��\n",
      "\n",
      "\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "synthetic compound derived from morphine, so authorities had probably considered it as a proscribed drug since the first schedule was passed in 1911, which included \"morphine, its salts and compounds.\"\n",
      "\n",
      "Proscribing codeine was more controversial, although after it was added doctors, druggists and the pharmaceutical industry successfully lobbied to have codeine decriminalized.\n",
      "\n",
      "It was removed from the schedule in 1925, though the U.S. government and the Canadian government��s own narcotic division criticized the decision.\n",
      "\n",
      "[[Emily]] Murphy's[[ �]]�new[[ menace]]��\n",
      "<<\n",
      ">>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 3:\n",
      "- Base Text -\n",
      "=================================================\n",
      " won the day in the British Privy Council.\n",
      "\n",
      "With no parliamentary debate, no evidence of public debate or discussion, and no paper trail about why marijuana was criminalized in 1923, it's understandable why people would later link the decision to The Black Candle. But Carstairs says it's probably just happenstance.\n",
      "\n",
      "She also told CBC News, \"There were insinuations in the records that the bureaucrats at the division of narcotic control did not think very highly of Emily Murphy and did not pay attention to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " won the day in the British Privy Council.\n",
      "\n",
      "With no parliamentary debate, no evidence of public debate or discussion, and no paper trail about why marijuana was criminalized in 1923, it's understandable why people would later link the decision to The Black Candle. But Carstairs says it's probably just happenstance.\n",
      "\n",
      "She also told CBC News, \"There were insinuations in the records that the bureaucrats at the division of narcotic control did not think very highly of[[ Emily]] Murphy and did not pay[[ attention]]<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 4:\n",
      "- Base Text -\n",
      "=================================================\n",
      " won the day in the British Privy Council.\n",
      "\n",
      "With no parliamentary debate, no evidence of public debate or discussion, and no paper trail about why marijuana was criminalized in 1923, it's understandable why people would later link the decision to The Black Candle. But Carstairs says it's probably just happenstance.\n",
      "\n",
      "She also told CBC News, \"There were insinuations in the records that the bureaucrats at the division of narcotic control did not think very highly of Emily Murphy and did not pay attention to what\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " won the day in the British Privy Council.\n",
      "\n",
      "With no parliamentary debate, no evidence of public debate or discussion, and no paper trail about why marijuana was criminalized in 1923, it's understandable why people would later link the decision to The Black Candle. But Carstairs says it's probably just happenstance.\n",
      "\n",
      "She also told CBC News, \"There were insinuations in the records that the bureaucrats at the division of narcotic control did not think very highly of[[ Emily]] Murphy and did not pay[[ attention]][[ to]]<< what>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 5:\n",
      "- Base Text -\n",
      "=================================================\n",
      " the \"Famous Five\" feminists, was unveiled in Calgary in 1999. She is also remembered for her anti-narcotic campaigning in the 1920s. (Canadian Press)\n",
      "\n",
      "A 1922 book, The Black Candle, by Emily Murphy, is frequently given as the explanation for the King government's move against marijuana.\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " the \"Famous Five\" feminists, was unveiled in Calgary in 1999. She is also remembered for her anti-narcotic campaigning in the 1920s. (Canadian Press)\n",
      "\n",
      "A 1922 book, The Black Candle, by Emily[[ Murphy]], is frequently given as the explanation for the King government's move against marijuana<<.>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 6:\n",
      "- Base Text -\n",
      "=================================================\n",
      " won the day in the British Privy Council.\n",
      "\n",
      "With no parliamentary debate, no evidence of public debate or discussion, and no paper trail about why marijuana was criminalized in 1923, it's understandable why people would later link the decision to The Black Candle. But Carstairs says it's probably just happenstance.\n",
      "\n",
      "She also told CBC News, \"There were insinuations in the records that the bureaucrats at the division of narcotic control did not think very highly of Emily Murphy and did not pay attention to what she was writing about, and they didn't consider her a particularly accurate or valuable source.\"\n",
      "\n",
      "\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " won the day in the British Privy Council.\n",
      "\n",
      "With no parliamentary debate, no evidence of public debate or discussion, and no paper trail about why marijuana was criminalized in 1923, it's understandable why people would later link the decision to The Black Candle. But Carstairs says it's probably just happenstance.\n",
      "\n",
      "She also told[[ CBC]] News, \"There were insinuations in the records that the bureaucrats at the division of narcotic control did not think very highly of[[ Emily]] Murphy and did not pay attention to what she was writing about, and they didn't consider her a particularly accurate or valuable source.\"[[\n",
      "]]<<\n",
      ">>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 7:\n",
      "- Base Text -\n",
      "=================================================\n",
      " proc constructT ( ) : T = if toDestroy . len > 0 : let ( d , p ) = toDestroy . pop ( ) d ( p )\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " proc[[ construct]]T ([[ )]] : T = if toDestroy . len > 0[[ :]][[ let]][[ (]][[ d]][[ ,]][[ p]] )[[ =]] toDestroy . pop ( )[[ d]] ( p<< )>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 8:\n",
      "- Base Text -\n",
      "=================================================\n",
      " he also has an active case in danger. Again, Witt is the father of five kids. His ex-wife reported him missing the Friday before Thanksgiving. St. Louis County Police are investigating.\n",
      "\n",
      "Former clients can contact Attorney Kenneth Carp to retrieve their old files. The Courts appointed Carp to take over some cases and help with abandoned files. You can contact Carp by calling him at 314-942-3005 or through one of his web-sites http://www.kcar\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " he also has an active case in danger. Again, Witt is the father of five kids. His ex-wife reported him missing the Friday before Thanksgiving. St. Louis County Police are investigating.\n",
      "\n",
      "Former clients can contact Attorney Kenneth[[ Car]][[p]] to retrieve their old files. The Courts appointed Carp to take over some cases and help with abandoned files. You can contact Carp by calling him at 314-942-3005 or through one of his web-sites http://www.k<<car>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 9:\n",
      "- Base Text -\n",
      "=================================================\n",
      ".\n",
      "\n",
      "{{tncms-inline account=\"TomMoorePhilly\" html=\"<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\"><a href=\"https://twitter.com/hashtag/Sixers?src=hash\">#Sixers</a> Simmons: 'I'm a winner' <a href=\"https://t.co/PPgZd8Gntx\">pic.twitter.com/\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      ".\n",
      "\n",
      "{{tncms-inline account=\"TomMoorePhilly\" html=\"<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\"><a href=\"https://twitter.com/hashtag/Sixers?src=hash\">#Sixers</a> Simmons: 'I'm a winner' <a href=\"https[[://]][[t]].co[[/]][[PP]]gZd8Gntx\">[[pic]].[[twitter]].[[com]]<</>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 10:\n",
      "- Base Text -\n",
      "=================================================\n",
      " are eligible for a one-off payment of up to £2,000 to help meet their needs.\"\n",
      "\n",
      "What is a PIP assessment?\n",
      "\n",
      "\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " are eligible for a one-off payment of up to £2,000 to help meet their needs[[.\"]]\n",
      "\n",
      "What[[ is]] a[[ P]]IP assessment?\n",
      "<<\n",
      ">>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 11:\n",
      "- Base Text -\n",
      "=================================================\n",
      " There are clear indications that the Talocan did not possess infomorph technology or advanced cloning facilities. In fact it seems to have been that lack of development which lead to their demise in Anoikis where they appear to have been decimated by a pandemic. Finally, the Drifter battleships do not look much like known Talocan ship designs.\n",
      "\n",
      "Enheduanni\n",
      "\n",
      "P\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " There are clear indications that the Talocan did not possess infomorph technology or advanced cloning facilities. In fact it seems to have been that lack of development which lead to their demise in Anoikis where they appear to have been decimated by a[[ pand]]emic. Finally, the Drifter battleships do not look much like known Talocan ship designs.\n",
      "\n",
      "Enheduanni\n",
      "\n",
      "<<P>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 12:\n",
      "- Base Text -\n",
      "=================================================\n",
      " kerfuffle, looks ��like a rounding error compared to Palin��s September hair and makeup expenses.�� It��s also surprising that this type of expenditure is legal, though apparently it is. [Think Progress]\n",
      "\n",
      "• Chuck Todd and friends believe the story ��could further add to the perception that Palin isn��t a serious candidate.�� And Andrea Mitchell wonders whether Palin is ��permitted to accept these kinds of gifts under Alaska ethics laws.�� [First Read/MSNBC]\n",
      "\n",
      "• Jake Tapper wonders whether\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " kerfuffle, looks ��like a rounding error compared to[[ Palin]]��s September hair and makeup expenses.�� It��s also surprising that this type of expenditure is legal, though apparently it is. [Think Progress]\n",
      "\n",
      "• Chuck Todd and friends believe the story ��could further add to the perception that Palin isn��t a serious candidate.�� And Andrea Mitchell wonders whether Palin is ��permitted to accept these kinds of gifts under Alaska ethics laws.�� [First Read/MSNBC]\n",
      "\n",
      "• Jake Tapper wonders<< whether>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 13:\n",
      "- Base Text -\n",
      "=================================================\n",
      " the campaign has done to portray Palin and her family as salt-of-the-earth middle-class types.�� [War Room/Salon]\n",
      "\n",
      "• Emily Bazelon contends that, ��In a sense,\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " the campaign has done to portray[[ Palin]] and her family as salt-of-the-earth middle-class types.�� [War Room/Salon]\n",
      "\n",
      "• Emily Bazelon contends that, ��[[In]] a[[ sense]]<<,>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 14:\n",
      "- Base Text -\n",
      "=================================================\n",
      " kerfuffle, looks ��like a rounding error compared to Palin��s September hair and makeup expenses.�� It��s also surprising that this type of expenditure is legal, though apparently it is. [Think Progress]\n",
      "\n",
      "• Chuck Todd and friends believe the story ��could further add to the perception that Palin isn��t a serious candidate.�� And Andrea Mitchell wonders whether\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " kerfuffle, looks ��like a rounding error compared to Palin��s September hair and makeup expenses.�� It��s also surprising that this type of expenditure is legal, though apparently it is. [Think Progress]\n",
      "\n",
      "• Chuck Todd and friends believe the story ��could further add to the perception that[[ Palin]] isn��t a serious candidate.�� And Andrea Mitchell wonders<< whether>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 15:\n",
      "- Base Text -\n",
      "=================================================\n",
      " the campaign has done to portray Palin and her family as salt-of-the-earth middle-class types.�� [War Room/Salon]\n",
      "\n",
      "• Emily Bazelon contends that, ��In a sense, this is unfair,�� because any wealthy candidate would already have the nice clothes that Palin needed to buy. Plus, ��Isn��t\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " the campaign has done to portray[[ Palin]] and her family as salt-of-the-earth middle-class types.�� [War Room/Salon]\n",
      "\n",
      "• Emily Bazelon contends that, ��In a sense, this is unfair,�� because any wealthy candidate would already have the nice clothes that Palin needed to buy. Plus, ��[[Isn]]��<<t>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 16:\n",
      "- Base Text -\n",
      "=================================================\n",
      " the campaign has done to portray Palin and her family as salt-of-the-earth middle-class types.�� [War Room/Salon]\n",
      "\n",
      "• Emily Bazelon contends that\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " the campaign has done to portray[[ Palin]] and her family as salt-of-the-earth middle-class types.�� [War Room/Salon]\n",
      "\n",
      "• Emily Bazelon[[ contends]]<< that>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 17:\n",
      "- Base Text -\n",
      "=================================================\n",
      " Jesse needs someone to look up to, but the Season 4 finale left more questions than answers for the pair.\n",
      "\n",
      "Walter has consistently betrayed Jesse throughout the series, and the shocking end to Season 4 proved just that, as we found out that it was Walt who poisoned Brock (Ian Posada). Jesse may not know the truth yet, but how does actor Aaron Paul feel about Walter's betrayal?\n",
      "\n",
      "\"Shame on Walt,\"\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " Jesse needs someone to look up to, but the Season 4 finale left more questions than answers for the pair.\n",
      "\n",
      "Walter has consistently betrayed Jesse throughout the series, and the shocking end to Season 4 proved just that, as we found out that it was Walt who poisoned Brock (Ian Posada). Jesse may not know the truth yet, but how[[ does]][[ actor]][[ Aaron]][[ Paul]] feel about Walter's betrayal?\n",
      "\n",
      "[[\"]]Shame on Walt<<,\">>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 18:\n",
      "- Base Text -\n",
      "=================================================\n",
      " Jesse needs someone to look up to, but the Season 4 finale left more questions than answers for the pair.\n",
      "\n",
      "Walter has consistently betrayed Jesse throughout the series, and the shocking end to Season 4 proved just that, as we found out that it was Walt who poisoned Brock (Ian Posada). Jesse may not know the truth yet, but how does actor Aaron Paul feel about Walter's betrayal?\n",
      "\n",
      "\"Shame on Walt,\" Paul told Vulture, while promoting his new film \"Smashed\" at Sundance.\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " Jesse needs someone to look up to, but the Season 4 finale left more questions than answers for the pair.\n",
      "\n",
      "Walter has consistently betrayed Jesse throughout the series, and the shocking end to Season 4 proved just that, as we found out that it was Walt who poisoned Brock (Ian Posada). Jesse may not know the truth yet, but how[[ does]][[ actor]][[ Aaron]][[ Paul]] feel about Walter's betrayal?[[\n",
      "]][[\n",
      "]]\"Shame on Walt[[,\"]] Paul told Vulture, while promoting his new film \"Smashed\" at Sundance<<.>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 19:\n",
      "- Base Text -\n",
      "=================================================\n",
      " all the horrible things that he did, oh my God. I love that they��re back together, but it��s always been such a back-and-forth struggle, a love-hate relationship.\"\n",
      "\n",
      "However, for Paul, he believes that the dynamic crime duo ultimately respect one another, even though they can't seem to trust each other.\n",
      "\n",
      "\"But I think at the end, in the parking lot, I think they��re there for each other,\"\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " all the horrible things that he did, oh my God. I love that they��re back together, but it��s always been such a back-and-forth struggle, a love-hate relationship.\"\n",
      "\n",
      "However,[[ for]][[ Paul]][[,]] he believes that the dynamic crime duo ultimately respect one another, even though they can't seem to trust each other.\n",
      "\n",
      "\"But I think at the end, in the parking lot, I think they��re there for each other<<,\">>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 20:\n",
      "- Base Text -\n",
      "=================================================\n",
      " provide direct sales tax refunds to consumers in the context of class action settlements.�� In other words, it won��t refund sales tax collected on the purchase of an affected diesel VW.\n",
      "\n",
      "Sign up for the Avalara newsletter and stay up-to-date on sales tax news.<|endoftext|>After the Los Angeles Clippers�� 127-95 Monday rout of the Brooklyn Nets, it��s clear the team has the ��singular focus�� Chris Paul referenced after the game.\n",
      "\n",
      "\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " provide direct sales tax refunds to consumers in the context of class action settlements.�� In other words, it won��t refund sales tax collected on the purchase of an affected diesel VW.\n",
      "\n",
      "Sign up for the Avalara newsletter and stay up-to-date on sales tax news.[[<|endoftext|>]]After the Los Angeles Clippers�� 127-95 Monday rout of the Brooklyn Nets, it��s clear the team has the ��singular focus��[[ Chris]][[ Paul]][[ referenced]] after the game.\n",
      "<<\n",
      ">>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 21:\n",
      "- Base Text -\n",
      "=================================================\n",
      " provide direct sales tax refunds to consumers in the context of class action settlements.�� In other words, it won��t refund sales tax collected on the purchase of an affected diesel VW.\n",
      "\n",
      "Sign up for the Avalara newsletter and stay up-to-date on sales tax news.<|endoftext|>After the Los Angeles Clippers�� 127-95 Monday rout of the Brooklyn Nets, it��s clear the team has the ��singular focus�� Chris Paul referenced after the game.\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " provide direct sales tax refunds to consumers in the context of class action settlements.�� In other words, it won��t refund sales tax collected on the purchase of an affected diesel VW.\n",
      "\n",
      "Sign up for the Avalara newsletter and stay up-to-date on sales tax news.<|endoftext|>After the Los Angeles Clippers�� 127-95 Monday rout of the Brooklyn Nets, it��s clear the team has the ��singular focus��[[ Chris]][[ Paul]] referenced after the[[ game]]<<.>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 22:\n",
      "- Base Text -\n",
      "=================================================\n",
      "ling panda. The different spot patterns may be a reference to red pandas, which also have their own unique facial markings.\n",
      "\n",
      "Name origin\n",
      "\n",
      "Spinda is a combination of spin (referring to its twirly eyes and ears and dizzy-seeming movement) and panda.\n",
      "\n",
      "Patcheel may be a combination of patch (referring to its appearance) and reel (to stagger, as from dizziness).\n",
      "\n",
      "In other languages\n",
      "\n",
      "Language Title Meaning Japanese ��ッチール Patcheel From patch and reel French Spinda Same as English name\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "ling panda. The different spot patterns may be a reference to red pandas, which also have their own unique facial markings.\n",
      "\n",
      "[[Name]][[ origin]]\n",
      "\n",
      "Spinda is a combination of spin (referring to its twirly eyes and ears and dizzy-seeming movement) and panda.\n",
      "\n",
      "Patcheel may be a combination of patch (referring to its appearance) and reel (to stagger, as from dizziness).\n",
      "\n",
      "In other languages\n",
      "\n",
      "Language Title Meaning[[ Japanese]] ��ッチール Patcheel From patch and reel[[ French]] Spinda Same as English<< name>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 23:\n",
      "- Base Text -\n",
      "=================================================\n",
      "��t really heroic at all, in fact, while Danny Rand is. Elektra, in all her portrayals, is an amoral killer who��s a foil for Matt Murdock��s morality, and in this particular portrayal she��s some sort of inherently evil demonic killing machine. Danny Rand, by contrast, is an ordinary likable guy in over his head trying to do his best—the kind of Everyman hero we��re used to seeing played by white guys named Chris.\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "��t really heroic at all, in fact, while Danny Rand is. Elektra, in all her portrayals, is an amoral killer who��s a foil for Matt Murdock��s morality, and in this particular portrayal she��s some sort of inherently evil demonic killing machine. Danny Rand, by contrast, is an ordinary likable guy in over his head trying to do his best—the kind of Everyman hero we��re used to seeing played by white guys named Chris<<.>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 24:\n",
      "- Base Text -\n",
      "=================================================\n",
      " (but predictable) geisha fantasies. The producers know that making Daredevil��s femme fatale a sexy ninja girl from the Orient would be playing directly into the preferences of a certain genus of skeevy nerd. They knew it would be, as the kids say these days, a bad look. They poked fun at themselves for doing it. But they did it anyway.\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " (but predictable) geisha fantasies. The producers know that making[[ Daredevil]]��s femme fatale a sexy ninja girl from the Orient would be playing directly into the preferences of a certain genus of skeevy nerd. They knew it would be, as the kids say these days, a bad look. They poked fun at themselves for doing it. But they[[ did]] it[[ anyway]]<<.>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 25:\n",
      "- Base Text -\n",
      "=================================================\n",
      "��t really heroic at all, in fact, while Danny Rand is. Elektra, in all her portrayals, is an amoral killer who��s a foil for Matt Murdock��s morality, and in this particular portrayal she��s some sort of inherently evil demonic killing machine.\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "��t really heroic at all, in fact, while Danny Rand is. Elektra, in all her portrayals, is an amoral killer who��s a foil for Matt Murdock��s morality, and in this particular portrayal she��s some sort of inherently evil demonic killing machine<<.>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 26:\n",
      "- Base Text -\n",
      "=================================================\n",
      " Jesse needs someone to look up to, but the Season 4 finale left more questions than answers for the pair.\n",
      "\n",
      "Walter has consistently betrayed Jesse throughout the series, and the shocking end to Season 4 proved just that, as we found out that it was Walt who poisoned Brock (Ian Posada). Jesse may not know the truth yet, but how does actor Aaron Paul feel about Walter's betrayal?\n",
      "\n",
      "\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " Jesse needs someone to look up to, but the Season 4 finale left more questions than answers for the pair.\n",
      "\n",
      "Walter has consistently betrayed Jesse throughout the series, and the shocking end to Season 4 proved just that, as we found out that it was Walt who poisoned Brock (Ian Posada). Jesse[[ may]][[ not]] know the truth yet,[[ but]][[ how]] does actor Aaron Paul feel about Walter's betrayal[[?]][[\n",
      "]]<<\n",
      ">>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 27:\n",
      "- Base Text -\n",
      "=================================================\n",
      " McCain campaign as a newborn fawn, the recent distractions coming from Sarah Palin can��t be helpful. The maverick governor apologized yesterday for her remark about the ��pro-America�� parts of the country. Then she gave a dubious answer to a third-grader��s question about the role of the vice-president in the United States government.\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " McCain campaign as a newborn fawn, the recent distractions coming from Sarah Palin can��t be helpful. The maverick governor apologized yesterday for her remark about the ��pro-America�� parts of the country. Then she gave a dubious answer to a third-grader��s question about the role of the vice-president in the United States government<<.>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 28:\n",
      "- Base Text -\n",
      "=================================================\n",
      " McCain campaign as a newborn fawn, the recent distractions coming from Sarah Palin can��t be helpful. The maverick governor apologized yesterday for her remark about the ��pro-America�� parts of the country. Then she gave a dubious answer to a third-grader��s question about the role of the vice-president in the United States government. Meanwhile, an AP investigation found that she charged the Alaska government for her kids�� travel expenses, and a new NBC/WSJ poll shows that Palin��s qualifications are voters�� No. 1 concern about\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " McCain campaign as a newborn fawn, the recent distractions coming from[[ Sarah]] Palin can��t be helpful. The maverick governor apologized yesterday for her remark about the ��pro-America�� parts of the country. Then she gave a dubious answer to a third-grader��s question about the role of the vice-president in the United States government. Meanwhile, an AP investigation found that she charged the Alaska government for her kids�� travel expenses, and a new NBC/WSJ poll shows that Palin��s qualifications are voters�� No. 1[[ concern]]<< about>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 29:\n",
      "- Base Text -\n",
      "=================================================\n",
      " McCain campaign as a newborn fawn, the recent distractions coming from Sarah Palin can��t be helpful.\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " McCain campaign as a newborn fawn, the recent distractions coming from Sarah Palin can[[�]]�t be helpful<<.>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 30:\n",
      "- Base Text -\n",
      "=================================================\n",
      " McCain campaign as a newborn fawn, the recent distractions coming from Sarah Palin can��t be helpful. The maverick governor apologized yesterday for her remark about the ��pro-America�� parts of the country.\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " McCain campaign as a newborn fawn, the recent distractions coming from[[ Sarah]] Palin can��t be helpful. The maverick governor apologized yesterday for her remark about the ��pro-America�� parts of the country<<.>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 31:\n",
      "- Base Text -\n",
      "=================================================\n",
      " Materials journal and discusses a newly found herringbone structure that has never been documented in nature that is contained within the outer layer of the dactyl club appendage. The structure shields the club upon impact and allows the mantis shrimp to cause an astounding amount of damage.\n",
      "\n",
      "Mantis shrimp come in two forms, ��smashers�� and ��spearers��.\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " Materials journal and discusses a newly found herringbone structure that has never been documented in nature that is contained within the outer layer of the dactyl club appendage. The structure shields the club upon impact and allows the mantis shrimp to cause an astounding amount of damage.[[\n",
      "]]\n",
      "Mantis shrimp come in[[ two]][[ forms]],[[ �]]�[[s]]mashers�� and ��spe[[arers]]��<<.>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 32:\n",
      "- Base Text -\n",
      "=================================================\n",
      " opened 30.93 points higher at 8,779.40.\n",
      "\n",
      "11.15am: The currency market is trading despite the ASX glitch. The Australian Dollar is currently buying US$1.0418, 74 Euro cents, 65 British pence, and 79.398 Yen. 11.13am: Chi-X, the rival trading market, is due to start soon too. Presumably they won't mind if the halt lasts all day. 11.11\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " opened 30.93 points higher at 8,[[779]].40.\n",
      "\n",
      "11.15am[[:]] The currency market is trading despite the ASX glitch. The Australian Dollar is currently buying US$1.0418, 74 Euro cents, 65 British pence, and 79.398 Yen. 11.[[13]][[am]][[:]] Chi-X, the rival trading market, is due to start soon too. Presumably they won't mind if the halt lasts all day.[[ 11]][[.]]<<11>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 33:\n",
      "- Base Text -\n",
      "=================================================\n",
      " opened 30.93 points higher at 8,779.40.\n",
      "\n",
      "11.15am: The currency market is trading despite the ASX glitch. The Australian Dollar is currently buying US$1.0418, 74 Euro cents, 65 British pence, and 79.398 Yen. 11.13\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " opened 30.93 points higher at 8,779.40.\n",
      "\n",
      "11.15[[am]]: The currency market is trading despite the ASX glitch. The Australian Dollar is currently buying US$1.0418, 74 Euro cents, 65 British pence, and 79.398 Yen. 11.<<13>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 34:\n",
      "- Base Text -\n",
      "=================================================\n",
      "\n",
      "\n",
      ">>> ��Testing amateurs is morally dubious��\n",
      "\n",
      "So why isn��t\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "\n",
      "\n",
      ">>> ��[[Testing]][[ am]]ateurs is morally[[ dubious]]��\n",
      "\n",
      "So[[ why]][[ isn]]�[[�]]<<t>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 35:\n",
      "- Base Text -\n",
      "=================================================\n",
      " the mining industry in NSW, particularly in the Hunter Valley. The study is expected to be concluded in the fourth quarter of calendar 2012.\n",
      "\n",
      "11.45am: Gold miner Newcrest says volatility in global markets and financial concerns in Europe and the United States will likely support a strong gold price in the short and medium term. Newcrest is in a healthy financial position with strong profit margins and low debt, chairman Don Mercer has told the company��s annual general meeting. 11.41\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " the mining industry in NSW, particularly in the Hunter Valley. The study is expected to be concluded in the fourth quarter of calendar 2012.\n",
      "\n",
      "11.45[[am]][[:]] Gold miner Newcrest says volatility in global markets and financial concerns in Europe and the United States will likely support a strong gold price in the short and medium term. Newcrest is in a healthy financial position with strong profit margins and low debt, chairman Don Mercer has told the company��s annual general meeting.[[ 11]].<<41>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 36:\n",
      "- Base Text -\n",
      "=================================================\n",
      "half. 11.31am: GPT Group says it is on track to increase full year operating earnings by seven per cent on what the property investor says is the high quality of its portfolio. GPT says the increase in operating earnings was well above the target of the CPI plus one per cent. Total shareholder return for GPT for the rolling 12 months to 30 September 2011 was 12.7 per cent. GPT said occupancy at its retail properties was at 99.9 per cent, office occupancy was at 97.5 per cent and industrial occupancy was at 100 per cent, as of September 30. 11.25\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "half. 11.31[[am]]: GPT Group says it is on track to increase full year operating earnings by seven per cent on what the property investor says is the high quality of its portfolio. GPT says the increase in operating earnings was well above the target of the CPI plus one per cent. Total shareholder return for GPT for the rolling 12 months to 30 September 2011 was 12.7 per cent. GPT said occupancy at its retail properties was at 99.9 per cent, office occupancy was at 97.5 per cent and industrial occupancy was at 100 per cent, as of September 30. 11.<<25>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 37:\n",
      "- Base Text -\n",
      "=================================================\n",
      " existing anti-smoking ordinance, tobacco and drug paraphernalia shops were already required to ban minors from entering alone. The vote on Wednesday modified that ordinance to include businesses that sell e-cigarettes and devote more than a two foot by four foot section of shelf space for the devices.\n",
      "\n",
      "There are 124 businesses — including gas stations and convenience stores — in Oceanside that have licenses to sell\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " existing anti-smoking ordinance, tobacco[[ and]] drug parap[[hern]][[alia]] shops were already required to ban minors from entering alone. The vote on Wednesday modified that ordinance to include businesses that[[ sell]][[ e]]-[[cigarettes]] and devote more than a two foot by four foot section of shelf space for the devices.\n",
      "\n",
      "There are 124 businesses — including gas stations and convenience stores — in Oceanside that have licenses to<< sell>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 38:\n",
      "- Base Text -\n",
      "=================================================\n",
      " level\n",
      "\n",
      "Summoners can make their minotaur drop their weapon\n",
      "\n",
      "Fix projectiles in flight from actors that died using Cease to Exist\n",
      "\n",
      "Elementals are now stun/blind/confusion/knockback immune\n",
      "\n",
      "C\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " level\n",
      "\n",
      "Summoners can make their minotaur drop their weapon\n",
      "\n",
      "Fix projectiles in flight from actors that died using[[ Ce]]ase to Exist\n",
      "\n",
      "Elementals are now stun/blind/confusion/knockback immune\n",
      "\n",
      "<<C>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 39:\n",
      "- Base Text -\n",
      "=================================================\n",
      " truck ploughs into crowd of people in Nice 'Omg terrorist attack': Panicked onlooker films crowds running\n",
      "\n",
      "SHARE PICTURE\n",
      "\n",
      "Copy link to paste in your message +57 A major police operation is ongoing in Munich, around the city's Olympic Park, with the force warning people to stay in their homes and avoid public spaces as they admitted they don't know where the gunmen\n",
      "\n",
      "SHARE PICTURE\n",
      "\n",
      "Copy link to paste in your message +57 Police officers respond to a shooting at the Olympia Einkaufzentrum (\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " truck ploughs into crowd of people in Nice 'Omg terrorist attack': Panicked onlooker films crowds running\n",
      "\n",
      "SHARE PICTURE\n",
      "\n",
      "Copy link to paste in your message +57 A major police operation is ongoing in Munich, around the city's Olympic Park, with the force warning people to stay in their homes and avoid public spaces as they admitted they don't know where the gunmen\n",
      "\n",
      "SHARE PICTURE\n",
      "\n",
      "Copy link to paste in your message +57 Police officers respond to a shooting at the Olympia[[ E]][[ink]]aufzent[[rum]]<< (>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 40:\n",
      "- Base Text -\n",
      "=================================================\n",
      " have a pro-Russian government. The Germans won't be playing much of a role in the diplomatic wrangling over the next few weeks even if Chancellor Angela Merkel's summit meeting with Medvedev in Sochi on Friday does focus solely on the Georgian question. German foreign ministry state secretary Gernot Erler defended the meeting by saying Medvedev was the man to talk to on foreign policy affairs. \"Medvedev takes the decisions,\"\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " have a pro-Russian government. The Germans won't be playing much of a role in the diplomatic wrangling over the next few weeks even if Chancellor Angela Merkel's summit meeting with Medvedev in Sochi on Friday does focus solely on the Georgian question. German foreign ministry state secretary Gernot[[ Er]]ler defended the meeting by saying Medvedev was the man to talk to on foreign policy affairs.[[ \"]]Medvedev takes the decisions<<,\">>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 41:\n",
      "- Base Text -\n",
      "=================================================\n",
      "4 pre-order customers offering them the chance to upgrade to the \"Mega Bundle\".\n",
      "\n",
      "ShopTo is selling the bundle, which includes a PS4, Killzone: Shadow Fall, two DualShock controllers and the new PlayStation Camera, for £449.86, just a few pence cheaper than GAME.\n",
      "\n",
      "\"ShopTo is pleased to announce that we have started sending out e-mails to the lucky customers who are eligible to swap to the PS4 'Mega Bundle',\" reads a statement on the ShopTo website. \"So keep an eye on your inbox.\n",
      "\n",
      "\"If you don't receive an\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "4 pre-order customers offering them the chance to upgrade to the \"Mega Bundle\".\n",
      "\n",
      "ShopTo is selling the bundle, which includes a PS4, Killzone: Shadow Fall, two DualShock controllers and the new PlayStation Camera, for £449.86, just a few pence cheaper than GAME.\n",
      "\n",
      "\"ShopTo is pleased to announce that we have started[[ sending]] out[[ e]]-[[mails]] to the lucky customers who are eligible to swap to the PS4 'Mega[[ Bundle]]',\" reads a statement on the ShopTo website. \"So keep an eye on your inbox.\n",
      "\n",
      "\"If you don't[[ receive]]<< an>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 42:\n",
      "- Base Text -\n",
      "=================================================\n",
      " of mycorrhizal fungi, particularly truffles. Tradd Cotter, owner of Mushroom Mountain, a mushroom farm and research laboratory in South Carolina. Tradd is author of the book Organic Mushroom Farming and Mycoremediation./td> Roy Halling, curator of mycology at the New York Botanical Garden. Roy works on mushroom systematics and mycogeography, with a particular focus on boletes. Mark Jones, CEO of Sharondale Mushroom Farm near Charlottesville, VA.\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " of mycorrhizal fungi, particularly truffles. Tradd Cotter, owner of Mushroom Mountain, a mushroom farm and research laboratory in South Carolina. Tradd is author of the book Organic Mushroom Farming and Mycoremediation./td>[[ Roy]][[ Hall]]ing, curator of mycology at the New York Botanical Garden.[[ Roy]] works on mushroom systematics and mycogeography, with a particular focus on boletes.[[ Mark]] Jones, CEO of Sharondale Mushroom Farm near Charlottesville,[[ VA]]<<.>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 43:\n",
      "- Base Text -\n",
      "=================================================\n",
      " correct values for denormals, and SCALE-FLOAT scales denormals correctly. EXT:UNIX-NAMESTRING no longer returns NIL if a directory does not exist. This was a regression from at least 18a.\n",
      "\n",
      "Trac Tickets: Ticket #90 fixed. Ticket #92 marked invalid.. Ticket #87\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " correct values for denormals, and SCALE-FLOAT scales denormals correctly. EXT:UNIX-NAMESTRING no longer returns NIL if a directory does not exist. This was a regression from at least 18a.\n",
      "\n",
      "Trac Tickets: Ticket[[ #]]90 fixed. Ticket[[ #]][[92]][[ marked]] invalid.. Ticket[[ #]]<<87>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 44:\n",
      "- Base Text -\n",
      "=================================================\n",
      " correct values for denormals, and SCALE-FLOAT scales denormals correctly. EXT:UNIX-NAMESTRING no longer returns NIL if a directory does not exist. This was a regression from at least 18a.\n",
      "\n",
      "Trac Tickets: Ticket #90 fixed. Ticket #92 marked invalid.. Ticket #87 fixed. Ticket #94\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " correct values for denormals, and SCALE-FLOAT scales denormals correctly. EXT:UNIX-NAMESTRING no longer returns NIL if a directory does not exist. This was a regression from at least 18a.\n",
      "\n",
      "Trac Tickets: Ticket[[ #]]90 fixed. Ticket[[ #]][[92]][[ marked]] invalid.. Ticket #87 fixed. Ticket[[ #]]<<94>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 45:\n",
      "- Base Text -\n",
      "=================================================\n",
      " correct values for denormals, and SCALE-FLOAT scales denormals correctly. EXT:UNIX-NAMESTRING no longer returns NIL if a directory does not exist. This was a regression from at least 18a.\n",
      "\n",
      "Trac Tickets: Ticket #90 fixed. Ticket #92 marked invalid.. Ticket #87 fixed. Ticket #94 fixed. Ticket #93 fixed. Ticket #98\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " correct values for denormals, and SCALE-FLOAT scales denormals correctly. EXT:UNIX-NAMESTRING no longer returns NIL if a directory does not exist. This was a regression from at least 18a.\n",
      "\n",
      "Trac Tickets: Ticket[[ #]]90 fixed. Ticket[[ #]][[92]][[ marked]] invalid.. Ticket #87 fixed. Ticket #94 fixed. Ticket #93 fixed. Ticket[[ #]]<<98>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 46:\n",
      "- Base Text -\n",
      "=================================================\n",
      "OPP) says the moose has now moved away from the highway and OPP have cleared the scene. York regional police and Ministry of Natural Resources officers remain on scene and are monitoring the situation.\n",
      "\n",
      "No injuries have been reported.\n",
      "\n",
      "The mayor of Markham tweeted asking people to be cautious and respectful.\n",
      "\n",
      "Please be cautious and on the lookout for #MooseOnTheLoose in our city, drive carefully, do not approach and let the experts handle this. @YRP @OPP_HSD @ONresources Hopefully this ends safely for all, including the moose. — Mayor\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "OPP) says the moose has now moved away from the highway and OPP have cleared the scene. York regional police and Ministry of Natural Resources officers remain on scene and are monitoring the situation.\n",
      "\n",
      "No injuries have been reported.\n",
      "\n",
      "The mayor of[[ Mark]]ham tweeted asking people to be cautious and respectful.\n",
      "\n",
      "Please be cautious and on the lookout for #MooseOnTheLoose in our city, drive carefully, do not approach and let the experts handle this. @YRP @OPP_HSD @ONresources Hopefully this ends safely for all, including the moose. —<< Mayor>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 47:\n",
      "- Base Text -\n",
      "=================================================\n",
      "—and you're really thirsty. If you decide not to open the packet, your dog sinks his teeth into it. Now your cute little poodle has become a ferocious vampire dog! Can you save your pooch before he bites off more than he can chew?\n",
      "\n",
      "16 Secret Agent Grandma April 1997 131 Will the Real Grandma Please Stay Alive! Your parents are going away so your super-cool grandma is coming to stay with you. But when you go to meet\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "—and you're really thirsty. If you decide not to open the packet, your dog sinks his teeth into it. Now your cute little poodle has become a ferocious vampire dog! Can you save your pooch before he bites off more than he can chew?\n",
      "\n",
      "16 Secret Agent Grandma April 1997 131 Will the Real Grandma Please Stay Alive! Your parents are going away so your super-cool[[ grandma]] is[[ coming]][[ to]] stay with you. But when you go to<< meet>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 48:\n",
      "- Base Text -\n",
      "=================================================\n",
      " is sung. Even the mutant in the Mutant Enemy trademark at the very end of the credits sings. That name, by the way, comes from a line in the song ��And You, And I�� by Yes.\n",
      "\n",
      "18. Vera Wang designed Buffy��s wedding dress in ��The Prom��, as well as the dress that Sarah Michelle Gellar wore to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " is sung. Even the mutant in the Mutant Enemy trademark at the very end of the credits sings. That name, by the way, comes from a line in the song ��And You, And I�� by Yes.\n",
      "\n",
      "18. Vera Wang designed Buffy��s wedding dress in ��The Prom��, as well as the[[ dress]][[ that]] Sarah Michelle G[[ellar]] wore<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 49:\n",
      "- Base Text -\n",
      "=================================================\n",
      "ling panda. The different spot patterns may be a reference to red pandas, which also have their own unique facial markings.\n",
      "\n",
      "Name origin\n",
      "\n",
      "Spinda is a combination of spin (referring to its twirly eyes and ears and dizzy-seeming movement) and panda.\n",
      "\n",
      "Patcheel may be a combination of patch (referring to its appearance) and reel (to stagger, as from dizziness).\n",
      "\n",
      "In other languages\n",
      "\n",
      "Language Title Meaning Japanese ��ッチール Patcheel From patch and reel French Spinda Same as English name\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "ling panda. The different spot patterns may be a reference to red pandas, which also have their own unique facial markings.\n",
      "\n",
      "[[Name]][[ origin]]\n",
      "\n",
      "Spinda is a combination of spin (referring to its twirly eyes and ears and dizzy-seeming movement) and panda.\n",
      "\n",
      "Patcheel may be a combination of patch (referring to its appearance) and reel (to stagger, as from dizziness).\n",
      "\n",
      "In other languages\n",
      "\n",
      "Language Title Meaning[[ Japanese]] ��ッチール Patcheel From patch and reel[[ French]] Spinda Same as English<< name>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 50:\n",
      "- Base Text -\n",
      "=================================================\n",
      "—and you're really thirsty. If you decide not to open the packet, your dog sinks his teeth into it. Now your cute little poodle has become a ferocious vampire dog! Can you save your pooch before he bites off more than he can chew?\n",
      "\n",
      "16 Secret Agent Grandma April 1997 131 Will the Real Grandma Please Stay Alive! Your parents are going away so your super-cool grandma is coming to stay with you. But when\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "—and you're really thirsty. If you decide not to open the packet, your dog sinks his teeth into it. Now your cute little poodle has become a ferocious vampire dog! Can you save your pooch before he bites off more than he can chew?\n",
      "\n",
      "16 Secret Agent Grandma April 1997 131 Will the Real Grandma Please Stay Alive! Your parents are going away so your super-cool grandma is coming to stay with you. But<< when>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 51:\n",
      "- Base Text -\n",
      "=================================================\n",
      " is sung. Even the mutant in the Mutant Enemy trademark at the very end of the credits sings. That name, by the way, comes from a line in the song ��And You, And I�� by Yes.\n",
      "\n",
      "18. Vera Wang designed Buffy��s wedding dress in ��The Prom��, as well as the dress that Sarah Michelle Gellar wore to her\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " is sung. Even the mutant in the Mutant Enemy trademark at the very end of the credits sings. That name, by the way, comes from a line in the song ��And You, And I�� by Yes.\n",
      "\n",
      "18. Vera Wang designed Buffy��s wedding dress in ��The Prom��, as well as the[[ dress]][[ that]] Sarah Michelle G[[ellar]] wore[[ to]]<< her>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 52:\n",
      "- Base Text -\n",
      "=================================================\n",
      " 10 ]. When taken concomitantly, St. John's wort can render many medications less effective; the clinical consequences of which may be severe [ 11 , 12 ]. The phytochemical culprit underlying St.\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " 10 ]. When taken concomitantly, St.[[ John]]'s wort can render many medications less effective; the clinical consequences of which may be severe [ 11 , 12 ]. The phytochemical culprit[[ underlying]] St<<.>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 53:\n",
      "- Base Text -\n",
      "=================================================\n",
      " 10 ]. When taken concomitantly, St. John's wort can render many medications less effective; the clinical consequences of which may be severe [ 11 , 12 ]. The phytochemical culprit underlying St\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " 10 ]. When taken concomitantly,[[ St]].[[ John]]'s wort can render many medications less effective; the clinical consequences of which may be severe [ 11 , 12 ]. The phytochemical culprit underlying<< St>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 54:\n",
      "- Base Text -\n",
      "=================================================\n",
      ". In this study we describe the effects of six top-selling botanical supplements (black cohosh, Echinacea, goldenseal, kava kava, milk thistle, and St. John's wort) on the activity of human CYP2D6 in vivo using a validated phenotyping technique, the debrisoquine urinary recovery ratio (DURR) [ 32 , 44 - 47 ].\n",
      "\n",
      "To date, the most recognized botanical supplement associated with CYP450-mediated herb-drug interactions is St\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      ". In this study we describe the effects of six top-selling botanical supplements (black cohosh, Echinacea, goldenseal, kava kava, milk thistle, and[[ St]].[[ John]]'s wort) on the activity of human CYP2D6 in vivo using a validated phenotyping technique, the debrisoquine urinary recovery ratio (DURR) [ 32 , 44 - 47 ].\n",
      "\n",
      "To date, the most recognized botanical supplement associated with CYP450-mediated herb-drug interactions is<< St>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 55:\n",
      "- Base Text -\n",
      "=================================================\n",
      "rd06.prod.outlook.com ([10.162.224.139]) by BLUPR06MB1729.namprd06.prod.outlook.com ([10.162.224.139]) with mapi id 15.01.0427.019; Sat, 5 Mar 2016 17:05:29 +0000 From: Josh Fidler <JOSH@chesapeakerealtypartners.com> To: \"john.podesta@gmail.com\" <\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "rd06.prod.outlook.com ([10.162.224.139]) by BLUPR06MB1729.namprd06.prod.outlook.com ([10.162.224.139]) with mapi id 15.01.0427.019; Sat, 5 Mar 2016 17:05:29 +0000 From: Josh Fidler <JOSH@chesapeakerealtypartners.com> To: \"[[john]].podesta@gmail.com\"<< <>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 56:\n",
      "- Base Text -\n",
      "=================================================\n",
      " dopers.\n",
      "\n",
      "Even if we halve those odds, three-quarters of races will contain one doper. This may be merely theoretical extrapolation, but it paints a troubling picture nonetheless.\n",
      "\n",
      "We asked UKAD��s director of operations Pat Myhill for his reaction to our survey��s prevalence figures:\n",
      "\n",
      "��There have been lots of studies and speculation on this matter, but actual prevalence is difficult to establish. Does your survey surprise me? Not particularly, no.��\n",
      "\n",
      "\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " dopers.\n",
      "\n",
      "Even if we halve those odds, three-quarters of races will contain one doper. This may be merely theoretical extrapolation, but it paints a troubling picture nonetheless.\n",
      "\n",
      "We asked UKAD��s director of operations Pat[[ My]]hill for his reaction to our survey��s prevalence figures:\n",
      "\n",
      "��There have been lots of studies and speculation on this matter, but actual prevalence is difficult to establish. Does your survey surprise me? Not[[ particularly]], no.�[[�]][[\n",
      "]]<<\n",
      ">>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 57:\n",
      "- Base Text -\n",
      "=================================================\n",
      " and competing.\n",
      "\n",
      "And I, for one, am looking forward to watching them do it.<|endoftext|>Advertisement Men accused of threatening Pokemon championships in court Kevin Norton, James Stumbo, both of Iowa, held on bail Share Shares Copy Link Copy\n",
      "\n",
      "Two Iowa men charged with threatening violence at a Pokemon competition in Boston were ordered held Tuesday on $150,000 bail.Kevin Norton, 18, of Ames, and\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " and competing.\n",
      "\n",
      "And I, for one, am looking forward to watching them do it.<|endoftext|>Advertisement Men accused of threatening[[ Pokemon]] championships in court[[ Kevin]][[ Norton]],[[ James]] Stumbo, both of Iowa, held on bail Share Shares Copy Link Copy\n",
      "\n",
      "Two Iowa[[ men]] charged with threatening violence at a Pokemon competition in Boston were ordered held Tuesday on $150,000 bail[[.]][[Kevin]][[ Norton]][[,]][[ 18]],[[ of]] Ames[[,]]<< and>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 58:\n",
      "- Base Text -\n",
      "=================================================\n",
      "storm we've got to kind of weather it, weather the storm, and I don't think we did a good job of that tonight.\"\n",
      "\n",
      "Deja vu in the fourth quarter.\n",
      "\n",
      "James usually rests at some point in the third so he can recharge before starting the fourth. But out of necessity -- and because of his stellar play --\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "storm we've got to kind of weather it, weather the storm, and I don't think we did a good job of that tonight.\"\n",
      "\n",
      "Deja vu in the fourth quarter.\n",
      "\n",
      "[[James]] usually rests at some point in the third so he can recharge before starting the fourth. But out of[[ necessity]] -- and[[ because]][[ of]][[ his]] stellar play<< -->>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 59:\n",
      "- Base Text -\n",
      "=================================================\n",
      " lineup we had at the end of the third, we had it flowing. We had the ball moving, Channing was knocking down shots, I was getting to the lane creating for others and we had a great end of that quarter. That's the feel of the game T-Lue had right there and it was the right call, going up seven to end the quarter. Obviously I needed to take a break.\"\n",
      "\n",
      "James earned it. He engineered a 22-5 eruption in the final seven minutes of the third period. During that stretch, he scored or assisted on 17 of the team's 22 points. It looked like\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " lineup we had at the end of the third, we had it flowing. We had the ball moving, Channing was knocking down shots, I was getting to the lane creating for others and we had a great end of that quarter. That's the feel of the game T-Lue had right there and it was the right call, going up seven to end the quarter. Obviously I needed to take a break.\"\n",
      "\n",
      "[[James]] earned it. He engineered a 22-5 eruption in the final seven minutes of the third period. During that stretch, he scored or assisted on 17 of the team's 22 points.[[ It]][[ looked]]<< like>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 60:\n",
      "- Base Text -\n",
      "=================================================\n",
      "storm we've got to kind of weather it, weather the storm, and I don't think we did a good job of that tonight.\"\n",
      "\n",
      "Deja vu in the fourth quarter.\n",
      "\n",
      "James usually rests at some point in the third so he can recharge before starting the fourth. But out of necessity -- and because\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "storm we've got to kind of weather it, weather the storm, and I don't think we did a good job of that tonight.\"\n",
      "\n",
      "Deja vu in the fourth quarter.\n",
      "\n",
      "[[James]] usually rests at some point in the third so he can recharge before starting the fourth. But out of necessity -- and<< because>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 61:\n",
      "- Base Text -\n",
      "=================================================\n",
      "storm we've got to kind of weather it, weather the storm, and I don't think we did a good job of that tonight.\"\n",
      "\n",
      "Deja vu in the fourth quarter.\n",
      "\n",
      "James usually rests at some point in the third so he can recharge before starting the fourth. But out of necessity -- and because of his stellar play -- James went the distance in the third, scoring six points and dishing out five (four to Channing Frye) of his game-high 10 assists.\n",
      "\n",
      "\"I just think it was the flow of the game tonight,\"\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "storm we've got to kind of weather it, weather the storm, and I don't think we did a good job of that tonight.\"\n",
      "\n",
      "Deja vu in the fourth quarter.\n",
      "\n",
      "[[James]] usually rests at some point in the third so he can recharge before starting the fourth. But out of necessity -- and because of his stellar play -- James went the distance in the third, scoring six points and dishing out five (four to Channing Frye) of his game-high 10 assists.\n",
      "\n",
      "\"I just think it was the flow of the game tonight<<,\">>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 62:\n",
      "- Base Text -\n",
      "=================================================\n",
      "icTalk is on Apple News. Favorite us!\n",
      "\n",
      "MORE: 100 Olympic storylines 100 days out from PyeongChang<|endoftext|>Though Florida Governor Rick Scott has recently said he won't privatize state prison operations (something he considered early in his term, which received flak after it was revealed that the conservative's election campaign received $30,000 in contributions from both Corrections Corporation of America and GEO Group), his administration has pushed forward with plans to privatize healthcare services in state prisons and he recently recommended that 14 of the state's publicly operated work release centers should also go to private contractors.\n",
      "\n",
      "Gov.\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "icTalk is on Apple News. Favorite us!\n",
      "\n",
      "MORE: 100 Olympic storylines 100 days out from PyeongChang<|endoftext|>Though Florida Governor Rick[[ Scott]] has recently said he won't privatize state prison operations (something he considered early in his term, which received flak after it was revealed that the conservative's election campaign received $30,000 in contributions from both Corrections Corporation of America and GEO Group), his administration has pushed forward with plans to privatize healthcare services in state prisons and he recently recommended that 14 of the state's publicly operated work release centers should also go to private contractors.\n",
      "\n",
      "[[Gov]]<<.>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 63:\n",
      "- Base Text -\n",
      "=================================================\n",
      "icTalk is on Apple News. Favorite us!\n",
      "\n",
      "MORE: 100 Olympic storylines 100 days out from PyeongChang<|endoftext|>Though Florida Governor Rick Scott has recently said he won't privatize state prison operations (something he considered early in his term, which received flak after it was revealed that the conservative's election campaign received $30,000 in contributions from both Corrections Corporation of America and GEO Group), his administration has pushed forward with plans to privatize healthcare services in state prisons and he recently recommended that 14 of the state's publicly operated work release centers should also go to private contractors.\n",
      "\n",
      "Gov\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "icTalk is on Apple News. Favorite us!\n",
      "\n",
      "MORE: 100 Olympic storylines 100 days out from PyeongChang<|endoftext|>Though Florida Governor Rick[[ Scott]] has recently said he won't privatize state prison operations (something he considered early in his term, which received flak after it was revealed that the conservative's election campaign received $30,000 in contributions from both Corrections Corporation of America and GEO Group), his administration has pushed forward with plans to privatize healthcare services in state prisons and he recently recommended that 14 of the state's publicly operated work release centers should also go to private contractors.\n",
      "\n",
      "<<Gov>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 64:\n",
      "- Base Text -\n",
      "=================================================\n",
      "icTalk is on Apple News. Favorite us!\n",
      "\n",
      "MORE: 100 Olympic storylines 100 days out from PyeongChang<|endoftext|>Though Florida Governor Rick Scott has recently said he won't privatize state prison operations (something\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "icTalk is on Apple News. Favorite us!\n",
      "\n",
      "MORE: 100 Olympic storylines 100 days out from PyeongChang<|endoftext|>Though Florida Governor Rick[[ Scott]] has recently said he won't privatize state prison operations (<<something>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 65:\n",
      "- Base Text -\n",
      "=================================================\n",
      "icTalk is on Apple News. Favorite us!\n",
      "\n",
      "MORE: 100 Olympic storylines 100 days out from PyeongChang<|endoftext|>Though Florida Governor Rick Scott has recently said he won't privatize state prison operations (something he considered early in his term, which received flak after it was revealed that the conservative's election campaign received $30,000 in contributions from both Corrections Corporation of America and GEO Group), his administration has pushed forward with plans to privatize healthcare services in state prisons and he recently recommended that 14 of the state's publicly operated work release centers should also go to private contractors.\n",
      "\n",
      "\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "icTalk is on Apple News. Favorite us!\n",
      "\n",
      "MORE: 100 Olympic storylines 100 days out from PyeongChang[[<|endoftext|>]]Though Florida Governor Rick[[ Scott]] has recently said he won't privatize state prison operations (something he considered early in his term, which received flak after it was revealed that the conservative's election campaign received $30,000 in contributions from both Corrections Corporation of America and GEO Group), his administration has pushed forward with plans to privatize healthcare services in state prisons and he recently recommended that 14 of the state's publicly operated work release centers should also go to private contractors.\n",
      "<<\n",
      ">>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 66:\n",
      "- Base Text -\n",
      "=================================================\n",
      "icTalk is on Apple News. Favorite us!\n",
      "\n",
      "MORE: 100 Olympic storylines 100 days out from PyeongChang<|endoftext|>Though Florida Governor Rick Scott has recently said he won't privatize state prison operations (something he considered early in his term, which received flak after it was revealed that\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "icTalk is on Apple News. Favorite us!\n",
      "\n",
      "MORE: 100 Olympic storylines 100 days out from PyeongChang<|endoftext|>Though Florida Governor Rick[[ Scott]] has recently said he won't privatize state prison operations (something he considered[[ early]][[ in]] his[[ term]], which received flak after it was revealed<< that>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 67:\n",
      "- Base Text -\n",
      "=================================================\n",
      " of the highlights:<|endoftext|>The Prix Goncourt was awarded on Monday by the 10 members of the Academy Goncourt in Paris to Eric Vuillard for having written the best French-language prose work of the preceding year.\n",
      "\n",
      "\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " of the highlights:[[<|endoftext|>]]The Prix Goncourt was awarded on[[ Monday]] by the 10 members of the Academy Goncourt in Paris to[[ Eric]] Vuillard for having written the best French-language prose work of the preceding year.\n",
      "<<\n",
      ">>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 68:\n",
      "- Base Text -\n",
      "=================================================\n",
      " of the highlights:<|endoftext|>The Prix Goncourt was awarded on Monday by the 10 members of the Academy Goncourt in Paris to Eric Vuillard for having written the best French-language prose work of the preceding year.\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " of the highlights:<|endoftext|>[[The]][[ Prix]] Goncourt was[[ awarded]] on Monday by the 10 members of the Academy Goncourt in Paris[[ to]][[ Eric]] Vuillard for having written the best French-language prose work of the preceding[[ year]]<<.>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 69:\n",
      "- Base Text -\n",
      "=================================================\n",
      "ville's life produced. Veronique Olmi's novel \"Bakhita\" tells the story of a 19th-century slave who becomes a nun in Italy. And the fourth finalist, Alice Zeniter, tells the story of a family's tangled, silent history between France and Algeria in \"L'Art de perdre\" (The art of loss).\n",
      "\n",
      "Yannick Haenel, Veronique Olmi, Eric Vuillard and Alice Zeniter were the four finalists for the Prix Goncourt 2017\n",
      "\n",
      "In 2016, French-Moroccan author\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "ville's life produced. Veronique Olmi's novel \"Bakhita\" tells the story of a 19th-century slave who becomes a nun in Italy. And the fourth finalist, Alice Zeniter, tells the story of a family's tangled, silent history between France and Algeria in \"L'Art de perdre\" (The art of loss).\n",
      "\n",
      "Yannick Haenel, Veronique Olmi,[[ Eric]] Vuillard and Alice Zeniter were the four finalists for the Prix Goncourt 2017\n",
      "\n",
      "In 2016, French-Moroccan<< author>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 70:\n",
      "- Base Text -\n",
      "=================================================\n",
      " ��Marilyn Monroe�� feel. It is a floor length halter dress made with flowing chiffon, and has a lace midriff that is also available in black. This dress can be flattering on thin or curvy figures. Style # 6532:\n",
      "\n",
      "Designed by Dessy Bridesmaids, style # 2721. The great thing about this dress is that it��s available in several different colors, including over 50 options for the sash color. This makes it easy to coordinate with your wedding color scheme.\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " ��Marilyn Monroe�� feel. It is a floor length halter dress made with flowing chiffon, and has a lace midriff that is also available in black. This dress can be flattering on thin or curvy figures.[[ Style]][[ #]][[ 65]]32:\n",
      "\n",
      "Designed by Dessy Bridesmaids, style # 2721. The great[[ thing]] about this dress is that it��s available in several different colors, including over 50 options for the sash color.[[ This]] makes it easy to coordinate with your wedding color scheme<<.>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 71:\n",
      "- Base Text -\n",
      "=================================================\n",
      " ��Marilyn Monroe�� feel. It is a floor length halter dress made with flowing chiffon, and has a lace midriff that is also available in black. This dress can be flattering on thin or curvy figures. Style # 6532:\n",
      "\n",
      "Designed by Dessy Bridesmaids, style # 2721. The great thing about this dress is that it��s available in several different colors, including over 50 options for the sash color.\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " ��Marilyn Monroe�� feel. It is a floor length halter dress made with flowing chiffon, and has a lace midriff that is also available in black. This dress can be flattering on thin or curvy figures.[[ Style]][[ #]] 6532:\n",
      "\n",
      "Designed by Dessy Bridesmaids, style # 2721. The great thing about this dress is that it��s available in several different colors, including over 50 options for the sash color<<.>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 72:\n",
      "- Base Text -\n",
      "=================================================\n",
      " custody documents, Johnson is accused of taking her son against his will. A September 11, 1991 affidavit signed by Daniel says that two days earlier, Johnson took him from elementary school ��against my will and made me go to her home.��\n",
      "\n",
      "An affidavit signed by Johnson��s mother claimed that Johnson took Daniel from school ��forcefully and without my permission.��\n",
      "\n",
      "Immediately after the school incident, documented by Moore��s office, Cofield was granted temporary custody of\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "[[ custody]] documents, Johnson is accused of taking her[[ son]] against his will. A September 11, 1991 affidavit signed by Daniel says that two days earlier, Johnson took him from elementary school ��against my will and made me go to her home.��\n",
      "\n",
      "An affidavit signed by Johnson��s mother claimed that Johnson took[[ Daniel]] from school ��forcefully and without my permission.��\n",
      "\n",
      "Immediately after the school incident, documented by Moore��s office, Cofield was granted temporary[[ custody]]<< of>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 73:\n",
      "- Base Text -\n",
      "=================================================\n",
      " Daniel began shouting that there was a 4th time he was on the stage and that was when it happened. We went back and watched the footage we have of the Lamb of God three song encore and found nothing. That doesn��t mean Daniel never was on stage a fourth time, it just means the footage we have didn't capture it as there are a few moments where\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " Daniel began shouting that[[ there]][[ was]] a 4th time he was[[ on]][[ the]] stage and that was when it happened. We went back and watched the footage we have of the Lamb of God three song encore and found nothing. That doesn��t mean[[ Daniel]] never was[[ on]] stage a fourth time, it just means the footage we have didn't capture it[[ as]][[ there]][[ are]][[ a]] few moments<< where>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 74:\n",
      "- Base Text -\n",
      "=================================================\n",
      " this case, we were under the assumption that Randy most likely pushed a kid off the stage and due to a bad fall, ended up in a coma. Fans in attendance have always stated that Daniel was on stage three times. We found three instances of Daniel on stage and Randy barely lays a finger on him. We also showed that a security guard hired by the venue threw Daniel head first into the ground with a lot of force the third time he got on the stage. The video shows Daniel stagger a bit, get up and pass by the camera with a large gash in his head.Following the release of the footage, friends of\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " this case, we were under the assumption that Randy most likely pushed a kid off the stage and due to a bad fall, ended up in a coma. Fans in attendance have always stated[[ that]][[ Daniel]][[ was]] on stage three times. We found three instances of Daniel on stage and Randy barely lays a finger on him. We also showed that a security guard hired by the venue threw Daniel head first into the ground with a lot of force the third time he got on the stage. The video shows Daniel stagger a bit, get up and pass by the camera with a large gash in his head.Following the release[[ of]] the footage,[[ friends]]<< of>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 75:\n",
      "- Base Text -\n",
      "=================================================\n",
      " Daniel began shouting that there was a 4th time he was on the stage and that was when it happened.\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "[[ Daniel]] began shouting that there was a 4th time he was on the stage and[[ that]] was[[ when]] it[[ happened]]<<.>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 76:\n",
      "- Base Text -\n",
      "=================================================\n",
      " this case, we were under the assumption that Randy most likely pushed a kid off the stage and due to a bad fall, ended up in a coma. Fans in attendance have always stated that Daniel was on stage three times. We found three instances of Daniel on stage and Randy barely lays a finger on him. We also showed that\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " this case, we were under the[[ assumption]] that Randy[[ most]] likely[[ pushed]] a kid off the stage and due to a bad fall, ended up in a coma. Fans in attendance have always stated[[ that]][[ Daniel]][[ was]] on stage three times. We found three instances of Daniel on stage and Randy barely lays a finger on him. We also showed<< that>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 77:\n",
      "- Base Text -\n",
      "=================================================\n",
      " Jesse needs someone to look up to, but the Season 4 finale left more questions than answers for the pair.\n",
      "\n",
      "Walter has consistently betrayed Jesse throughout the series, and the shocking end to Season 4 proved just that, as we found out that it was Walt who poisoned Brock (Ian Posada). Jesse may not know the truth yet, but how does actor Aaron Paul feel about Walter's betrayal?\n",
      "\n",
      "\"\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " Jesse needs someone to look up to, but the Season 4 finale left more questions than answers for the pair.\n",
      "\n",
      "Walter has consistently betrayed Jesse throughout the series, and the shocking end to Season 4 proved just that, as we found out that it was Walt who poisoned Brock (Ian Posada). Jesse may not know the truth yet, but how does actor[[ Aaron]] Paul feel about Walter's betrayal?\n",
      "\n",
      "<<\">>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 78:\n",
      "- Base Text -\n",
      "=================================================\n",
      " on behalf of Johnson��s mother, Cofield.\n",
      "\n",
      "Numerous attempts to reach Johnson for comment were unsuccessful.\n",
      "\n",
      "Moore has strenuously denied the numerous accusations against him.\n",
      "\n",
      "Aaron Klein is Breitbart��s Jerusalem bureau chief and senior investigative reporter. He is a New York Times bestselling author and hosts the popular weekend talk radio program, Aaron Klein Investigative Radio. Follow him on Twitter @\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " on behalf of Johnson��s mother, Cofield.\n",
      "\n",
      "Numerous attempts to reach Johnson for comment were unsuccessful.\n",
      "\n",
      "Moore has strenuously denied the numerous accusations against him.\n",
      "\n",
      "[[Aaron]] Klein is Breitbart��s Jerusalem bureau chief and senior investigative reporter. He is a New York Times bestselling author and hosts the popular weekend talk radio program, Aaron Klein Investigative Radio. Follow him on Twitter<< @>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 79:\n",
      "- Base Text -\n",
      "=================================================\n",
      " on behalf of Johnson��s mother, Cofield.\n",
      "\n",
      "Numerous attempts to reach Johnson for comment were unsuccessful.\n",
      "\n",
      "Moore has strenuously denied the numerous accusations against him.\n",
      "\n",
      "Aaron Klein is Breitbart��s Jerusalem bureau chief and senior investigative reporter. He is a New York Times bestselling author and hosts the popular weekend talk radio program, Aaron Klein Investigative Radio. Follow\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " on behalf of Johnson��s mother, Cofield.\n",
      "\n",
      "Numerous attempts to reach Johnson for comment were unsuccessful.\n",
      "\n",
      "Moore has strenuously denied the numerous accusations against him.\n",
      "\n",
      "[[Aaron]] Klein is Breitbart��s Jerusalem bureau chief and senior investigative reporter. He is a New York Times bestselling author and hosts the popular weekend talk radio program, Aaron Klein Investigative Radio.<< Follow>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 80:\n",
      "- Base Text -\n",
      "=================================================\n",
      " Jesse needs someone to look up to, but the Season 4 finale left more questions than answers for the pair.\n",
      "\n",
      "Walter has consistently betrayed Jesse throughout the series, and the shocking end to Season 4 proved just that, as we found out that it was Walt who poisoned Brock (Ian Posada). Jesse may not know the truth yet, but how does actor Aaron Paul feel about Walter's betrayal?\n",
      "\n",
      "\"Shame on Walt,\" Paul told Vulture, while promoting his new film \"Smashed\" at Sundance. \"\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " Jesse needs someone to look up to, but the Season 4 finale left more questions than answers for the pair.\n",
      "\n",
      "Walter has consistently betrayed Jesse throughout the series, and the shocking end to Season 4 proved just that, as we found out that it was Walt who poisoned Brock (Ian Posada). Jesse may not know the truth yet, but how does actor[[ Aaron]] Paul feel about Walter's betrayal?\n",
      "\n",
      "\"Sh[[ame]][[ on]] Walt,\" Paul told Vulture, while promoting his new film \"Smashed\" at[[ Sund]]ance[[.]]<< \">>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 81:\n",
      "- Base Text -\n",
      "=================================================\n",
      " Jesse needs someone to look up to, but the Season 4 finale left more questions than answers for the pair.\n",
      "\n",
      "Walter has consistently betrayed Jesse throughout the series, and the shocking end to Season 4 proved just that, as we found out that it was Walt who poisoned Brock (Ian Posada). Jesse may not know the truth yet, but how does actor Aaron Paul feel about Walter's betrayal?\n",
      "\n",
      "\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " Jesse needs someone to look up to, but the Season 4 finale left more questions than answers for the pair.\n",
      "\n",
      "Walter has consistently betrayed Jesse throughout the series, and the shocking end to Season 4 proved just that, as we found out that it was Walt who poisoned Brock (Ian Posada). Jesse may not know the truth yet, but how does actor[[ Aaron]] Paul feel about Walter's betrayal[[?]][[\n",
      "]]<<\n",
      ">>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 82:\n",
      "- Base Text -\n",
      "=================================================\n",
      " of rust fungi. Alan Bessette, mycologist and professor emeritus of biology at Utica College. Alan and his wife, Arleen, have authored more than 20 books, including Mushrooms of the Southeastern United States. Arleen Bessette, amateur mycologist, photographer, and dyer. With her husband, Alan, Arleen has authored more than 20 books including Rainbow Beneath My Feet: A Mushroom Dyer��s Field Guide. Michael Castellano, researcher at the U.S. Forest Service and associate professor at Oregon State University.\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " of rust fungi. Alan Bessette, mycologist and professor emeritus of biology at Utica College. Alan and his wife, Arleen, have authored more than 20 books, including Mushrooms of the Southeastern United States. Arleen Bessette, amateur mycologist, photographer, and dyer.[[ With]] her husband, Alan, Arleen has authored more than 20 books including Rainbow Beneath My Feet: A Mushroom Dyer��s Field Guide.[[ Michael]][[ Cast]]ellano[[,]] researcher at the U.S. Forest Service and associate professor at Oregon State University<<.>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 83:\n",
      "- Base Text -\n",
      "=================================================\n",
      "\n",
      "43. Everyone makes stupid mistakes. Laugh about them. When we are young and new to restaurants, we all order steak tartare and then get shocked when a plate of bloody, uncooked meat arrives. But like all other stupid mistakes, you should only order steak tartare once.\n",
      "\n",
      "44. A little of what you fancy will always do you good - unless what you fancy is crack.\n",
      "\n",
      "Read next Michael Carrick should be kept on as Manchester United��s next manager Michael Carrick should be kept on as Manchester United��s next manager Why bring in\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "\n",
      "43. Everyone makes stupid mistakes. Laugh about them. When we are young and new to restaurants, we all order steak tartare and then get shocked when a plate of bloody, uncooked meat arrives. But like all other stupid mistakes, you should only order steak tartare once.\n",
      "\n",
      "44. A little of what you fancy will always do you good - unless what you fancy is crack.\n",
      "\n",
      "Read next[[ Michael]] Carrick should be kept on as Manchester United��s next manager Michael Carrick should be kept on as Manchester United��s next manager[[ Why]][[ bring]]<< in>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 84:\n",
      "- Base Text -\n",
      "=================================================\n",
      "\n",
      "43. Everyone makes stupid mistakes. Laugh about them. When we are young and new to restaurants, we all order steak tartare and then get shocked when a plate of bloody, uncooked meat arrives. But like all other stupid mistakes, you should only order steak tartare once.\n",
      "\n",
      "44. A little of what you fancy will always do you good - unless what you fancy is crack.\n",
      "\n",
      "Read next Michael Carrick should be kept on as Manchester United��s next manager\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "\n",
      "43. Everyone makes stupid mistakes. Laugh about them. When we are young and new to restaurants, we all order steak tartare and then get shocked when a plate of bloody, uncooked meat arrives. But like all other stupid mistakes, you should only order steak tartare once.\n",
      "\n",
      "44. A little of what you fancy will always do you good - unless what you fancy is crack.\n",
      "\n",
      "Read[[ next]][[ Michael]] Carrick should be kept on as Manchester United��s[[ next]]<< manager>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 85:\n",
      "- Base Text -\n",
      "=================================================\n",
      "\n",
      "\n",
      "This was a very lucrative business with very vulnerable clients. - Crown attorney Michael Foote\n",
      "\n",
      "\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "\n",
      "[[\n",
      "]]This was a very lucrative business with very vulnerable clients. - Crown attorney[[ Michael]] Foote\n",
      "<<\n",
      ">>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 86:\n",
      "- Base Text -\n",
      "=================================================\n",
      " could be flagging calls and e-mails for interception almost automatically (like GMail deciding what to flag as ��important��), with the analyst occasionally checking off an ��OK�� box.\n",
      "\n",
      "Still, this is more or less what the FISA Amendments Act was designed to do. Shame people didn��t freak out to this extent at the end of 2012, when Congress voted for five more years of it.<|endoftext|>On AMC's hit drama \"Breaking Bad,\" Jesse (Aaron Paul) and Walter (Bryan Cranston) are the perfect poisonous pair. Walt needs\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      " could be flagging calls and e-mails for interception almost automatically (like GMail deciding what to flag as ��important��), with the analyst occasionally checking off an ��OK�� box.\n",
      "\n",
      "Still, this is more or less what the FISA Amendments Act was designed to do. Shame people didn��t freak out to this extent at the end of 2012, when Congress voted for five more years of it.<|endoftext|>On AMC's hit drama \"Breaking Bad,\"[[ Jesse]] (Aaron Paul) and Walter (Bryan Cranston) are the perfect poisonous[[ pair]][[.]][[ Walt]]<< needs>>\n",
      "=================================================\n",
      "\n",
      "\n",
      "\n",
      "IOI Task Examples:\n",
      "                         \n",
      "EXAMPLE 2:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Emily and Charles had a lot of fun at the station. Charles gave a kiss to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "[[Then]],[[ Emily]] and Charles had a lot of fun at the station.[[ Charles]] gave a kiss<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 3:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Aaron and Emily had a lot of fun at the house. Aaron gave a ring to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "[[Then]],[[ Aaron]][[ and]][[ Emily]] had a lot of fun at the house.[[ Aaron]][[ gave]] a ring<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 4:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Emily and Kyle had a lot of fun at the office. Kyle gave a drink to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "[[Then]],[[ Emily]][[ and]][[ Kyle]] had a lot of fun at the office.[[ Kyle]] gave a drink<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 5:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Emily and Christopher had a lot of fun at the garden. Christopher gave a basketball to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "[[Then]],[[ Emily]] and Christopher had a lot of[[ fun]] at the garden[[.]][[ Christopher]][[ gave]] a basketball<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 6:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Emily and Kyle had a lot of fun at the office. Kyle gave\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "[[Then]],[[ Emily]][[ and]][[ Kyle]] had a lot of fun at the office.[[ Kyle]]<< gave>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 7:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Paul and Crystal had a lot of fun at the store. Crystal gave a ring to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Paul]] and[[ Crystal]] had a lot of[[ fun]] at the store.[[ Crystal]] gave a ring<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 8:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Paul and Jacob had a lot of fun at the restaurant. Jacob gave a computer to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Paul]] and[[ Jacob]] had a lot of[[ fun]] at the restaurant.[[ Jacob]] gave a computer<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 9:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Jessica and Paul had a lot of fun at the house. Jessica gave a necklace to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Jessica]][[ and]][[ Paul]] had a lot of[[ fun]] at the house.[[ Jessica]][[ gave]] a necklace<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 10:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Stephen and Paul had a lot of fun at the garden. Stephen gave a drink to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Stephen]][[ and]][[ Paul]] had a lot of fun at the garden.[[ Stephen]] gave a[[ drink]]<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 11:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Paul and Adam had a lot of fun at the office. Adam gave a computer to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Paul]] and Adam had a lot of fun at the office.[[ Adam]] gave a[[ computer]]<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 12:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Jonathan and Sarah had a lot of fun at the station. Jonathan gave a necklace to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Jonathan]][[ and]][[ Sarah]] had a lot of fun at the station.[[ Jonathan]][[ gave]] a necklace<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 13:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Sarah and Ryan had a lot of fun at the hospital. Ryan gave a kiss to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Sarah]] and Ryan had a lot of[[ fun]] at the hospital[[.]][[ Ryan]] gave a kiss<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 14:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Sarah and Tyler had a lot of fun at the hospital. Tyler gave\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Sarah]] and[[ Tyler]] had a lot of fun at the[[ hospital]].[[ Tyler]]<< gave>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 15:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Sarah and Ryan had a lot of fun at the hospital. Ryan gave\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Sarah]] and Ryan had a lot of[[ fun]] at the hospital[[.]][[ Ryan]]<< gave>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 16:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Sarah and Jacob had a lot of fun at the station. Jacob gave a kiss to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "[[Then]],[[ Sarah]][[ and]][[ Jacob]][[ had]] a lot of fun at the station.[[ Jacob]] gave a kiss<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 17:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Jessica and Paul had a lot of fun at the house. Jessica gave a necklace to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Jessica]][[ and]][[ Paul]] had a lot of[[ fun]] at the house.[[ Jessica]][[ gave]] a necklace<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 18:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Paul and Jacob had a lot of fun at the restaurant. Jacob gave a computer to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Paul]] and[[ Jacob]] had a lot of[[ fun]] at the restaurant.[[ Jacob]] gave a computer<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 19:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Paul and Adam had a lot of fun at the office. Adam gave a computer to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Paul]] and Adam had a lot of fun at the office.[[ Adam]] gave a[[ computer]]<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 20:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Paul and Steven had a lot of fun at the garden. Steven gave a ring to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Paul]] and[[ Steven]] had a lot of fun at the garden.[[ Steven]][[ gave]] a ring<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 21:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Stephen and Paul had a lot of fun at the garden. Stephen gave a drink to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Stephen]][[ and]][[ Paul]] had a lot of fun at the garden.[[ Stephen]] gave a[[ drink]]<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 22:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Alexander and Jessica had a lot of fun at the office. Alexander gave a kiss to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Alexander]][[ and]][[ Jessica]] had a lot of fun at the office.[[ Alexander]] gave a[[ kiss]]<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 23:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Jessica and Sean had a lot of fun at the office. Sean gave a ring to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Jessica]] and[[ Sean]] had a lot of fun at the office[[.]][[ Sean]] gave a[[ ring]]<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 24:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Paul and Jessica had a lot of fun at the school. Paul gave a snack to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Paul]][[ and]][[ Jessica]] had a lot of fun at the school[[.]][[ Paul]] gave a[[ snack]]<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 25:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Robert and Jessica had a lot of fun at the hospital. Robert gave a snack to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Robert]][[ and]][[ Jessica]] had a lot of fun at the hospital.[[ Robert]] gave a[[ snack]]<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 26:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Jessica and Charles had a lot of fun at the office. Charles gave a snack to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Jessica]] and Charles had a lot of fun at the office.[[ Charles]] gave a[[ snack]]<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 27:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Sarah and Jacob had a lot of fun at the station. Jacob gave a kiss to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "[[Then]],[[ Sarah]][[ and]][[ Jacob]][[ had]] a lot of fun at the station.[[ Jacob]] gave a kiss<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 28:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Sarah and Ryan had a lot of fun at the hospital. Ryan gave a kiss to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Sarah]] and Ryan had a lot of[[ fun]] at the hospital[[.]][[ Ryan]] gave a kiss<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 29:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Jonathan and Sarah had a lot of fun at the station. Jonathan gave a necklace to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Jonathan]][[ and]][[ Sarah]] had a lot of fun at the station.[[ Jonathan]][[ gave]] a necklace<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 30:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Rachel and Sarah had a lot of fun at the garden. Rachel gave a ring to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Rachel]][[ and]][[ Sarah]] had a lot of fun at the garden[[.]][[ Rachel]] gave a ring<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 31:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Sarah and Ryan had a lot of fun at the hospital. Ryan gave\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Sarah]] and Ryan had a lot of[[ fun]] at the hospital[[.]][[ Ryan]]<< gave>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 32:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Crystal and Amy had a lot of fun at the station. Crystal gave a necklace to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Crystal]][[ and]][[ Amy]] had a lot of[[ fun]] at the station.[[ Crystal]][[ gave]] a necklace<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 33:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Adam and Crystal had a lot of fun at the garden. Crystal gave a kiss to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Adam]] and Crystal had a lot of[[ fun]] at the garden[[.]][[ Crystal]] gave a kiss<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 34:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Crystal and Amy had a lot of fun at the station. Crystal gave\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Crystal]][[ and]][[ Amy]] had a lot of[[ fun]] at the station[[.]][[ Crystal]]<< gave>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 35:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Adam and Crystal had a lot of fun at the garden. Crystal gave\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Adam]] and Crystal had a lot of[[ fun]] at the garden[[.]][[ Crystal]]<< gave>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 36:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Steven and Amy had a lot of fun at the restaurant. Steven gave\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Steven]][[ and]][[ Amy]] had a lot of[[ fun]] at the restaurant[[.]][[ Steven]]<< gave>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 37:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, James and Eric had a lot of fun at the restaurant. James gave a necklace to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ James]][[ and]][[ Eric]] had a lot of fun at the restaurant.[[ James]][[ gave]] a necklace<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 38:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Eric and Jose had a lot of fun at the school. Jose gave a basketball to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Eric]] and Jose had a lot of[[ fun]] at the school[[.]][[ Jose]] gave a basketball<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 39:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Christopher and Eric had a lot of fun at the school. Christopher gave a computer to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Christopher]][[ and]][[ Eric]] had a lot of fun at the school.[[ Christopher]][[ gave]] a computer<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 40:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Eric and Rachel had a lot of fun at the school. Rachel gave a basketball to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Eric]] and[[ Rachel]] had a lot of fun at the school.[[ Rachel]] gave a basketball<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 41:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Eric and Steven had a lot of fun at the store. Steven gave a ring to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Eric]] and[[ Steven]] had a lot of fun at the store.[[ Steven]][[ gave]] a ring<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 42:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Mark and Jonathan had a lot of fun at the house. Jonathan gave a computer to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Mark]] and[[ Jonathan]][[ had]] a lot of fun at the house.[[ Jonathan]][[ gave]] a computer<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 43:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Mark and Scott had a lot of fun at the house. Scott gave a computer to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Mark]] and[[ Scott]][[ had]] a lot of fun[[ at]] the[[ house]].[[ Scott]] gave a computer<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 44:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Mark and Justin had a lot of fun at the store. Justin gave a ring to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Mark]] and Justin had a lot of fun at the store.[[ Justin]][[ gave]] a ring<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 45:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Charles and Mark had a lot of fun at the office. Charles gave a ring to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Charles]][[ and]][[ Mark]] had a lot of fun at the office[[.]][[ Charles]] gave a ring<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 46:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Mark and Amy had a lot of fun at the school. Amy gave a computer to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Mark]] and[[ Amy]] had a lot of fun at the school.[[ Amy]][[ gave]] a computer<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 47:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Rachel and Anthony had a lot of fun at the garden. Anthony gave a necklace to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Rachel]] and[[ Anthony]] had a lot of fun at the garden.[[ Anthony]][[ gave]][[ a]] necklace<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 48:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Steven and Rachel had a lot of fun at the house. Steven gave a computer to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Steven]][[ and]][[ Rachel]] had a lot of[[ fun]] at the house.[[ Steven]] gave a computer<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 49:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Steven and Rachel had a lot of fun at the house. Steven gave\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Steven]][[ and]][[ Rachel]] had a lot of fun at the house[[.]][[ Steven]]<< gave>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 50:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Rachel and Michelle had a lot of fun at the garden. Michelle gave a drink to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Rachel]] and Michelle had a[[ lot]][[ of]][[ fun]] at the garden[[.]][[ Michelle]] gave a drink<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 51:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Rachel and Elizabeth had a lot of fun at the school. Elizabeth gave a drink to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Rachel]] and Elizabeth had a lot of fun at the school. Elizabeth gave a[[ drink]]<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 52:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, John and Charles had a lot of fun at the restaurant. Charles gave a necklace to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ John]] and Charles had a lot of fun at the restaurant.[[ Charles]] gave a necklace<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 53:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Patrick and John had a lot of fun at the house. Patrick gave a necklace to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "[[Then]],[[ Patrick]][[ and]][[ John]] had a lot of fun at the house.[[ Patrick]][[ gave]] a necklace<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 54:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, John and Ryan had a lot of fun at the station. Ryan gave a necklace to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ John]] and[[ Ryan]] had a lot of[[ fun]] at the station[[.]][[ Ryan]][[ gave]] a necklace<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 55:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, John and Joseph had a lot of fun at the station. Joseph gave a kiss to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ John]] and[[ Joseph]][[ had]] a lot of fun at the station.[[ Joseph]] gave a[[ kiss]]<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 56:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Sean and John had a lot of fun at the office. Sean gave a basketball to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Sean]][[ and]][[ John]] had a lot of fun at the office.[[ Sean]][[ gave]] a basketball<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 57:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, James and Thomas had a lot of fun at the restaurant. Thomas gave a computer to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ James]] and[[ Thomas]] had a lot of[[ fun]] at the restaurant.[[ Thomas]] gave a[[ computer]]<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 58:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Stephen and James had a lot of fun at the station. Stephen gave a snack to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Stephen]][[ and]][[ James]] had a lot of fun at the station.[[ Stephen]] gave a[[ snack]]<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 59:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Christopher and James had a lot of fun at the garden. Christopher gave a drink to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Christopher]][[ and]][[ James]] had a lot of fun at the garden.[[ Christopher]] gave a[[ drink]]<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 60:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Thomas and James had a lot of fun at the hospital. Thomas gave a snack to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Thomas]][[ and]][[ James]] had a lot of[[ fun]] at the hospital.[[ Thomas]] gave a[[ snack]]<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 61:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Stephen and James had a lot of fun at the station. Stephen gave\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Stephen]][[ and]][[ James]] had a lot of fun at the station.[[ Stephen]]<< gave>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 62:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Alexander and Scott had a lot of fun at the restaurant. Alexander gave a kiss to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Alexander]][[ and]][[ Scott]] had a lot of fun at the restaurant.[[ Alexander]] gave a[[ kiss]]<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 63:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Scott and Jeremy had a lot of fun at the school. Jeremy gave a basketball to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Scott]] and[[ Jeremy]] had a lot of fun at the school.[[ Jeremy]] gave a basketball<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 64:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Scott and Jeremy had a lot of fun at the office. Jeremy gave a snack to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Scott]] and[[ Jeremy]][[ had]] a lot of fun at the office.[[ Jeremy]][[ gave]] a[[ snack]]<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 65:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Matthew and Scott had a lot of fun at the store. Matthew gave a basketball to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "[[Then]],[[ Matthew]][[ and]][[ Scott]] had a lot of fun at the store.[[ Matthew]][[ gave]] a basketball<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 66:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Ryan and Scott had a lot of fun at the garden. Ryan gave a computer to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Ryan]][[ and]][[ Scott]] had a lot of[[ fun]] at the garden.[[ Ryan]] gave a computer<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 67:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Eric and Jose had a lot of fun at the school. Jose gave a basketball to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Eric]] and Jose had a lot of[[ fun]] at the school[[.]][[ Jose]] gave a basketball<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 68:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, James and Eric had a lot of fun at the restaurant. James gave a necklace to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ James]][[ and]][[ Eric]] had a lot of fun at the restaurant.[[ James]][[ gave]] a necklace<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 69:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Christopher and Eric had a lot of fun at the school. Christopher gave a computer to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Christopher]][[ and]][[ Eric]] had a lot of fun at the school.[[ Christopher]][[ gave]] a computer<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 70:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Eric and Steven had a lot of fun at the store. Steven gave a ring to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Eric]] and[[ Steven]] had a lot of fun at the store.[[ Steven]][[ gave]] a ring<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 71:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Eric and Rachel had a lot of fun at the school. Rachel gave a basketball to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Eric]] and[[ Rachel]] had a lot of fun at the school.[[ Rachel]] gave a basketball<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 72:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Daniel and Amy had a lot of fun at the office. Amy gave a ring to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Daniel]] and[[ Amy]] had a lot of fun at the office[[.]][[ Amy]] gave a[[ ring]]<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 73:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Daniel and Kevin had a lot of fun at the store. Kevin gave a snack to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Daniel]] and[[ Kevin]] had a lot of[[ fun]] at the store[[.]][[ Kevin]][[ gave]] a[[ snack]]<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 74:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Daniel and Paul had a lot of fun at the restaurant. Paul gave a computer to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Daniel]][[ and]][[ Paul]][[ had]] a[[ lot]] of[[ fun]] at the restaurant.[[ Paul]] gave a computer<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 75:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Daniel and Sarah had a lot of fun at the restaurant. Sarah gave a basketball to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Daniel]] and Sarah had a lot of fun at the restaurant.[[ Sarah]][[ gave]] a basketball<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 76:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Daniel and Thomas had a lot of fun at the office. Thomas gave a basketball to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Daniel]] and[[ Thomas]] had a lot of fun at the office[[.]][[ Thomas]] gave a basketball<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 77:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Robert and Aaron had a lot of fun at the house. Robert gave a computer to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Robert]][[ and]][[ Aaron]] had a lot of fun at the house.[[ Robert]] gave a computer<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 78:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Aaron and Jessica had a lot of fun at the garden. Jessica gave a necklace to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "[[Then]],[[ Aaron]] and[[ Jessica]] had a lot of fun at the garden.[[ Jessica]] gave a necklace<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 79:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Michael and Aaron had a lot of fun at the school. Michael gave a computer to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Michael]][[ and]][[ Aaron]] had a lot of[[ fun]] at the school.[[ Michael]] gave a computer<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 80:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Aaron and Richard had a lot of fun at the restaurant. Richard gave a ring to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "[[Then]],[[ Aaron]] and[[ Richard]] had a lot of[[ fun]] at the[[ restaurant]].[[ Richard]] gave a[[ ring]]<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 81:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Aaron and Richard had a lot of fun at the hospital. Richard gave a kiss to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "[[Then]],[[ Aaron]] and Richard had a lot of fun at the hospital. Richard gave a[[ kiss]]<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 82:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Michael and Anthony had a lot of fun at the store. Anthony gave a computer to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Michael]] and[[ Anthony]] had a lot of[[ fun]] at the store[[.]][[ Anthony]][[ gave]] a computer<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 83:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Michael and Eric had a lot of fun at the hospital. Eric gave a necklace to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Michael]] and Eric had a lot of[[ fun]] at the hospital[[.]][[ Eric]] gave a[[ necklace]]<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 84:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Michael and Tyler had a lot of fun at the station. Tyler gave a necklace to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Michael]] and[[ Tyler]] had a lot of fun at the[[ station]][[.]][[ Tyler]][[ gave]] a necklace<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 85:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, James and Michael had a lot of fun at the office. James gave a necklace to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ James]][[ and]][[ Michael]] had a lot of fun at the office.[[ James]][[ gave]] a necklace<< to>>\n",
      "=================================================\n",
      "\n",
      "                         \n",
      "EXAMPLE 86:\n",
      "- Base Text -\n",
      "=================================================\n",
      "Then, Michael and Tyler had a lot of fun at the house. Tyler gave a kiss to\n",
      "=================================================\n",
      "\n",
      "- Annotated Text -\n",
      "=================================================\n",
      "Then,[[ Michael]] and[[ Tyler]] had a lot of fun at the house.[[ Tyler]] gave a kiss<< to>>\n",
      "=================================================\n",
      "\n",
      "\n",
      "\n",
      "OUTPUT:\n",
      "                         \n",
      "Step 1:\n"
     ]
    }
   ],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wg/cdt_cw_5265_z_gwnxlf0tv80000gn/T/ipykernel_8977/1571428423.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dataset_prompt_tokens = torch.tensor(tokens)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[451, 1572, 22215, 24234, 23307, 6352, 8562, 2297]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:32<00:00,  4.61s/it]\n",
      "100%|██████████| 5/5 [01:46<00:00, 21.25s/it]\n",
      "100%|██████████| 4/4 [00:03<00:00,  1.23it/s]\n",
      "100%|██████████| 5/5 [00:13<00:00,  2.73s/it]\n",
      "100%|██████████| 20/20 [01:31<00:00,  4.58s/it]\n",
      "100%|██████████| 5/5 [01:49<00:00, 21.81s/it]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.36it/s]\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.54s/it]\n",
      "100%|██████████| 20/20 [01:33<00:00,  4.70s/it]\n",
      "100%|██████████| 5/5 [01:45<00:00, 21.04s/it]\n",
      "100%|██████████| 4/4 [00:03<00:00,  1.25it/s]\n",
      "100%|██████████| 5/5 [00:13<00:00,  2.63s/it]\n",
      "100%|██████████| 20/20 [01:33<00:00,  4.65s/it]\n",
      "100%|██████████| 5/5 [01:39<00:00, 19.99s/it]\n",
      "100%|██████████| 4/4 [00:03<00:00,  1.28it/s]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.98s/it]\n",
      "100%|██████████| 20/20 [01:32<00:00,  4.65s/it]\n",
      "100%|██████████| 5/5 [01:41<00:00, 20.32s/it]\n",
      "100%|██████████| 4/4 [00:03<00:00,  1.26it/s]\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.50s/it]\n",
      "100%|██████████| 20/20 [01:30<00:00,  4.52s/it]\n",
      "100%|██████████| 5/5 [01:41<00:00, 20.24s/it]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.35it/s]\n",
      "100%|██████████| 5/5 [00:13<00:00,  2.68s/it]\n",
      "100%|██████████| 20/20 [01:31<00:00,  4.57s/it]\n",
      "100%|██████████| 5/5 [01:46<00:00, 21.31s/it]\n",
      "100%|██████████| 4/4 [00:03<00:00,  1.23it/s]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.86s/it]\n",
      "100%|██████████| 20/20 [01:30<00:00,  4.52s/it]\n",
      "100%|██████████| 5/5 [01:40<00:00, 20.19s/it]\n",
      "100%|██████████| 4/4 [00:03<00:00,  1.31it/s]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.87s/it]\n"
     ]
    }
   ],
   "source": [
    "features = [x for x in list(set(cp.circuit_hypergraph['L10_H7']['features'])) if x!=-1]\n",
    "print(features)\n",
    "\n",
    "# #feature = 19042\n",
    "layer = 10\n",
    "num_examples = 2500\n",
    "\n",
    "strategy = create_simple_greedy_strategy(\n",
    "    passes=1,\n",
    "    node_contributors=1,\n",
    "    minimal=True,\n",
    ")\n",
    "\n",
    "\n",
    "dataset_prompts = gen_templated_prompts(template_idex=1, N=500)\n",
    "prompts = [x['text'] + x['correct'] for x in dataset_prompts]\n",
    "tokens = model.to_tokens(prompts)  # Assuming `model` is already defined\n",
    "dataset_prompt_tokens = torch.tensor(tokens)\n",
    "\n",
    "mini_examples_owt_overall = []\n",
    "mini_examples_ioi_overall = []\n",
    "\n",
    "for feature in features:\n",
    "    try:\n",
    "\n",
    "        analyze_owt = MaxActAnalysis(\n",
    "            \"attn\", \n",
    "            layer, \n",
    "            feature, \n",
    "            num_sequences=num_examples, \n",
    "            batch_size=128, \n",
    "            strategy=strategy\n",
    "        )\n",
    "        mini_examples_owt = analyze_owt.get_context_referenced_prompts_for_range(0, 5)\n",
    "        mini_examples_owt_overall.extend(mini_examples_owt)\n",
    "\n",
    "        # For Dataset Prompt Tokens\n",
    "        analyze_prompts = MaxActAnalysis(\n",
    "            \"attn\", \n",
    "            layer, \n",
    "            feature, \n",
    "            num_sequences=num_examples, \n",
    "            batch_size=128, \n",
    "            strategy=strategy, \n",
    "            token_dataset=dataset_prompt_tokens\n",
    "        )\n",
    "        mini_examples_ioi = analyze_prompts.get_context_referenced_prompts_for_range(0, 5)\n",
    "        mini_examples_ioi_overall.extend(mini_examples_ioi)\n",
    "    \n",
    "    except:\n",
    "        print(f\"Error with feature {feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tokens causing the activation of this neuron are predominantly prepositions and determiners like \"to\", \"the\", \"of\", \"@\", \"a\", \"for\", \"in\", \"and\", \".\", \",\" with a single instance of the pronoun \"he\". \n",
      "\n",
      "Step 2:\n",
      "The context where the for the tokens resides is indicative of an interaction or a relation being established between entities, events, or ideas; these include relation of possession, location, or the performance of an action. Multiple instances include  verb-noun or verb-object constructions.\n",
      "\n",
      "Step 3:\n",
      "Many of the text examples contain information related to some activity or action undertaken by individuals or groups, with concrete consequences or outputs. The activities are varied, but often involve an item or concept being transferred, displayed, or impacted by an agent.\n",
      "\n",
      "Step 4:\n",
      "In all the IOI examples, the neuron activated on the token \"to\" or \"gave\".\n",
      "\n",
      "Step 5:\n",
      "The context in all of these examples involves an initial clause that introduces two named entities and a subsequent main clause where the first named entity from the initial clause (the subject) performing the action of giving something unspecified to the second named entity (the indirect object).\n",
      "\n",
      "Step 6:\n",
      "All of the IOI sentence examples introduce two parties and a location. Following that, in the next sentence S1 give a not fully defined object to S2.\n",
      "\n",
      "Step 7: \n",
      "[EXPLANATION]: This neuron is responsible for the prediction of prepositions that establish a relation, particularly the preposition \"to\", which is indicative of an object being given or directed towards someone or something, as per the standard IOI task. This behavior could be facilitated by prior neurons that detect linking structures and subsequently promote the prediction of a token (typically a preposition) that formalizes an interaction.\n"
     ]
    }
   ],
   "source": [
    "incoming_information = [\n",
    "    # (\"L2H2\", l2h2_interp),\n",
    "    # (\"L0H1\", l0h1_interp),\n",
    "    # (\"L3H0\", l3h0_interp),\n",
    "    # (\"L4H11\", l4h11_interp),\n",
    "    #(\"L5H5\", l5h5_interp),\n",
    "    (\"L8H6\", l8h6_interp),\n",
    "]\n",
    "\n",
    "p = main_aug_interp_prompt_ioi_incoming(mini_examples_owt_overall, mini_examples_ioi_overall, incoming_information)\n",
    "interp = get_response(p)\n",
    "print(interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
