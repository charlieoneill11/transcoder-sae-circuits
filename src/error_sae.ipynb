{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import einops\n",
    "\n",
    "from circuit_lens import get_model_encoders\n",
    "from z_sae import ZSAE\n",
    "from mlp_transcoder import SparseTranscoder\n",
    "from transformer_lens import HookedTransformer\n",
    "from jaxtyping import Float, Int\n",
    "from torch import Tensor\n",
    "from typing import List, Dict, TypedDict, Any, Union, Tuple, Optional\n",
    "from tqdm import trange\n",
    "from plotly_utils import imshow\n",
    "from pprint import pprint\n",
    "from transformer_lens.utils import get_act_name, to_numpy\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm \n",
    "\n",
    "# Import plotly stuff\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, z_saes, transcoders = get_model_encoders(device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Pile dataset we'll use for activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/Users/charlesoneill/.cache/huggingface/datasets/NeelNanda___parquet/NeelNanda--pile-10k-72f566e9f7c464ab/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c5aec90ae18476fbd5ade520cc0fd9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"NeelNanda/pile-10k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 243/243 [00:00<00:00, 809.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# Split the huggingface dataset up into seq_len text\n",
    "seq_len = 128\n",
    "batch_size = 4096\n",
    "model_name = 'gpt2-small'\n",
    "\n",
    "model = HookedTransformer.from_pretrained(model_name, device='cpu')\n",
    "\n",
    "tokenized_dataset = []\n",
    "# Concat all the text together\n",
    "text = \" \".join(dataset['train']['text'])\n",
    "\n",
    "# Tokenize the text\n",
    "for i in trange(0, len(text)//100, 2500):\n",
    "    tokens = model.to_tokens(text[i:i+2500]).squeeze()\n",
    "    # Split into seq_len chunks\n",
    "    for j in range(0, len(tokens), seq_len):\n",
    "        tokenized_dataset.append(tokens[j:j+seq_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only examples with seq_len 128\n",
    "tokenized_dataset = [x for x in tokenized_dataset if len(x) == seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1124"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert all tensors have shape seq_length\n",
    "for i, tokens in enumerate(tokenized_dataset):\n",
    "    assert tokens.shape[0] == seq_len, f\"Token {i} has shape {tokens.shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 128])\n"
     ]
    }
   ],
   "source": [
    "# Turn tokenized_dataset (a list of tensors) into a Pytorch Dataset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "class TokenizedDataset(Dataset):\n",
    "    def __init__(self, tokenized_dataset):\n",
    "        self.tokenized_dataset = tokenized_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tokenized_dataset[idx]\n",
    "    \n",
    "dataset = TokenizedDataset(tokenized_dataset)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "print(next(iter(dataloader)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x4942133b0>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Disable torch grad\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:53<00:00,  1.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([143872, 768])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = 9\n",
    "sae = z_saes[layer]\n",
    "\n",
    "# Get all z activations\n",
    "z_acts = []\n",
    "for batch in tqdm(dataloader):\n",
    "    logits, cache = model.run_with_cache(batch)\n",
    "    z = cache[\"z\", layer] # batch_size x seq_len x n_heads x d_head\n",
    "    del logits\n",
    "    del cache\n",
    "    z = einops.rearrange(\n",
    "        z, \n",
    "        \"b s n d -> (b s) (n d)\"\n",
    "    )\n",
    "    z_acts.append(z)\n",
    "\n",
    "# Stack all z activations along first dimension\n",
    "z_acts = torch.cat(z_acts, dim=0)\n",
    "z_acts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(z_acts, 'z_acts.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load z_acts\n",
    "z_acts = torch.load(\"z_acts.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get SAE reconstructions and errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([143872, 768])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_acts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 768])\n"
     ]
    }
   ],
   "source": [
    "# Create SAE dataset\n",
    "class SAEDataset(Dataset):\n",
    "    def __init__(self, z_acts):\n",
    "        self.z_acts = z_acts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.z_acts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.z_acts[idx]\n",
    "    \n",
    "sae_dataset = SAEDataset(z_acts)\n",
    "\n",
    "# Create SAE dataloader\n",
    "sae_dataloader = DataLoader(sae_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(next(iter(sae_dataloader)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8992 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8992/8992 [01:08<00:00, 130.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get SAE errors on each z_acts - we need to store the errors, and the original z_acts\n",
    "sae_errors = []\n",
    "original_z = []\n",
    "for z_batch in tqdm(sae_dataloader):\n",
    "    _, z_recon, z_acts, _, _ = sae(z_batch)\n",
    "    sae_error = z_batch - z_recon\n",
    "    sae_errors.append(sae_error)\n",
    "    original_z.append(z_batch)\n",
    "    \n",
    "# Stack all sae errors along first dimension\n",
    "sae_errors = torch.cat(sae_errors, dim=0)\n",
    "original_z = torch.cat(original_z, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([143872, 768]), torch.Size([143872, 768]))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae_errors.shape, original_z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save both\n",
    "torch.save(sae_errors, 'sae_errors.pt')\n",
    "torch.save(original_z, 'original_z.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a gated SAE to predict the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import einops\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the sae errors and original z\n",
    "sae_errors = torch.load('sae_errors.pt')\n",
    "original_z = torch.load('original_z.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gated SAE\n",
    "class GatedSAE(nn.Module):\n",
    "\n",
    "    def __init__(self, n_input_features, n_learned_features, l1_coefficient=0.01):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_input_features = n_input_features\n",
    "        self.n_learned_features = n_learned_features\n",
    "        self.l1_coefficient = l1_coefficient\n",
    "\n",
    "        self.W_enc = nn.Parameter(\n",
    "            torch.nn.init.kaiming_uniform_(torch.empty(self.n_input_features, self.n_learned_features))   \n",
    "        )\n",
    "        self.W_dec = nn.Parameter(\n",
    "            torch.nn.init.kaiming_uniform_(torch.empty(self.n_learned_features, self.n_input_features))   \n",
    "        )\n",
    "\n",
    "        self.r_mag = nn.Parameter(\n",
    "            torch.zeros(self.n_learned_features)\n",
    "        )\n",
    "        self.b_mag = nn.Parameter(\n",
    "            torch.zeros(self.n_learned_features)\n",
    "        )\n",
    "        self.b_gate = nn.Parameter(\n",
    "            torch.zeros(self.n_learned_features)\n",
    "        )\n",
    "        self.b_dec = nn.Parameter(\n",
    "            torch.zeros(self.n_input_features)\n",
    "        )\n",
    "\n",
    "        self.activation_fn = nn.ReLU()\n",
    "\n",
    "    def forward(self, x_act, y_error):\n",
    "        # Assert x_act (original z activations i.e. the input) and the y_error (SAE error i.e. the target) have the same shape\n",
    "        assert x_act.shape == y_error.shape, f\"x_act shape {x_act.shape} does not match y_error shape {y_error.shape}\"\n",
    "\n",
    "        hidden_pre = einops.einsum(x_act, self.W_enc, \"... d_in, d_in d_sae -> ... d_sae\")\n",
    "\n",
    "        # Gated SAE\n",
    "        hidden_pre_mag = hidden_pre * torch.exp(self.r_mag) + self.b_mag\n",
    "        hidden_post_mag = self.activation_fn(hidden_pre_mag)  \n",
    "        hidden_pre_gate = hidden_pre + self.b_gate\n",
    "        hidden_post_gate = (torch.sign(hidden_pre_gate) + 1) / 2\n",
    "        hidden_post = hidden_post_mag * hidden_post_gate\n",
    "\n",
    "        sae_out = einops.einsum(hidden_post, self.W_dec, \"... d_sae, d_sae d_in -> ... d_in\") + self.b_dec\n",
    "\n",
    "        # Now we need to handle all the loss stuff\n",
    "        # Reconstruction loss\n",
    "        per_item_mse_loss = self.per_item_mse_loss_with_target_norm(sae_out, y_error)\n",
    "        mse_loss = per_item_mse_loss.mean()\n",
    "        # L1 loss\n",
    "        via_gate_feature_magnitudes = F.relu(hidden_pre_gate)\n",
    "        sparsity = via_gate_feature_magnitudes.norm(p=1, dim=1).mean(dim=(0,))\n",
    "        l1_loss = self.l1_coefficient * sparsity\n",
    "        # Auxiliary loss\n",
    "        via_gate_reconstruction = einops.einsum(via_gate_feature_magnitudes, self.W_dec.detach(), \"... d_sae, d_sae d_in -> ... d_in\") + self.b_dec.detach()\n",
    "        aux_loss = F.mse_loss(via_gate_reconstruction, y_error, reduction=\"mean\")\n",
    "        \n",
    "        loss = mse_loss + l1_loss + aux_loss\n",
    "\n",
    "        return sae_out, loss\n",
    "\n",
    "    def per_item_mse_loss_with_target_norm(self, preds, target):\n",
    "        return torch.nn.functional.mse_loss(preds, target, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input_features = 768\n",
    "projection_up = 4\n",
    "gated_sae = GatedSAE(n_input_features=768, n_learned_features=n_input_features*projection_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 768]), tensor(2.5217))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the forward pass\n",
    "x = original_z[:16, :]\n",
    "y = sae_errors[:16, :]\n",
    "sae_out, loss = gated_sae(x, y)\n",
    "sae_out.shape, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GatedSAE dataset\n",
    "class GatedSAEDataset(Dataset):\n",
    "    def __init__(self, original_z, sae_errors):\n",
    "        self.original_z = original_z\n",
    "        self.sae_errors = sae_errors\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.original_z)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.original_z[idx], self.sae_errors[idx]\n",
    "    \n",
    "gated_sae_dataset = GatedSAEDataset(original_z, sae_errors)\n",
    "\n",
    "# Create GatedSAE train dataloader and test dataloader\n",
    "train_size = int(0.8 * len(gated_sae_dataset))\n",
    "test_size = len(gated_sae_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(gated_sae_dataset, [train_size, test_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x4b78acbc0>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Batch 0 Loss 2.2689952850341797\n",
      "Batch 1 Loss 1.7172391414642334\n",
      "Batch 2 Loss 0.928523600101471\n",
      "Batch 3 Loss 0.4895963668823242\n",
      "Batch 4 Loss 0.722083568572998\n",
      "Batch 5 Loss 0.24162815511226654\n",
      "Batch 6 Loss 0.2363552749156952\n",
      "Batch 7 Loss 0.16351088881492615\n",
      "Batch 8 Loss 0.10887334495782852\n",
      "Batch 9 Loss 0.05956375598907471\n",
      "Batch 10 Loss 0.089531809091568\n",
      "Batch 11 Loss 0.06512608379125595\n",
      "Batch 12 Loss 0.08334121108055115\n",
      "Batch 13 Loss 0.059068404138088226\n",
      "Batch 14 Loss 0.04388595372438431\n",
      "Batch 15 Loss 0.039961010217666626\n",
      "Batch 16 Loss 0.04903621971607208\n",
      "Batch 17 Loss 0.05079043656587601\n",
      "Batch 18 Loss 0.11217576265335083\n",
      "Batch 19 Loss 0.05086073279380798\n",
      "Batch 20 Loss 0.059194840490818024\n",
      "Batch 21 Loss 0.06037326902151108\n",
      "Batch 22 Loss 0.04465043544769287\n",
      "Batch 23 Loss 0.05342236906290054\n",
      "Batch 24 Loss 0.05961407721042633\n",
      "Batch 25 Loss 0.05566681548953056\n",
      "Batch 26 Loss 0.057308271527290344\n",
      "Batch 27 Loss 0.05143804848194122\n",
      "Batch 28 Loss 0.04597126692533493\n",
      "Batch 29 Loss 0.05362758785486221\n",
      "Batch 30 Loss 0.054940879344940186\n",
      "Batch 31 Loss 0.0474090613424778\n",
      "Batch 32 Loss 0.059162139892578125\n",
      "Batch 33 Loss 0.05194314941763878\n",
      "Batch 34 Loss 0.05367707833647728\n",
      "Batch 35 Loss 0.05037485808134079\n",
      "Batch 36 Loss 0.04183194041252136\n",
      "Batch 37 Loss 0.046429794281721115\n",
      "Batch 38 Loss 0.05183332785964012\n",
      "Batch 39 Loss 0.06468147039413452\n",
      "Batch 40 Loss 0.05748472362756729\n",
      "Batch 41 Loss 0.060314442962408066\n",
      "Batch 42 Loss 0.05468277260661125\n",
      "Batch 43 Loss 0.06277716159820557\n",
      "Batch 44 Loss 0.04296353459358215\n",
      "Batch 45 Loss 0.04517829418182373\n",
      "Batch 46 Loss 0.04425039887428284\n",
      "Batch 47 Loss 0.05626675486564636\n",
      "Batch 48 Loss 0.07306729257106781\n",
      "Batch 49 Loss 0.07630592584609985\n",
      "Batch 50 Loss 0.052214525640010834\n",
      "Batch 51 Loss 0.06114846467971802\n",
      "Batch 52 Loss 0.06797714531421661\n",
      "Batch 53 Loss 0.058848414570093155\n",
      "Batch 54 Loss 0.06592735648155212\n",
      "Batch 55 Loss 0.058269668370485306\n",
      "Batch 56 Loss 0.04172872006893158\n",
      "Batch 57 Loss 0.04233495146036148\n",
      "Batch 58 Loss 0.0653226226568222\n",
      "Batch 59 Loss 0.04228772968053818\n",
      "Batch 60 Loss 0.047934144735336304\n",
      "Batch 61 Loss 0.05350760743021965\n",
      "Batch 62 Loss 0.03816927224397659\n",
      "Batch 63 Loss 0.05375821143388748\n",
      "Batch 64 Loss 0.03804406523704529\n",
      "Batch 65 Loss 0.07491259276866913\n",
      "Batch 66 Loss 0.041350942105054855\n",
      "Batch 67 Loss 0.060334037989377975\n",
      "Batch 68 Loss 0.04471414536237717\n",
      "Batch 69 Loss 0.04468415677547455\n",
      "Batch 70 Loss 0.059580475091934204\n",
      "Batch 71 Loss 0.05649268627166748\n",
      "Batch 72 Loss 0.05778699368238449\n",
      "Batch 73 Loss 0.052403584122657776\n",
      "Batch 74 Loss 0.06411708146333694\n",
      "Batch 75 Loss 0.07619190216064453\n",
      "Batch 76 Loss 0.049603670835494995\n",
      "Batch 77 Loss 0.0538744181394577\n",
      "Batch 78 Loss 0.04676499590277672\n",
      "Batch 79 Loss 0.05282827466726303\n",
      "Batch 80 Loss 0.04878540337085724\n",
      "Batch 81 Loss 0.06796861439943314\n",
      "Batch 82 Loss 0.04106120020151138\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[170], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m test_dataloader:\n\u001b[0;32m---> 20\u001b[0m     sae_out, loss \u001b[38;5;241m=\u001b[39m \u001b[43mgated_sae\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     test_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/anu/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/anu/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[163], line 55\u001b[0m, in \u001b[0;36mGatedSAE.forward\u001b[0;34m(self, x_act, y_error)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# L1 loss\u001b[39;00m\n\u001b[1;32m     54\u001b[0m via_gate_feature_magnitudes \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(hidden_pre_gate)\n\u001b[0;32m---> 55\u001b[0m sparsity \u001b[38;5;241m=\u001b[39m \u001b[43mvia_gate_feature_magnitudes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m l1_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml1_coefficient \u001b[38;5;241m*\u001b[39m sparsity\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Auxiliary loss\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "import torch.optim as optim\n",
    "\n",
    "n_epochs = 10\n",
    "gated_sae = GatedSAE(n_input_features=768, n_learned_features=768*4)\n",
    "optimizer = optim.Adam(gated_sae.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    for i, (x, y) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        sae_out, loss = gated_sae(x, y)\n",
    "        loss.backward()\n",
    "        print(f\"Batch {i} Loss {loss.item()}\")\n",
    "        optimizer.step()\n",
    "        if i % (n_epochs // 10) == 0:\n",
    "            # Evaluate on test set\n",
    "            test_loss = 0\n",
    "            for x, y in test_dataloader:\n",
    "                sae_out, loss = gated_sae(x, y)\n",
    "                test_loss += loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
