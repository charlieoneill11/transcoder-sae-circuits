{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import einops\n",
    "\n",
    "from circuit_lens import get_model_encoders\n",
    "from z_sae import ZSAE\n",
    "from mlp_transcoder import SparseTranscoder\n",
    "from transformer_lens import HookedTransformer\n",
    "from jaxtyping import Float, Int\n",
    "from torch import Tensor\n",
    "from typing import List, Dict, TypedDict, Any, Union, Tuple, Optional\n",
    "from tqdm import trange\n",
    "from plotly_utils import imshow\n",
    "from pprint import pprint\n",
    "from transformer_lens.utils import get_act_name, to_numpy\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm \n",
    "\n",
    "# Import plotly stuff\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, z_saes, transcoders = get_model_encoders(device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_saes[9].cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Pile dataset we'll use for activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"NeelNanda/pile-10k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the huggingface dataset up into seq_len text\n",
    "seq_len = 128\n",
    "batch_size = 4096\n",
    "model_name = 'gpt2-small'\n",
    "\n",
    "model = HookedTransformer.from_pretrained(model_name, device='cpu')\n",
    "\n",
    "tokenized_dataset = []\n",
    "# Concat all the text together\n",
    "text = \" \".join(dataset['train']['text'])\n",
    "\n",
    "# Tokenize the text\n",
    "for i in trange(0, len(text)//100, 2500):\n",
    "    tokens = model.to_tokens(text[i:i+2500]).squeeze()\n",
    "    # Split into seq_len chunks\n",
    "    for j in range(0, len(tokens), seq_len):\n",
    "        tokenized_dataset.append(tokens[j:j+seq_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only examples with seq_len 128\n",
    "tokenized_dataset = [x for x in tokenized_dataset if len(x) == seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert all tensors have shape seq_length\n",
    "for i, tokens in enumerate(tokenized_dataset):\n",
    "    assert tokens.shape[0] == seq_len, f\"Token {i} has shape {tokens.shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn tokenized_dataset (a list of tensors) into a Pytorch Dataset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "class TokenizedDataset(Dataset):\n",
    "    def __init__(self, tokenized_dataset):\n",
    "        self.tokenized_dataset = tokenized_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tokenized_dataset[idx]\n",
    "    \n",
    "dataset = TokenizedDataset(tokenized_dataset)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "print(next(iter(dataloader)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable torch grad\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 9\n",
    "sae = z_saes[layer]\n",
    "\n",
    "# Get all z activations\n",
    "z_acts = []\n",
    "for batch in tqdm(dataloader):\n",
    "    logits, cache = model.run_with_cache(batch)\n",
    "    z = cache[\"z\", layer] # batch_size x seq_len x n_heads x d_head\n",
    "    del logits\n",
    "    del cache\n",
    "    z = einops.rearrange(\n",
    "        z, \n",
    "        \"b s n d -> (b s) (n d)\"\n",
    "    )\n",
    "    z_acts.append(z)\n",
    "\n",
    "# Stack all z activations along first dimension\n",
    "z_acts = torch.cat(z_acts, dim=0)\n",
    "z_acts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(z_acts, 'z_acts.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load z_acts\n",
    "z_acts = torch.load(\"z_acts.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get SAE reconstructions and errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_acts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SAE dataset\n",
    "class SAEDataset(Dataset):\n",
    "    def __init__(self, z_acts):\n",
    "        self.z_acts = z_acts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.z_acts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.z_acts[idx]\n",
    "    \n",
    "sae_dataset = SAEDataset(z_acts)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create SAE dataloader\n",
    "sae_dataloader = DataLoader(sae_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(next(iter(sae_dataloader)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get SAE errors on each z_acts - we need to store the errors, and the original z_acts\n",
    "sae_errors = []\n",
    "original_z = []\n",
    "for z_batch in tqdm(sae_dataloader):\n",
    "    _, z_recon, _, _, _ = sae(z_batch)\n",
    "    print(z_recon.shape)\n",
    "    print(z_batch.shape)\n",
    "    sae_error = z_batch - z_recon\n",
    "    print(sae_error.shape)\n",
    "    # Assert sae_error + z_recon = z_batch\n",
    "    if not torch.allclose(z_recon + sae_error, z_batch, rtol=1e-3, atol=1e-3):\n",
    "        print(z_recon[0][0], sae_error[0][0], z_batch[0][0])\n",
    "        print(z_recon[0][0] + sae_error[0][0], z_batch[0][0])\n",
    "        print(\"ERROR\")\n",
    "        break\n",
    "    sae_errors.append(sae_error)\n",
    "    original_z.append(z_batch)\n",
    "    #break\n",
    "    \n",
    "# Stack all sae errors along first dimension\n",
    "sae_errors = torch.cat(sae_errors, dim=0)\n",
    "original_z = torch.cat(original_z, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_errors.shape, original_z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save both\n",
    "torch.save(sae_errors, 'sae_errors.pt')\n",
    "torch.save(original_z, 'original_z.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a gated SAE to predict the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import einops\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the sae errors and original z\n",
    "sae_errors = torch.load('sae_errors.pt')\n",
    "original_z = torch.load('original_z.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gated SAE\n",
    "class GatedSAE(nn.Module):\n",
    "\n",
    "    def __init__(self, n_input_features, n_learned_features, l1_coefficient=0.01):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_input_features = n_input_features\n",
    "        self.n_learned_features = n_learned_features\n",
    "        self.l1_coefficient = l1_coefficient\n",
    "\n",
    "        self.W_enc = nn.Parameter(\n",
    "            torch.nn.init.kaiming_uniform_(torch.empty(self.n_input_features, self.n_learned_features))   \n",
    "        )\n",
    "        self.W_dec = nn.Parameter(\n",
    "            torch.nn.init.kaiming_uniform_(torch.empty(self.n_learned_features, self.n_input_features))   \n",
    "        )\n",
    "\n",
    "        self.r_mag = nn.Parameter(\n",
    "            torch.zeros(self.n_learned_features)\n",
    "        )\n",
    "        self.b_mag = nn.Parameter(\n",
    "            torch.zeros(self.n_learned_features)\n",
    "        )\n",
    "        self.b_gate = nn.Parameter(\n",
    "            torch.zeros(self.n_learned_features)\n",
    "        )\n",
    "        self.b_dec = nn.Parameter(\n",
    "            torch.zeros(self.n_input_features)\n",
    "        )\n",
    "\n",
    "        self.activation_fn = nn.ReLU()\n",
    "\n",
    "    def forward(self, x_act, y_error):\n",
    "        # Assert x_act (original z activations i.e. the input) and the y_error (SAE error i.e. the target) have the same shape\n",
    "        assert x_act.shape == y_error.shape, f\"x_act shape {x_act.shape} does not match y_error shape {y_error.shape}\"\n",
    "\n",
    "        hidden_pre = einops.einsum(x_act, self.W_enc, \"... d_in, d_in d_sae -> ... d_sae\")\n",
    "\n",
    "        # Gated SAE\n",
    "        hidden_pre_mag = hidden_pre * torch.exp(self.r_mag) + self.b_mag\n",
    "        hidden_post_mag = self.activation_fn(hidden_pre_mag)  \n",
    "        hidden_pre_gate = hidden_pre + self.b_gate\n",
    "        hidden_post_gate = (torch.sign(hidden_pre_gate) + 1) / 2\n",
    "        hidden_post = hidden_post_mag * hidden_post_gate\n",
    "\n",
    "        sae_out = einops.einsum(hidden_post, self.W_dec, \"... d_sae, d_sae d_in -> ... d_in\") + self.b_dec\n",
    "\n",
    "        # Now we need to handle all the loss stuff\n",
    "        # Reconstruction loss\n",
    "        per_item_mse_loss = self.per_item_mse_loss_with_target_norm(sae_out, y_error)\n",
    "        mse_loss = per_item_mse_loss.mean()\n",
    "        # L1 loss\n",
    "        via_gate_feature_magnitudes = F.relu(hidden_pre_gate)\n",
    "        sparsity = via_gate_feature_magnitudes.norm(p=1, dim=1).mean(dim=(0,))\n",
    "        l1_loss = self.l1_coefficient * sparsity\n",
    "        # Auxiliary loss\n",
    "        via_gate_reconstruction = einops.einsum(via_gate_feature_magnitudes, self.W_dec.detach(), \"... d_sae, d_sae d_in -> ... d_in\") + self.b_dec.detach()\n",
    "        aux_loss = F.mse_loss(via_gate_reconstruction, y_error, reduction=\"mean\")\n",
    "        \n",
    "        loss = mse_loss + l1_loss + aux_loss\n",
    "\n",
    "        return sae_out, loss\n",
    "\n",
    "    def per_item_mse_loss_with_target_norm(self, preds, target):\n",
    "        return torch.nn.functional.mse_loss(preds, target, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input_features = 768\n",
    "projection_up = 4\n",
    "gated_sae = GatedSAE(n_input_features=768, n_learned_features=n_input_features*projection_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the forward pass\n",
    "x = original_z[:16, :]\n",
    "y = sae_errors[:16, :]\n",
    "sae_out, loss = gated_sae(x, y)\n",
    "sae_out.shape, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GatedSAE dataset\n",
    "class GatedSAEDataset(Dataset):\n",
    "    def __init__(self, original_z, sae_errors):\n",
    "        self.original_z = original_z\n",
    "        self.sae_errors = sae_errors\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.original_z)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.original_z[idx], self.sae_errors[idx]\n",
    "    \n",
    "gated_sae_dataset = GatedSAEDataset(original_z, sae_errors)\n",
    "\n",
    "# Create GatedSAE train dataloader and test dataloader\n",
    "train_size = int(0.8 * len(gated_sae_dataset))\n",
    "test_size = len(gated_sae_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(gated_sae_dataset, [train_size, test_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "import torch.optim as optim\n",
    "\n",
    "n_epochs = 10\n",
    "gated_sae = GatedSAE(n_input_features=768, n_learned_features=768*4)\n",
    "optimizer = optim.Adam(gated_sae.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    for i, (x, y) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        sae_out, loss = gated_sae(x, y)\n",
    "        loss.backward()\n",
    "        print(f\"Batch {i} Loss {loss.item()}\")\n",
    "        optimizer.step()\n",
    "        if i % (n_epochs // 10) == 0:\n",
    "            # Evaluate on test set\n",
    "            test_loss = 0\n",
    "            for x, y in test_dataloader:\n",
    "                sae_out, loss = gated_sae(x, y)\n",
    "                test_loss += loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data/gated_sae.py and upload to huggingface\n",
    "from gated_sae import GatedSAE\n",
    "\n",
    "# Load the model\n",
    "gated_sae = GatedSAE.from_pretrained(\"gated-sae\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
