{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to huggingface\n",
    "from huggingface_hub import HfApi, HfFolder\n",
    "import torch\n",
    "from gated_sae import GatedSAE\n",
    "from vanilla_sae import SparseAutoencoder\n",
    "import plotly.express as px\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from circuit_lens import get_model_encoders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _, _ = get_model_encoders(device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"hello neel\"\n",
    "tokens = model.to_tokens(prompt)\n",
    "_, cache = model.run_with_cache(prompt) \n",
    "print(cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gated_sae = torch.load('data/gated_sae.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "import torch\n",
    "from huggingface_hub import hf_hub_download\n",
    "from gated_sae import GatedSAE\n",
    "\n",
    "# Define the function to download and load the model\n",
    "def load_gated_sae(repo_id, filename, n_input_features, projection_up, l1_coefficient):\n",
    "    # Download the model file from HuggingFace Hub\n",
    "    file_path = hf_hub_download(repo_id=repo_id, filename=filename)\n",
    "    model = torch.load(file_path, map_location=torch.device('cpu'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Define parameters\n",
    "layer = 9\n",
    "repo_id = 'charlieoneill/error-saes'\n",
    "filename = f'sae_layer_{layer}.pt'\n",
    "n_input_features = 768\n",
    "projection_up = 8\n",
    "l1_coefficient = 3e-4\n",
    "\n",
    "# Load the model\n",
    "gated_sae = load_gated_sae(repo_id, filename, n_input_features, projection_up, l1_coefficient)\n",
    "\n",
    "# Print model summary (optional)\n",
    "print(gated_sae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gated_sae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_errors = torch.load(f'data/sae_errors_layer_{layer}.pt')\n",
    "original_z = torch.load(f'data/original_z_layer_{layer}.pt')\n",
    "print(sae_errors.shape, original_z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "x = original_z[idx, :].unsqueeze(0)\n",
    "y = sae_errors[idx, :].unsqueeze(0)\n",
    "\n",
    "print(f\"Original Z act: {x[0][0]:.3f}\")\n",
    "print(f\"SAE error: {y[0][0]:.3f}\")\n",
    "\n",
    "sae_pred = original_z - sae_errors\n",
    "print(f\"SAE pred: {sae_pred[idx, 0]:.3f}\")\n",
    "\n",
    "recon, loss, recon_loss = gated_sae(x, y)\n",
    "print(f\"Recon: {recon[0][0]:.3f}\") \n",
    "print(f\"Loss: {loss:.3f}\")\n",
    "print(f\"Recon loss: {recon_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original z line plot\n",
    "fig = px.line(x=range(0, 768), y=original_z[idx, :].detach().numpy(), title='Original z')\n",
    "fig.add_scatter(y=sae_pred[idx, :].detach().numpy(), mode='lines', name='SAE Pred')\n",
    "fig.show()\n",
    "\n",
    "# Original z line plot\n",
    "fig = px.line(x=range(0, 768), y=sae_errors[idx, :].detach().numpy(), title='SAE Error')\n",
    "fig.add_scatter(y=recon.squeeze().detach().numpy(), mode='lines', name='Reconstructed Error')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "x = original_z[idx, :].unsqueeze(0)\n",
    "y = sae_errors[idx, :].unsqueeze(0)\n",
    "sae_pred = original_z - sae_errors\n",
    "recon_0, loss, _ = gated_sae(x, y)\n",
    "\n",
    "\n",
    "idx = 1\n",
    "x = original_z[idx, :].unsqueeze(0)\n",
    "y = sae_errors[idx, :].unsqueeze(0)\n",
    "sae_pred = original_z - sae_errors\n",
    "recon_1, loss, _ = gated_sae(x, y)\n",
    "recon_1 += 0.0\n",
    "\n",
    "# Plot recon_0 and recon_1\n",
    "fig = px.line(x=range(0, 768), y=recon_0.squeeze().detach().numpy(), title='Reconstructed 0')\n",
    "fig.add_scatter(y=recon_1.squeeze().detach().numpy(), mode='lines', name='Reconstructed 1')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of L1 regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "\n",
    "def run_experiments(model_type: str, l1_coefficients: list, n_epochs: int = 1):\n",
    "    results = {}\n",
    "    for l1_coefficient in tqdm(l1_coefficients, desc=\"Running Experiments\"):\n",
    "        print(f\"Running experiment with l1_coefficient={l1_coefficient}\")\n",
    "        final_recon_loss, l0_loss = train.main(model_type=model_type, n_epochs=n_epochs, l1_coefficient=l1_coefficient)\n",
    "        results[l1_coefficient] = (final_recon_loss, l0_loss)\n",
    "        print(f\"Final Reconstruction Error for l1_coefficient={l1_coefficient}: {final_recon_loss:.4f}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_coefficients = [5e-5, 8e-5, 1e-4, 3e-4]\n",
    "results = run_experiments(model_type='gated', l1_coefficients=l1_coefficients, n_epochs=2)\n",
    "print(\"Experiment Results:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_errors = [result[0] for result in results.values()]\n",
    "l0_errors = [result[1] for result in results.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly plot results\n",
    "fig = px.line(x=l1_coefficients, y=recon_errors, \n",
    "              labels={'x': 'L1 Coefficient', 'y': 'Reconstruction Error'},\n",
    "              title='Reconstruction Error vs L1 Coefficient (Gated SAE)', width=600)\n",
    "# Log x-axis\n",
    "fig.update_xaxes(type=\"log\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L0 loss\n",
    "fig = px.line(x=l1_coefficients, y=l0_errors, \n",
    "              labels={'x': 'L1 Coefficient', 'y': 'L0 Loss'},\n",
    "              title='L0 Loss vs L1 Coefficient (Gated SAE)', width=600)\n",
    "# Log x-axis\n",
    "fig.update_xaxes(type=\"log\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the SAE with and without SAE error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the test dataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from train import GatedSAEDataset\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from circuit_lens import get_model_encoders\n",
    "\n",
    "device = 'cpu'\n",
    "model, z_saes, _ = get_model_encoders(device=device)\n",
    "layer = 9\n",
    "sae = z_saes[layer]\n",
    "print(sae.cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the test dataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from train import GatedSAEDataset\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from circuit_lens import get_model_encoders\n",
    "\n",
    "# Load in the test dataset\n",
    "test_dataset = torch.load('data/test_dataset.pt')\n",
    "# # shuffle\n",
    "# test_dataset = test_dataset[torch.randperm(len(test_dataset))]\n",
    "# Print the shape of the dataset\n",
    "# print(test_dataset.shape)\n",
    "# Keep random 1% of the dataset\n",
    "#test_dataset = test_dataset[:int(len(test_dataset) * 0.01)]\n",
    "test_dataset[0][0].shape, test_dataset[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get GPT2 (model), and our SAE\n",
    "model, z_saes, _ = get_model_encoders(device='cpu')\n",
    "layer = 9 \n",
    "sae = z_saes[layer]\n",
    "del z_saes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_original = test_dataset[0][0].unsqueeze(0)\n",
    "loss, z_reconstruct, acts, l2_loss, l1_loss = sae(z_original)\n",
    "error = z_original.float() - z_reconstruct.float()\n",
    "l2_loss_ours = (z_reconstruct.float() - z_original.float()).pow(2).sum(-1)\n",
    "\n",
    "# Print all shapes\n",
    "print(f\"Original Z shape: {z_original.shape}\")\n",
    "print(f\"Reconstructed Z shape: {z_reconstruct.shape}\")\n",
    "print(f\"Error shape: {error.shape}\")\n",
    "print(f\"Layer {layer} activations shape: {acts.shape}\")\n",
    "print(f\"L2 Loss: {l2_loss:.4f}\")\n",
    "print(f\"L2 Loss (Ours): {l2_loss_ours.item():.4f}\")\n",
    "print(f\"L1 Loss: {l1_loss:.4f}\")\n",
    "print(f\"Mean error = {error.abs().mean(-1).item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error.abs().mean(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Initial metrics: l2 loss, l1 loss, mean error\n",
    "evaluation_results = []\n",
    "for i, (original_z, _) in enumerate(tqdm(test_dataloader)):\n",
    "    original_z = original_z.to('cpu')\n",
    "    loss, z_reconstruct, acts, l2_loss, l1_loss = sae(original_z)\n",
    "    error = original_z.float() - z_reconstruct.float()\n",
    "    mean_error = error.abs().sum(-1).mean()\n",
    "    evaluation_results.append((l2_loss.item(), mean_error.item()))\n",
    "\n",
    "# Divide by number of batches\n",
    "l2_loss, mean_error = zip(*evaluation_results)\n",
    "l2_loss = sum(l2_loss) / len(test_dataloader)\n",
    "mean_error = sum(mean_error) / len(test_dataloader)\n",
    "\n",
    "# Print\n",
    "print(f\"L2 Loss: {l2_loss:.4f}\")\n",
    "print(f\"Mean Error: {mean_error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gated_sae = torch.load('data/gated_sae.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "import torch\n",
    "from huggingface_hub import hf_hub_download\n",
    "from gated_sae import GatedSAE\n",
    "\n",
    "# Define the function to download and load the model\n",
    "def load_gated_sae(repo_id, filename, n_input_features, projection_up, l1_coefficient):\n",
    "    # Download the model file from HuggingFace Hub\n",
    "    file_path = hf_hub_download(repo_id=repo_id, filename=filename)\n",
    "    model = torch.load(file_path, map_location=torch.device('cpu'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Define parameters\n",
    "layer = 9\n",
    "repo_id = 'charlieoneill/error-saes'\n",
    "filename = f'sae_layer_{layer}.pt'\n",
    "n_input_features = 768\n",
    "projection_up = 8\n",
    "l1_coefficient = 3e-4\n",
    "\n",
    "# Load the model\n",
    "gated_sae = load_gated_sae(repo_id, filename, n_input_features, projection_up, l1_coefficient)\n",
    "\n",
    "# Print model summary (optional)\n",
    "print(gated_sae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we test the same metrics but with our trained gated SAE\n",
    "gated_sae = gated_sae.to('cpu')\n",
    "gated_sae.eval()\n",
    "\n",
    "# Initial metrics: l2 loss, l1 loss, mean error\n",
    "evaluation_results = []\n",
    "for i, (original_z, _) in enumerate(tqdm(test_dataloader)):\n",
    "    original_z = original_z.to('cpu')\n",
    "    _, z_reconstruct, acts, _, _ = sae(original_z)\n",
    "    error = original_z - z_reconstruct\n",
    "    predicted_error, _, _ = gated_sae(original_z, error)\n",
    "    # Add the predicted error to the z_reconstruct\n",
    "    z_reconstruct = z_reconstruct + predicted_error\n",
    "    new_error = original_z - z_reconstruct\n",
    "    # Evaluate the same metrics as before\n",
    "    l2_loss = (z_reconstruct - original_z).pow(2).sum(-1).mean().item()\n",
    "    mean_error = new_error.abs().sum(-1).mean().item()\n",
    "    evaluation_results.append((l2_loss, mean_error))\n",
    "\n",
    "# Divide by number of batches\n",
    "l2_loss, mean_error = zip(*evaluation_results)\n",
    "l2_loss = sum(l2_loss) / len(test_dataloader)\n",
    "mean_error = sum(mean_error) / len(test_dataloader)\n",
    "\n",
    "# Print\n",
    "print(f\"L2 Loss: {l2_loss:.4f}\")\n",
    "print(f\"Mean Error: {mean_error:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class TokenizedDataset(Dataset):\n",
    "    def __init__(self, tokenized_dataset):\n",
    "        self.tokenized_dataset = tokenized_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tokenized_dataset[idx]\n",
    "\n",
    "tokenized_dataset = torch.load('data/tokenized_dataset.pt')\n",
    "tokenized_dataset = tokenized_dataset[:1000, :]\n",
    "dataset = TokenizedDataset(tokenized_dataset)\n",
    "print(f\"Length of tokenised dataset = {len(tokenized_dataset)}\")\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Disable torch grad\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# Get the first batch\n",
    "batch = next(iter(dataloader))\n",
    "_, cache = model.run_with_cache(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache[\"z\", 9].shape # batch, seq, n_heads, head_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want some more comprehensive metrics\n",
    "# Basically, if we patch in the original SAE reconstruction, and then original SAE + predicted error\n",
    "# We will compare this to zero ablation and random ablation as a baseline\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from transformer_lens.utils import get_act_name\n",
    "from functools import partial\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def calculate_kl_divergence(clean_logits, patched_logits):\n",
    "    # Ensure the inputs are log probabilities\n",
    "    clean_log_probs = F.log_softmax(clean_logits, dim=-1)\n",
    "    patched_log_probs = F.log_softmax(patched_logits, dim=-1)\n",
    "    \n",
    "    # Convert patched_logits to probabilities\n",
    "    patched_probs = torch.exp(patched_log_probs)\n",
    "    \n",
    "    # Calculate KL divergence for each element in the batch and sequence\n",
    "    kl_div = F.kl_div(clean_log_probs, patched_probs, reduction='none')\n",
    "    \n",
    "    # Average over the vocabulary size (last dimension)\n",
    "    kl_div = kl_div.sum(dim=-1)\n",
    "    \n",
    "    # Average over the batch and sequence length\n",
    "    kl_div = kl_div.mean(dim=0).mean(dim=0)\n",
    "    \n",
    "    return kl_div.item()\n",
    "\n",
    "def attention_head_z_patching_hook(attention_head_z, hook: HookPoint, layer: int, sae: SparseAutoencoder, gated_sae: GatedSAE):\n",
    "    z_acts = einops.rearrange(attention_head_z, \"b s h d -> (b s) (h d)\")\n",
    "    if sae is not None:\n",
    "        # Get the reconstructions from the SAE\n",
    "        _, z_reconstruct, _, _, _ = sae(z_acts)\n",
    "    else:\n",
    "        z_reconstruct = torch.zeros_like(z_acts)\n",
    "    if gated_sae is not None:\n",
    "        # Get the error\n",
    "        error = z_acts - z_reconstruct\n",
    "        # Get the predicted error\n",
    "        predicted_error, _, _ = gated_sae(z_acts, error)\n",
    "        # Add the predicted error to the z_reconstruct\n",
    "        z_reconstruct = z_reconstruct + predicted_error\n",
    "    # Rearrange back into original shape\n",
    "    z_reconstruct = einops.rearrange(z_reconstruct, \"(b s) (h d) -> b s h d\", b=attention_head_z.shape[0], s=attention_head_z.shape[1], h=attention_head_z.shape[2], d=attention_head_z.shape[3])\n",
    "    attention_head_z = z_reconstruct\n",
    "    return attention_head_z\n",
    "\n",
    "# Let's try running this on the first batch\n",
    "clean_logits, clean_loss = model(batch, return_type=\"both\")\n",
    "\n",
    "hook_fn = partial(attention_head_z_patching_hook, layer=9, sae=None, gated_sae=None)\n",
    "patched_logits, patched_loss = model.run_with_hooks(\n",
    "    batch,\n",
    "    fwd_hooks=[(get_act_name(\"z\", layer, \"attn\"), hook_fn)],\n",
    "    return_type=\"both\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_loss, patched_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_divergence = calculate_kl_divergence(clean_logits, patched_logits)\n",
    "print(f\"KL Divergence: {kl_divergence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to write a function to do it for all batches\n",
    "def run_ablation_experiment(dataloader, model, sae, gated_sae):\n",
    "    kl_divergences, loss_differences = [], []\n",
    "    for i, batch in enumerate(tqdm(dataloader)):\n",
    "        clean_logits, clean_loss = model(batch, return_type=\"both\")\n",
    "        hook_fn = partial(attention_head_z_patching_hook, layer=9, sae=sae, gated_sae=gated_sae)\n",
    "        patched_logits, patched_loss = model.run_with_hooks(\n",
    "            batch,\n",
    "            fwd_hooks=[(get_act_name(\"z\", 9, \"attn\"), hook_fn)],\n",
    "            return_type=\"both\"\n",
    "        )\n",
    "        kl_divergence = calculate_kl_divergence(clean_logits, patched_logits)\n",
    "        kl_divergences.append(kl_divergence)\n",
    "        loss_difference = patched_loss - clean_loss\n",
    "        loss_differences.append(loss_difference)\n",
    "\n",
    "    # Average and return\n",
    "    kl_divergence = sum(kl_divergences) / len(dataloader)\n",
    "    loss_difference = sum(loss_differences) / len(dataloader)\n",
    "\n",
    "    # Normalise the loss difference \n",
    "    # loss_difference = loss_difference / clean_loss\n",
    "    return kl_divergence, loss_difference\n",
    "\n",
    "kl_divergence, loss_difference = run_ablation_experiment(dataloader, model, sae, gated_sae)\n",
    "print(f\"KL Divergence: {kl_divergence}\")\n",
    "print(f\"Loss Difference: {loss_difference}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without using the gated SAE\n",
    "kl_divergence, loss_difference = run_ablation_experiment(dataloader, model, sae, gated_sae=None)\n",
    "print(f\"KL Divergence: {kl_divergence}\")\n",
    "print(f\"Loss Difference: {loss_difference}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero ablation\n",
    "kl_divergence, loss_difference = run_ablation_experiment(dataloader, model, sae=None, gated_sae=None)\n",
    "print(f\"KL Divergence: {kl_divergence}\")\n",
    "print(f\"Loss Difference: {loss_difference}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, HfFolder\n",
    "# Import login\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n",
    "\n",
    "# Ensure you are logged in to HuggingFace\n",
    "# You can use the following command to log in via the terminal\n",
    "# huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = HfApi()\n",
    "username = \"charlieoneill\"\n",
    "repo_name = \"error-saes\"\n",
    "repo_id = f\"{username}/{repo_name}\"\n",
    "\n",
    "repo_url = api.create_repo(repo_id=repo_id, private=False, token=\"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\")\n",
    "print(f\"Repository {repo_id} created at: {repo_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload gated saes to the repo\n",
    "hf_folder = HfFolder()\n",
    "hf_folder.push_to_hub(repo_id=repo_id, token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_name = \"charlieoneill/error-saes\"\n",
    "\n",
    "file_name = \"sae_layer_9.pt\"\n",
    "\n",
    "gated_sae "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from huggingface_hub import hf_hub_download\n",
    "from gated_sae import GatedSAE\n",
    "\n",
    "# Define the function to download and load the model\n",
    "def load_gated_sae(repo_id, filename, n_input_features, projection_up, l1_coefficient):\n",
    "    # Download the model file from HuggingFace Hub\n",
    "    file_path = hf_hub_download(repo_id=repo_id, filename=filename)\n",
    "\n",
    "    model = torch.load(file_path, map_location=torch.device('cpu'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Define parameters\n",
    "repo_id = 'charlieoneill/error-saes'\n",
    "filename = 'sae_layer_9.pt'\n",
    "n_input_features = 768\n",
    "projection_up = 8\n",
    "l1_coefficient = 1e-4\n",
    "\n",
    "# Load the model\n",
    "model = load_gated_sae(repo_id, filename, n_input_features, projection_up, l1_coefficient)\n",
    "\n",
    "# Print model summary (optional)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "path = 'data/tokenized_dataset.pt'\n",
    "\n",
    "tokens = torch.load(path)\n",
    "tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import load_dataset\n",
    "\n",
    "def create_tokenized_dataset():\n",
    "    print(\"Creating tokenized dataset...\")\n",
    "    model_name = 'gpt2-small'\n",
    "    #dataset = load_dataset(\"NeelNanda/pile-10k\")\n",
    "\n",
    "    dataset = load_dataset(\"apollo-research/monology-pile-uncopyrighted-tokenizer-gpt2\", streaming=True)\n",
    "    print(\"Dataset loaded.\")\n",
    "    \n",
    "    seq_len = 128\n",
    "    model = HookedTransformer.from_pretrained(model_name, device='cpu')\n",
    "    \n",
    "    tokenized_dataset = []\n",
    "    text = \" \".join(dataset['train']['text'])\n",
    "    \n",
    "    for i in trange(0, len(text)//100, 2500):\n",
    "        tokens = model.to_tokens(text[i:i+2500]).squeeze()\n",
    "        for j in range(0, len(tokens), seq_len):\n",
    "            tokenized_dataset.append(tokens[j:j+seq_len])\n",
    "    \n",
    "    tokenized_dataset = [x for x in tokenized_dataset if len(x) == seq_len]\n",
    "    print(f\"Length of tokenised dataset = {len(tokenized_dataset)}\")\n",
    "    \n",
    "    for i, tokens in enumerate(tokenized_dataset):\n",
    "        assert tokens.shape[0] == seq_len, f\"Token {i} has shape {tokens.shape}\"\n",
    "    \n",
    "    tokenized_dataset = torch.stack(tokenized_dataset)\n",
    "    torch.save(tokenized_dataset, 'data/tokenized_dataset.pt')\n",
    "    print(f\"Tokenized dataset with {len(tokenized_dataset)} examples with {seq_len} tokens saved to 'data/tokenized_dataset.pt'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"apollo-research/monology-pile-uncopyrighted-tokenizer-gpt2\", streaming=True)\n",
    "print(\"Dataset loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first 1000 examples\n",
    "data_iter = iter(dataset['train'])\n",
    "input_ids_list = []\n",
    "seq_len = 128\n",
    "for i in tqdm(range(125000)):\n",
    "    example = next(data_iter)\n",
    "    input_ids = example['input_ids']\n",
    "    # Split this list into chunks of 128\n",
    "    for j in range(0, len(input_ids), seq_len):\n",
    "        input_ids_list.append(torch.tensor(input_ids[j:j+seq_len]))\n",
    "\n",
    "# Stack the input_ids\n",
    "tokenized_dataset = torch.stack(input_ids_list)\n",
    "torch.save(tokenized_dataset, 'data/tokenized_dataset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(tokenized_dataset, 'data/tokenized_dataset.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "# Initialize the model\n",
    "model_name = \"gpt2-small\"\n",
    "model = HookedTransformer.from_pretrained(model_name)\n",
    "model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the dataset\n",
    "dataset_name = \"apollo-research/monology-pile-uncopyrighted-tokenizer-gpt2\"\n",
    "dataset = load_dataset(dataset_name, split=\"train\", streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_lens.toolkit.pretrained_saes import get_gpt2_res_jb_saes\n",
    "\n",
    "# let's start with a layer 8 SAE.\n",
    "hook_point = \"blocks.8.hook_resid_pre\"\n",
    "\n",
    "# if the SAEs were stored with precomputed feature sparsities,\n",
    "#  those will be return in a dictionary as well.\n",
    "saes, sparsities = get_gpt2_res_jb_saes(hook_point)\n",
    "\n",
    "print(saes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_lens.training.session_loader import LMSparseAutoencoderSessionloader\n",
    "\n",
    "sparse_autoencoder = saes[hook_point]\n",
    "device = 'cpu'\n",
    "sparse_autoencoder.to(device)\n",
    "sparse_autoencoder.cfg.device = device\n",
    "\n",
    "print(sparse_autoencoder.cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_lens.training.session_loader import LMSparseAutoencoderSessionloader\n",
    "from sae_lens.toolkit.pretrained_saes import get_gpt2_res_jb_saes\n",
    "\n",
    "# let's start with a layer 8 SAE.\n",
    "hook_point = \"blocks.8.hook_resid_pre\"\n",
    "\n",
    "# if the SAEs were stored with precomputed feature sparsities,\n",
    "#  those will be return in a dictionary as well.\n",
    "saes, sparsities = get_gpt2_res_jb_saes(hook_point)\n",
    "\n",
    "sparse_autoencoder = saes[hook_point]\n",
    "device = 'cpu'\n",
    "sparse_autoencoder.to(device)\n",
    "sparse_autoencoder.cfg.device = device\n",
    "\n",
    "sparse_autoencoder.cfg.hook_point = \"blocks.9.attn.hook_z\"\n",
    "sparse_autoencoder.cfg.store_batch_size = 4\n",
    "\n",
    "print(sparse_autoencoder.cfg.store_batch_size)\n",
    "\n",
    "loader = LMSparseAutoencoderSessionloader(sparse_autoencoder.cfg)\n",
    "\n",
    "# don't overwrite the sparse autoencoder with the loader's sae (newly initialized)\n",
    "model, _, activation_store = loader.load_sae_training_group_session()\n",
    "\n",
    "# batch_tokens = activation_store.get_batch_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tokens = activation_store.get_batch_tokens()\n",
    "batch_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tokens = activation_store.get_batch_tokens()\n",
    "batch_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, cache = model.run_with_cache(batch_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "\n",
    "z = cache[\"z\", 9]\n",
    "print(z.shape)\n",
    "z = einops.rearrange(z, \"b s n d -> (b s) (n d)\")\n",
    "print(z.shape)\n",
    "# Print norm of z\n",
    "print(z.norm(dim=-1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.norm(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
